{
  "prompt_id": "evaluation-report-template",
  "prompt_text": "Create a comprehensive evaluation report template for [ORGANIZATION NAME]\u2019s [PROGRAM NAME] covering [REPORT PERIOD] in [GEOGRAPHY].\n\nQuick start (minimal inputs): If you only provide [ORGANIZATION NAME], [PROGRAM NAME], [REPORT PERIOD], [GEOGRAPHY], and [TONE: BALANCED (default), FORMAL, or WARM], generate the full template using defaults for all other fields.\n\nIf key details are missing, first ask these 5 questions, then proceed:\n1) Primary audience and uses? [e.g., program staff to improve delivery; leadership to inform planning]\n2) Funders/board version needed? [Yes/No; which funder/board?]\n3) Key demographics for equity breakdowns? [e.g., age, race/ethnicity, income, language, zip code]\n4) Main data sources available? [e.g., surveys, interviews, admin data, observations]\n5) Team capacity? [TEAM SIZE/RESOURCES: e.g., 3 staff, part-time evaluator, $50K program budget]\n\nDELIVERABLE: Produce a complete, fill-in-ready template document that includes:\n- Section headings in the specified order with per-section word ranges\n- Writing prompts in [BRACKETS] for users to complete\n- At least one short, concrete example in the Executive Summary and one in the Findings section showing the expected level of specificity\n- Sample data table shells and visual placeholders with caption prompts\n- \u201cIn plain language\u201d callouts translating evaluator terms\n- \u201cHow to adapt for funders/board\u201d notes within each section\n- Equity and participation prompts embedded in methods and findings\n- Constructive subheads for mixed/negative results: \u201cWhat we learned / Why this matters / What we\u2019re changing\u201d\n\nLENGTH TARGET: 10\u201325 pages total (adjustable). If user does not specify a page target, default to 10\u201325 pages.\n\nTONE: [BALANCED (default) | FORMAL | WARM]\n- BALANCED: Professional and approachable\n- FORMAL: Grant/board-facing, neutral\n- WARM: Community-centered, accessible\n\nAUDIENCES AND USES:\n- Primary audience: [PRIMARY AUDIENCE and intended uses]\n- Secondary audience(s): [SECONDARY AUDIENCE and intended uses]\n- Funders/Board: [FUNDERS/BOARD if applicable]\n\nTEMPLATE STRUCTURE AND SPECIFICATIONS\n\n1) Executive Summary (350\u2013600 words)\nInclude prompts for:\n- Program purpose and who it serves: [Program aims; target population; high-level needs/context]\n- Reach and participation: [# served; eligibility; participation intensity/dosage; key demographics]\n- Top 2\u20133 findings: [Quantitative KPI highlights with %/#; qualitative themes with brief quote]\n- High-level recommendations: [Most actionable next steps]\n- Overall assessment/learning stance: [Balanced summary; what worked; what to improve]\n- In plain language: \u201cThis section tells busy readers what changed, for whom, and what we\u2019ll do next.\u201d\n- How to adapt for funders/board: Lead with outcomes tied to grant objectives; keep to one page; include grant KPIs and cost-per-outcome if available.\n\nExample (model the level of detail and tone):\n\u201cIn 2024, the Youth Pathways mentoring program served 127 students in Westview (62% Latinx, 28% Black; 71% eligible for free/reduced lunch). Attendance improved for 89% of participants; average chronic absence dropped from 16% to 9% over two semesters. Students completing 10+ mentoring sessions were 2.1x more likely to submit all homework on time. Youth and caregiver interviews highlighted stronger school belonging and improved communication at home. We recommend formalizing caregiver touchpoints and expanding peer mentoring to all cohorts.\u201d\n\n2) Program Overview (300\u2013450 words)\nPrompts:\n- Goals and theory of change: [Brief aims; core assumptions]\n- Target population and eligibility: [Age/grade; geography; barriers addressed]\n- Activities and dosage: [What, how often, by whom; training/credentials]\n- Staffing/resources: [TEAM SIZE/RESOURCES; partnerships; budget range]\n- Context: [Relevant policy/school-year cycles; community factors]\n- Logic model reference: [Appendix reference]\n- Sample phrasing: \u201cIn [YEAR], [PROGRAM] served [#] participants through [KEY ACTIVITIES] to achieve [OUTCOMES].\u201d\n- How to adapt for funders/board: Align goals and activities with funded objectives and approved budget.\n\n3) Evaluation Questions & Methodology (300\u2013500 words)\nPrompts:\n- Evaluation questions (3\u20135): [e.g., To what extent did participants improve in [OUTCOME]? Which components were most/least helpful and for whom?]\n- Design/approach: [Pre-post, cohort tracking, contribution not attribution; any comparison group]\n- Data sources: [DATA SOURCES: surveys, interviews, focus groups, admin records, observations; instrument names]\n- Sampling and timing: [Who, how many, when; response rates]\n- Data quality checks: [Missing data review, reliability checks, spot audits, data cleaning steps]\n- Ethics/consent: [Consent process; privacy; IRB status if applicable]\n- Equity/participation: [Whose voices shaped questions? Any community reviewers? Accessibility considerations]\n- In plain language: \u201cWe measured success by [brief description of indicators and how collected].\u201d\n- Table shell: Method | Sample/Response Rate | Timeline | Purpose/Question(s) Informed\n- How to adapt for funders/board: Keep design description concise, emphasize validity, consent, and alignment with grant indicators.\n\n4) Findings by Outcome Area (400\u2013700 words per outcome)\nFor each outcome area, include:\n- Outcome definition and indicator(s): [Define; list KPIs and targets]\n- Quantitative results:\n  - KPI table shell: Indicator | Target | Actual | % Achieved | Data Source | Notes\n  - Visual placeholder suggestions:\n    - Pre/post change \u2192 Paired bar or line chart\n    - Achievement rates \u2192 Simple bar chart\n    - Demographic distribution \u2192 Stacked bar chart\n  - Caption prompts: \u201cParticipants showed [X]% improvement in [OUTCOME] from [BASELINE] to [ENDLINE] (n=[N]).\u201d\n- Qualitative insights:\n  - Themes: [2\u20133 themes with brief evidence]\n  - Quote placeholder(s): \u201c[Insert 1\u20132 participant quotes with consent; include ID code]\u201d\n- Equity lens:\n  - Disaggregate by [KEY DEMOGRAPHICS] and interpret gaps\n  - Prompt: \u201cWhose outcomes improved least? Possible drivers? Actionable responses?\u201d\n- Mixed/negative results framing:\n  - What we learned: [Specific finding]\n  - Why this matters: [Implication for clients/operations/equity]\n  - What we\u2019re changing: [Concrete adjustment and when]\n- Evidence tags: [Cite source: \u201cSurvey Q12,\u201d \u201cAdmin attendance record,\u201d \u201cFocus Group 2\u201d]\n- How to adapt for funders/board: Lead with grant KPIs; include 1\u20132 concise visuals; footnote methods; keep quotes brief.\n\nExample (model the expected specificity):\nOutcome: Improved on-time homework submission\n- Indicator: % of students submitting \u226590% of assignments\n- Target: 70%; Actual: 64% (n=114); % Achieved: 91%\n- Pre/post: 41% \u2192 64% (+23 points)\n- Disaggregation: Grades 9\u201310: 68%; Grades 11\u201312: 58%; English learners: 61%; Non-EL: 66%\n- Theme: Students credited text reminders and peer study halls. Quote: \u201cThe Tuesday study group kept me from falling behind.\u201d \u2014 10th grader (consented)\n- What we\u2019re changing: Expand peer study halls to 2x/week for upper grades; pilot multilingual reminders.\n\n5) Discussion/Interpretation (300\u2013500 words)\nPrompts:\n- Connect findings to program theory: [Which components likely drove change, for whom, and why]\n- Triangulate: [How quantitative and qualitative converge/diverge]\n- External factors: [School calendar, transportation, policy shifts]\n- Surprises: [What was unexpected and how we validated it]\n- Learning stance:\n  - What we learned / Why this matters / What we\u2019re changing\n- In plain language: \u201cHere we make sense of why results look the way they do.\u201d\n- How to adapt for funders/board: Emphasize accountability, practical lessons, and planned course corrections.\n\n6) Recommendations & Next Steps (250\u2013400 words)\nPrompts:\n- Tie each recommendation to an insight and an outcome gap\n- Make steps specific, time-bound, and feasible given [TEAM SIZE/RESOURCES]\n- Table shell:\n  - Recommendation | Owner/Lead | Timeframe (immediate/3\u20136 months/12 months) | Resource Needs (staff hours, budget) | Feasibility (H/M/L) | Success Measure\n- Sample recommendations:\n  - \u201cExpand peer mentoring to all cohorts | Program Manager | 6 months | 20 staff hours, $2K | High | \u226575% cohort participation\u201d\n  - \u201cStandardize caregiver outreach script and schedule | Family Liaison | Immediate | 8 hours setup | High | 80% reach within first month\u201d\n- How to adapt for funders/board: Flag any budget-neutral options; identify items requiring reallocation or future grant funding.\n\n7) Limitations (150\u2013250 words)\nPrompts:\n- Sample size/response rates and representativeness\n- Data quality issues: [Missingness, self-report bias]\n- Design constraints: [No comparison group; short follow-up window]\n- External influences\n- Ethics/consent status: [All quotes used with explicit permission; data stored securely]\n- In plain language: \u201cHere\u2019s what we couldn\u2019t measure or are less sure about.\u201d\n- How to adapt for funders/board: Be transparent and concise; emphasize mitigation steps.\n\n8) Appendices (checklist with placeholders)\n- [ ] Logic model or theory of change\n- [ ] Data collection instruments (surveys, interview/focus group guides)\n- [ ] Detailed data tables (by demographic subgroup)\n- [ ] Sample consent forms and data privacy statement\n- [ ] Complete indicator list with definitions and calculation notes\n- [ ] Additional participant quotes (with consent documentation)\n- [ ] Data quality checks documentation (missing data rates; reliability)\n\nFormatting and style requirements\n- Define all acronyms on first use\n- Use specific numbers and percentages (avoid \u201cmany/most\u201d)\n- Tie each claim to a data source\n- Use simple, plain English; include \u201cIn plain language\u201d callouts where technical\n- Visuals: include captions, n-sizes, and data sources\n- Page target: [PAGE TARGET if specified; otherwise 10\u201325 pages]\n\nEquity and participation integration\n- For each outcome: disaggregate by [KEY DEMOGRAPHICS], interpret gaps, and propose actions\n- Prompts: \u201cWhose voices informed this evaluation?\u201d \u201cWho is missing and how will we include them next time?\u201d\n- Note access and language accommodations in data collection\n- Encourage participatory steps: [participant reviewers; co-interpretation sessions]\n\nQuality standards\nDo:\n- Use realistic nonprofit examples (e.g., volunteer training completion, client retention, attendance)\n- Present successes and challenges honestly\n- Make recommendations concrete, resourced, and sequenced\nAvoid:\n- Hype, defensiveness, or unexplained jargon\n- Vague claims or recommendations without owners/timelines\n\nDocument details (front matter fields)\n- Prepared by: [AUTHOR NAME/TITLE]\n- In collaboration with: [EVALUATOR NAME/ORGANIZATION, if external]\n- Date: [DATE]\n- Report covers: [REPORT PERIOD]\n- Geographic scope: [GEOGRAPHY]\n- Audiences and uses: [PRIMARY/SECONDARY/FUNDERS-BOARD]\n\nOUTPUT INSTRUCTIONS FOR AI\n- Generate a complete, fill-in-ready template document with all sections above, writing prompts in [BRACKETS], table shells, visual placeholders, \u201cIn plain language\u201d callouts, equity prompts, and \u201cHow to adapt for funders/board\u201d notes within each section.\n- Include at least one concise, concrete example paragraph in the Executive Summary and one in the Findings section to demonstrate expected specificity and tone.\n- If the user provided only quick-start inputs, apply sensible defaults:\n  - Tone: BALANCED\n  - Audiences: Primary\u2014program staff/leadership; Secondary\u2014partners/community; Funders/Board\u2014if specified\n  - Key demographics: age, race/ethnicity, income, language, geography\n  - Data sources: surveys, interviews, admin data\n  - Team capacity: \u201c3-person team; part-time evaluator; $50K program budget\u201d\n- End the template with a short \u201cHow to refine\u201d note for users, e.g.:\n  - \u201cAsk: \u2018Shorten the methodology to 200 words\u2019\u201d\n  - \u201cAsk: \u2018Add a visual for the retention KPI and write a caption\u2019\u201d\n  - \u201cAsk: \u2018Rewrite for a FORMAL tone for a board packet\u2019\u201d",
  "category": "programs",
  "generated_at": "2025-11-02T14:22:04.317005Z",
  "scenarios": [
    {
      "id": "scenario_1",
      "name": "Small Community Org",
      "description": "Urban food access nonprofit serving Chicago\u2019s South Side neighborhoods through produce vouchers, peer-led nutrition circles, and corner-store partnerships.",
      "values": {
        "ORGANIZATION NAME": "Southside Fresh Food Collective (SFFC)",
        "PROGRAM NAME": "Corner Store Produce Vouchers & Nutrition Circles",
        "REPORT PERIOD": "January 1\u2013December 31, 2024",
        "GEOGRAPHY": "Chicago South Side (Englewood, Washington Park, Bronzeville, Woodlawn)",
        "TONE": "WARM",
        "BALANCED (default) | FORMAL | WARM": "WARM",
        "PAGE TARGET if specified; otherwise 10\u201325 pages": "12\u201318 pages",
        "Primary audience and uses": "Program staff and Community Advisory Council to improve delivery, refine outreach, and plan 2025 curriculum.",
        "Secondary audience and intended uses": "Partner corner stores, volunteers, and local health collaborators to coordinate stocking, timing, and workshop content.",
        "Funders/Board version needed?": "Yes \u2014 Chicago Community Trust (Food Equity Fund) and Aldi Community Giving; brief board packet for SFFC Board of Directors.",
        "FUNDERS/BOARD if applicable": "Chicago Community Trust (Food Equity Fund), Aldi Community Giving, SFFC Board of Directors",
        "Key demographics for equity breakdowns": [
          "Age (18\u201334, 35\u201354, 55+)",
          "Race/Ethnicity (Black, Latinx, White, Other)",
          "Household income (<$25K, $25\u201350K, >$50K)",
          "Language (English, Spanish)",
          "ZIP code (60621, 60637, 60653, 60615)",
          "SNAP eligibility (Yes/No)",
          "Household with children (Yes/No)"
        ],
        "Main data sources available": [
          "Participant intake and follow-up surveys (SFFC Intake & Follow-Up Survey v2)",
          "USDA 6-Item Food Security Module",
          "Store voucher redemption logs (serialized QR codes)",
          "Workshop attendance sheets",
          "Focus group notes (two groups)",
          "Observation checklists for store produce displays",
          "Text reminder system logs (Twilio)"
        ],
        "TEAM SIZE/RESOURCES": "4 staff (2 Program Coordinators, 1 Outreach Specialist, 0.5 FTE evaluator), ~35 volunteers; program budget $180,000",
        "Partnerships": [
          "7 partner corner stores",
          "Englewood Community Kitchen",
          "Cook County Health Promotoras",
          "Local farmer aggregation co-op"
        ],
        "Budget range": "$180,000 program budget; organizational budget ~$420,000",
        "Program aims; target population; high-level needs/context": "Increase affordable access to fresh produce and build food skills among low-income households facing high rates of diet-related disease and limited healthy retail options.",
        "# served; eligibility; participation intensity/dosage; key demographics": "320 households enrolled (76% SNAP-eligible; 61% Black, 29% Latinx; 23% Spanish-speaking). Eligibility: South Side residents with income \u2264200% FPL. Dosage: up to 6 monthly $20 produce vouchers; 4 peer-led nutrition circles per cohort; optional cooking demos.",
        "Quantitative KPI highlights with %/#; qualitative themes with brief quote": "Average fruit/veg servings rose from 2.3 to 3.5/day (+1.2; n=246). Food insecurity decreased from 68% to 52% (n=238). Voucher redemption rate 83% (1,587 of 1,920 issued). \u201cThe Wednesday text about greens reminded me to stop by the store.\u201d \u2014 Participant P-114 (consented).",
        "Most actionable next steps": [
          "Add Spanish-speaking co-facilitator for all nutrition circles by March 2025",
          "Pilot extended evening store hours with two partners (Q2 2025)",
          "Launch \u2018produce-of-the-month\u2019 text with quick bilingual recipe cards (Q1 2025)"
        ],
        "Balanced summary; what worked; what to improve": "Vouchers combined with peer support increased produce intake and reduced food insecurity, with strong redemption rates. Participation lagged for Spanish speakers and older adults; access barriers include evening availability and transportation.",
        "Brief aims; core assumptions": "Financial incentives plus peer learning and easier access at nearby stores will increase healthy purchasing and consumption.",
        "Age/grade; geography; barriers addressed": "Adults 18+ and caregivers in Chicago South Side neighborhoods; barriers include cost, nearby supply, store hours, and limited culturally relevant produce.",
        "What, how often, by whom; training/credentials": "Monthly vouchers; twice-monthly nutrition circles led by certified Community Health Workers; store-owner coaching on produce handling; quarterly cooking demos by trained volunteers with food safety certification.",
        "TEAM SIZE/RESOURCES; partnerships; budget range": "4 staff (0.5 FTE evaluator), 35 volunteers; 7 stores and 3 community partners; $180K program budget.",
        "Relevant policy/school-year cycles; community factors": "Inflation increased produce costs; ongoing corner-store closures; city Healthy Corner Store Initiative aligns incentives.",
        "Appendix reference": "Appendix A: Logic model; Appendix B: Instruments",
        "YEAR": 2024,
        "PROGRAM": "Corner Store Produce Vouchers & Nutrition Circles",
        "#": 320,
        "KEY ACTIVITIES": [
          "Produce vouchers (QR-coded)",
          "Peer-led nutrition circles",
          "Cooking demonstrations",
          "Store partner training on stocking and display",
          "Bilingual text nudges"
        ],
        "OUTCOMES": [
          {
            "name": "Increased fruit and vegetable consumption",
            "definition": "Daily servings of fruits and vegetables among enrolled adults.",
            "kpis": [
              {
                "indicator": "% of participants consuming \u22655 servings/day",
                "target": 35,
                "actual": 31,
                "%_achieved": 89,
                "data_source": "SFFC Survey Q5 (24-hr recall adaptation)",
                "notes": "Matched pre-post sample; see Appendix D."
              },
              {
                "indicator": "Average daily servings (mean)",
                "target": 3.4,
                "actual": 3.5,
                "%_achieved": 103,
                "data_source": "SFFC Survey Q5",
                "notes": "Baseline 2.3 \u2192 Endline 3.5"
              }
            ],
            "baseline": 2.3,
            "endline": 3.5,
            "n": 246,
            "disaggregation": {
              "Race_Ethnicity": {
                "Black_mean_servings": 3.6,
                "Latinx_mean_servings": 3.4
              },
              "Language": {
                "English_mean_servings": 3.6,
                "Spanish_mean_servings": 3.3
              },
              "Household_with_children": {
                "Yes_mean_servings": 3.6,
                "No_mean_servings": 3.2
              },
              "ZIP": {
                "60621_mean_servings": 3.6,
                "60637_mean_servings": 3.4,
                "60653_mean_servings": 3.3,
                "60615_mean_servings": 3.5
              }
            },
            "themes": [
              "Peer recipes and cooking demos made produce less intimidating.",
              "Text reminders tied to store specials increased redemption midweek."
            ],
            "quotes": [
              {
                "text": "The Wednesday text about greens reminded me to stop by the store.",
                "id": "P-114",
                "consent": "Yes"
              }
            ],
            "equity_gap_analysis": "Spanish speakers improved less (avg 3.3 vs 3.6). Likely drivers: translation lag, fewer bilingual circles. Action: add Spanish co-facilitator and translate all texts by March 2025.",
            "mixed_negative_results": {
              "what_we_learned": "Improvements were smaller among Spanish-speaking participants.",
              "why_this_matters": "Language access affects equitable health gains.",
              "what_we_are_changing": "Recruit and onboard bilingual facilitator; prioritize Spanish-language recipe cards (Q1 2025)."
            },
            "evidence_tags": [
              "Survey Q5",
              "Workshop attendance sheet",
              "Text log export"
            ]
          },
          {
            "name": "Reduced household food insecurity",
            "definition": "Household-level food security measured via USDA 6-Item module.",
            "kpis": [
              {
                "indicator": "% households \u2018food secure\u2019 at endline",
                "target": 55,
                "actual": 48,
                "%_achieved": 87,
                "data_source": "USDA 6-Item",
                "notes": "Movement from high/very low to marginal/secure."
              },
              {
                "indicator": "Food insecurity rate (any)",
                "target": 55,
                "actual": 52,
                "%_achieved": 106,
                "data_source": "USDA 6-Item",
                "notes": "Baseline 68% \u2192 Endline 52% (\u221216 points)"
              }
            ],
            "baseline": 68,
            "endline": 52,
            "n": 238,
            "disaggregation": {
              "Household_with_children": {
                "Endline_food_secure": 49
              },
              "SNAP_status": {
                "SNAP_enrolled_endline_food_secure": 51,
                "Not_on_SNAP_endline_food_secure": 44
              },
              "Age": {
                "55_plus_endline_food_secure": 45,
                "18_54_endline_food_secure": 49
              }
            },
            "themes": [
              "Vouchers helped bridge the last week of the month.",
              "Store hours limited access for shift workers."
            ],
            "quotes": [
              {
                "text": "The $20 kept us from skipping dinner that last week.",
                "id": "P-207",
                "consent": "Yes"
              }
            ],
            "equity_gap_analysis": "Older adults (55+) improved less. Mobility and fixed incomes may limit shopping frequency. Pilot delivery and mobile market stop at senior building in Q2 2025.",
            "mixed_negative_results": {
              "what_we_learned": "Evening access remains a barrier for shift workers.",
              "why_this_matters": "Without access when people are off work, benefits are underutilized.",
              "what_we_are_changing": "Two stores will extend hours to 9 pm on Wednesdays (Q2 2025)."
            },
            "evidence_tags": [
              "USDA 6-Item",
              "Store redemption logs",
              "Focus Group 1"
            ]
          },
          {
            "name": "Store healthy inventory",
            "definition": "Number of partner stores meeting SFFC healthy stocking standard (\u226510 fresh produce SKUs).",
            "kpis": [
              {
                "indicator": "# of stores \u226510 SKUs",
                "target": 6,
                "actual": 5,
                "%_achieved": 83,
                "data_source": "Store audit checklist",
                "notes": "Quarterly audits by staff."
              },
              {
                "indicator": "Average produce SKUs per store",
                "target": 10,
                "actual": 9.8,
                "%_achieved": 98,
                "data_source": "Store audit checklist",
                "notes": "Baseline 7.2 \u2192 Endline 9.8"
              }
            ],
            "baseline": 7.2,
            "endline": 9.8,
            "n": 7,
            "disaggregation": {
              "Store_type": {
                "Independent_bodega_avg_SKUs": 9.5,
                "Franchise_corner_avg_SKUs": 10.2
              }
            },
            "themes": [
              "Microgrants for refrigeration increased leafy green offerings.",
              "Spoilage risk remains a concern without predictable demand."
            ],
            "quotes": [
              {
                "text": "The small cooler let us try cilantro without it wilting in two days.",
                "id": "Store-03",
                "consent": "Yes"
              }
            ],
            "equity_gap_analysis": "Stores in 60653 lag behind in SKUs due to lower foot traffic; targeted promotions planned.",
            "mixed_negative_results": {
              "what_we_learned": "Two stores fell short due to spoilage concerns.",
              "why_this_matters": "Limited variety reduces participant choice and cultural relevance.",
              "what_we_are_changing": "Offer $500 spoilage offset + \u2018produce-of-the-month\u2019 marketing (Q2 2025)."
            },
            "evidence_tags": [
              "Store audit",
              "Redemption logs",
              "Observation checklist"
            ]
          }
        ],
        "Evaluation questions": [
          "To what extent did participants increase fruit and vegetable consumption?",
          "How did food security status change over the program period, and for whom?",
          "Which components (vouchers, circles, texts) were most helpful and why?",
          "What barriers limited participation or redemption, especially for Spanish speakers and older adults?"
        ],
        "Design/approach": "Pre-post cohort tracking with matched IDs; contribution not attribution; no comparison group.",
        "DATA SOURCES: surveys, interviews, focus groups, admin records, observations; instrument names": "SFFC Intake & Follow-Up Survey v2 (English/Spanish), USDA 6-Item, store audit checklist, redemption logs (QR scans), Twilio SMS logs, two focus groups using semi-structured guide.",
        "Sampling and timing": "Census of 320 enrolled households; endline survey response rate 77% (246 matched). Focus groups n=17 total (9 English, 8 Spanish) in November 2024.",
        "Data quality checks": "Range and logic checks in SurveyCTO; 10% spot-audits of store SKUs; de-duplication of QR scans; bilingual back-translation review.",
        "Consent process; privacy; IRB status if applicable": "Written consent at enrollment; de-identified analysis; encrypted drive; IRB not required.",
        "Whose voices shaped questions? Any community reviewers? Accessibility considerations": "Community Advisory Council (12 residents) prioritized measures; Spanish translation and interpretation; childcare and $25 gift cards for focus groups.",
        "In plain language: brief description of indicators and how collected": "We asked people about how many fruits and vegetables they ate, whether they worried about running out of food, and we tracked how often vouchers were used and which stores stocked produce.",
        "Define; list KPIs and targets": "See OUTCOMES.kpis for indicators, targets, and actuals for consumption, food security, and store stocking.",
        "Which components likely drove change, for whom, and why": "Voucher value plus midweek text reminders supported purchases; peer circles normalized trying new produce, especially for caregivers.",
        "How quantitative and qualitative converge/diverge": "Survey improvements aligned with redemption peaks and circle attendance; qualitative comments highlighted language access gaps explaining lower gains among Spanish speakers.",
        "School calendar, transportation, policy shifts": "Inflation and two store closures influenced supply; bus route change in 60621 improved access midyear.",
        "What was unexpected and how we validated it": "Large redemption spike on Wednesdays; confirmed via store logs and SMS schedule analytics.",
        "Missingness, self-report bias": "Diet recall self-report may over/under-estimate; 23% lacked matched endline; sensitivity analysis showed similar patterns.",
        "Design constraints: No comparison group; short follow-up window": "No counterfactual; six-month average exposure limited detection of sustained behavior change.",
        "All quotes used with explicit permission; data stored securely": "Yes \u2014 documented consents; quotes labeled with IDs; data on encrypted drives.",
        "participant reviewers; co-interpretation sessions": "Two co-interpretation sessions with Advisory Council (Dec 2024) to review preliminary charts.",
        "Caption variables example": {
          "X": -16,
          "OUTCOME": "Food insecurity rate (any)",
          "BASELINE": 68,
          "ENDLINE": 52,
          "N": 238
        },
        "AUTHOR NAME/TITLE": "Jada Morris, Program Manager",
        "EVALUATOR NAME/ORGANIZATION, if external": "Marisol Reyes, MPH (contract evaluator)",
        "DATE": "2025-01-30",
        "PRIMARY/SECONDARY/FUNDERS-BOARD": "Primary: SFFC program staff and Community Advisory Council; Secondary: partner stores and volunteers; Funders/Board: Chicago Community Trust, Aldi Community Giving, SFFC Board",
        "BRACKETS": "Use [ ] to indicate fill-in prompts throughout the template"
      }
    },
    {
      "id": "scenario_2",
      "name": "Mid-Size Professional Org",
      "description": "Rural health access nonprofit coordinating telehealth navigation, device lending, and coaching across Appalachian Kentucky.",
      "values": {
        "ORGANIZATION NAME": "Mountain Health Access Network (MHAN)",
        "PROGRAM NAME": "TeleCare Connect",
        "REPORT PERIOD": "FY2024 (July 1, 2023\u2013June 30, 2024)",
        "GEOGRAPHY": "Eastern Kentucky (Perry, Knott, Letcher, and Breathitt counties)",
        "TONE": "FORMAL",
        "BALANCED (default) | FORMAL | WARM": "FORMAL",
        "PAGE TARGET if specified; otherwise 10\u201325 pages": "15\u201320 pages",
        "Primary audience and uses": "Operations leadership and care navigators to drive quality improvement and resource allocation; compliance with contract metrics.",
        "Secondary audience and intended uses": "Hospital/clinic partners and county libraries to coordinate scheduling windows and private telehealth spaces.",
        "Funders/Board version needed?": "Yes \u2014 Kentucky Cabinet for Health and Family Services (Telehealth Modernization Grant), Anthem Medicaid MCO; Board of Directors summary.",
        "FUNDERS/BOARD if applicable": "KY Cabinet for Health and Family Services; Anthem Medicaid; MHAN Board of Directors",
        "Key demographics for equity breakdowns": [
          "Age (18\u201344, 45\u201364, 65+)",
          "Rurality/distance to clinic (>30 miles vs \u226430 miles)",
          "Insurance type (Medicaid, Medicare, Commercial, Uninsured)",
          "Income (<150% FPL, 150\u2013300% FPL, >300% FPL)",
          "Disability status",
          "Language (English, Spanish, ASL via interpreter)",
          "Veteran status"
        ],
        "Main data sources available": [
          "EHR scheduling/attendance data (partner clinics)",
          "Navigator call logs (Salesforce)",
          "Patient Activation Measure (PAM-10) survey",
          "Post-visit patient satisfaction survey",
          "Key informant interviews (clinic managers)",
          "Broadband speed tests (Ookla snapshots)"
        ],
        "TEAM SIZE/RESOURCES": "18 FTE (10 navigators, 2 CHW leads, 1 evaluation manager, 3 admin, 2 IT), device lending library (120 tablets), program budget $600,000",
        "Partnerships": [
          "Appalachian Regional Healthcare (ARH)",
          "County library systems (4)",
          "University of Kentucky Telehealth Lab",
          "Regional 211 call center"
        ],
        "Budget range": "$600,000 program; organizational budget ~$2.3M",
        "Program aims; target population; high-level needs/context": "Reduce missed appointments and improve chronic disease management by enabling rural residents to access telehealth reliably.",
        "# served; eligibility; participation intensity/dosage; key demographics": "1,420 enrolled patients (65% Medicaid; 24% age 65+; 2% Spanish-speaking; 6% veterans). Average 3 navigator contacts; 1.8 telehealth visits scheduled; 1.3 completed.",
        "Quantitative KPI highlights with %/#; qualitative themes with brief quote": "Completion rate for scheduled telehealth visits rose from 62% to 71% (+9 points; n=3,012 visits). No-show rate fell from 28% to 16% (n=1,420). 57% moved up \u22651 PAM level (n=612). \u201cHaving someone show me how to click in made all the difference.\u201d \u2014 Client C-089 (consented).",
        "Most actionable next steps": [
          "Add evening navigator hours (Mon\u2013Thu until 8 pm) by Q1 2025",
          "Integrate bilingual text reminders and ASL interpreter scheduling by Q2 2025",
          "Deploy three additional signal boosters to library private rooms by May 2025"
        ],
        "Balanced summary; what worked; what to improve": "Navigator coaching and device lending improved visit completion and activation. Gaps persist among seniors (65+) and those >30 miles from clinics due to broadband instability and comfort with technology.",
        "Brief aims; core assumptions": "Hands-on tech support and stable access reduce missed visits and increase patient readiness for telehealth.",
        "Age/grade; geography; barriers addressed": "Adults and seniors in remote counties; barriers include connectivity, device access, digital literacy, and transportation backup when telehealth fails.",
        "What, how often, by whom; training/credentials": "Navigator calls before every telehealth appointment; device lending up to 90 days; tech coaching sessions; staff trained in HIPAA and chronic care protocols.",
        "TEAM SIZE/RESOURCES; partnerships; budget range": "18 FTE; ARH, libraries, UK Telehealth Lab partnerships; $600K budget.",
        "Relevant policy/school-year cycles; community factors": "State policy allowed telehealth parity payments; flood recovery and periodic power outages affected connectivity.",
        "Appendix reference": "Appendix A: Logic model; Appendix B: Instruments; Appendix C: Data tables",
        "YEAR": 2024,
        "PROGRAM": "TeleCare Connect",
        "#": 1420,
        "KEY ACTIVITIES": [
          "Telehealth readiness screening",
          "Navigator pre-visit coaching and reminders",
          "Device lending (tablets + data)",
          "Library private room reservations",
          "Broadband mapping and troubleshooting"
        ],
        "OUTCOMES": [
          {
            "name": "Completed telehealth visits",
            "definition": "Proportion of scheduled telehealth visits that are completed among enrolled patients.",
            "kpis": [
              {
                "indicator": "Telehealth completion rate (%)",
                "target": 75,
                "actual": 71,
                "%_achieved": 95,
                "data_source": "EHR attendance export",
                "notes": "Pre 62% \u2192 Post 71% (+9 points)"
              },
              {
                "indicator": "# completed telehealth visits",
                "target": 2200,
                "actual": 2120,
                "%_achieved": 96,
                "data_source": "EHR attendance export",
                "notes": "Across 1,420 patients"
              }
            ],
            "baseline": 62,
            "endline": 71,
            "n": 3012,
            "disaggregation": {
              "Distance_to_clinic": {
                ">30_miles_completion_rate": 66,
                "\u226430_miles_completion_rate": 73
              },
              "Age": {
                "65_plus_completion_rate": 68,
                "Under_65_completion_rate": 72
              },
              "Insurance": {
                "Medicaid_completion_rate": 70,
                "Medicare_completion_rate": 69,
                "Commercial_completion_rate": 74
              }
            },
            "themes": [
              "Hands-on device coaching reduced login failures.",
              "Library private rooms increased privacy and confidence."
            ],
            "quotes": [
              {
                "text": "Having someone show me how to click in made all the difference.",
                "id": "C-089",
                "consent": "Yes"
              }
            ],
            "equity_gap_analysis": "Seniors (65+) and those >30 miles had lower completion. Drivers: connectivity instability and tech comfort. Action: in-home setup visits for 65+ starting March 2025; expanded signal boosters in three libraries.",
            "mixed_negative_results": {
              "what_we_learned": "Completion still below 75% target.",
              "why_this_matters": "Missed care exacerbates chronic disease complications.",
              "what_we_are_changing": "Evening navigator hours and pre-visit test calls for all first-time users (Q1 2025)."
            },
            "evidence_tags": [
              "EHR attendance export",
              "Navigator log audit",
              "Interview: Clinic Manager #2"
            ]
          },
          {
            "name": "Reduced no-show rates",
            "definition": "No-show rate for scheduled clinic and telehealth visits among enrolled patients.",
            "kpis": [
              {
                "indicator": "No-show rate (%)",
                "target": 18,
                "actual": 16,
                "%_achieved": 112,
                "data_source": "EHR scheduling/attendance",
                "notes": "Pre 28% \u2192 Post 16% (\u221212 points)"
              }
            ],
            "baseline": 28,
            "endline": 16,
            "n": 1420,
            "disaggregation": {
              "Distance_to_clinic": {
                ">30_miles_no_show": 18,
                "\u226430_miles_no_show": 15
              },
              "Language": {
                "Spanish_no_show": 22,
                "English_no_show": 16
              }
            },
            "themes": [
              "Reminder texts reduced day-of no-shows.",
              "Backup plan for in-person conversion helped during broadband outages."
            ],
            "quotes": [
              {
                "text": "If the video fails, they switch me to a call right away\u2014no more missing the doctor.",
                "id": "C-231",
                "consent": "Yes"
              }
            ],
            "equity_gap_analysis": "Spanish speakers underrepresented and higher no-shows (22%). Plan to hire bilingual navigator and integrate interpreter scheduling by Q2 2025.",
            "mixed_negative_results": {
              "what_we_learned": "Language access gaps persist.",
              "why_this_matters": "Lower engagement risks widening disparities.",
              "what_we_are_changing": "Bilingual navigator hire approved; Spanish/English automated reminders (Q2 2025)."
            },
            "evidence_tags": [
              "EHR attendance",
              "Navigator logs",
              "Focus Group: Library Staff"
            ]
          },
          {
            "name": "Patient activation",
            "definition": "Patient Activation Measure (PAM-10) level change among participants with matched surveys.",
            "kpis": [
              {
                "indicator": "% moving up \u22651 PAM level",
                "target": 60,
                "actual": 57,
                "%_achieved": 95,
                "data_source": "PAM-10 survey",
                "notes": "Matched n=612"
              },
              {
                "indicator": "Mean PAM level",
                "target": 2.5,
                "actual": 2.5,
                "%_achieved": 100,
                "data_source": "PAM-10 survey",
                "notes": "Baseline 2.1 \u2192 Endline 2.5"
              }
            ],
            "baseline": 2.1,
            "endline": 2.5,
            "n": 612,
            "disaggregation": {
              "Age": {
                "65_plus_gain_levels": 0.3,
                "Under_65_gain_levels": 0.5
              },
              "Insurance": {
                "Medicaid_gain_levels": 0.5,
                "Medicare_gain_levels": 0.3
              }
            },
            "themes": [
              "Simple checklists increased confidence logging in.",
              "Printed instructions helpful for low digital literacy."
            ],
            "quotes": [
              {
                "text": "The step-by-step sheet stayed by my computer. I don\u2019t panic anymore.",
                "id": "C-477",
                "consent": "Yes"
              }
            ],
            "equity_gap_analysis": "Seniors advanced less in activation. Action: add in-home first-session setup and family caregiver coaching (Q2 2025).",
            "mixed_negative_results": {
              "what_we_learned": "Activation gains fell short by 3 points.",
              "why_this_matters": "Lower self-efficacy predicts future missed care.",
              "what_we_are_changing": "Navigator script revised with teach-back method, starting March 2025."
            },
            "evidence_tags": [
              "PAM-10",
              "Navigator call audit",
              "Interview: Navigator Lead"
            ]
          }
        ],
        "Evaluation questions": [
          "To what extent did telehealth completion rates improve among enrolled patients?",
          "Which navigation components (coaching, device lending, reminders) contributed most to reduced no-shows?",
          "For which subgroups (age 65+, >30 miles) did outcomes lag, and why?",
          "What program adaptations could close observed gaps within existing resources?"
        ],
        "Design/approach": "Pre-post cohort analysis; contribution not attribution; no comparison group; linkage of EHR and navigator logs.",
        "DATA SOURCES: surveys, interviews, focus groups, admin records, observations; instrument names": "EHR exports; Salesforce navigator logs; PAM-10; post-visit survey; key informant interview guide.",
        "Sampling and timing": "All enrolled patients; matched PAM-10 n=612 (43% of enrolled). Quarterly EHR pulls with month-end refresh.",
        "Data quality checks": "10% random audit of navigator logs; MRN-based de-duplication; crosswalk validation between EHR and Salesforce.",
        "Consent process; privacy; IRB status if applicable": "Consent via phone script; BAA with partners; HIPAA-compliant storage; IRB not required.",
        "Whose voices shaped questions? Any community reviewers? Accessibility considerations": "Patient Advisory Council (8 members) reviewed tools; large-print guides; ASL interpreter scheduling as needed.",
        "In plain language: brief description of indicators and how collected": "We tracked whether scheduled telehealth visits happened, if people missed appointments, and if people felt more ready to manage their care.",
        "Define; list KPIs and targets": "See OUTCOMES: completion rate, no-show rate, and PAM level change with targets and actuals.",
        "Which components likely drove change, for whom, and why": "Pre-visit coaching and simple checklists boosted confidence; device lending removed access barriers.",
        "How quantitative and qualitative converge/diverge": "EHR improvements matched navigator reports; interviews highlighted broadband issues explaining subgroup gaps.",
        "School calendar, transportation, policy shifts": "Telehealth parity policy supported clinic supply; storm-related outages reduced completion in Feb 2024.",
        "What was unexpected and how we validated it": "High success in library rooms compared to home; confirmed by speed test logs and appointment completion timestamps.",
        "Missingness, self-report bias": "PAM-10 nonresponse among oldest patients may bias activation upward; sensitivity checks conducted.",
        "Design constraints: No comparison group; short follow-up window": "No counterfactual; 6\u20139 month average exposure.",
        "All quotes used with explicit permission; data stored securely": "Yes \u2014 consent logged; encrypted server.",
        "participant reviewers; co-interpretation sessions": "Patient Advisory Council reviewed preliminary charts in July 2024.",
        "Caption variables example": {
          "X": 9,
          "OUTCOME": "Telehealth completion rate (%)",
          "BASELINE": 62,
          "ENDLINE": 71,
          "N": 3012
        },
        "AUTHOR NAME/TITLE": "Dana Whitaker, Director of Programs",
        "EVALUATOR NAME/ORGANIZATION, if external": "Bluegrass Evaluation Collaborative, LLC",
        "DATE": "2024-08-15",
        "PRIMARY/SECONDARY/FUNDERS-BOARD": "Primary: MHAN operations and navigator teams; Secondary: ARH clinics and libraries; Funders/Board: KY Cabinet for Health and Family Services, Anthem Medicaid, MHAN Board",
        "BRACKETS": "Use [ ] to indicate fill-in prompts throughout the template"
      }
    },
    {
      "id": "scenario_3",
      "name": "Large Established Org",
      "description": "Established refugee resettlement agency providing workforce development, ESL, and credentialing support across the Seattle metro.",
      "values": {
        "ORGANIZATION NAME": "Pacific Horizons Refugee Services (PHRS)",
        "PROGRAM NAME": "Career Pathways for New Americans",
        "REPORT PERIOD": "January 1\u2013December 31, 2024",
        "GEOGRAPHY": "King County, Washington (Seattle, Kent, Tukwila, Burien, Renton)",
        "TONE": "BALANCED",
        "BALANCED (default) | FORMAL | WARM": "BALANCED",
        "PAGE TARGET if specified; otherwise 10\u201325 pages": "18\u201322 pages",
        "Primary audience and uses": "Program leadership and employment specialists to guide continuous quality improvement and 2025 cohort design.",
        "Secondary audience and intended uses": "Employer partners and community colleges to align training slots, hiring cohorts, and credential evaluation timelines.",
        "Funders/Board version needed?": "Yes \u2014 U.S. Office of Refugee Resettlement (ORR), WA Department of Commerce, Ballmer Group; summary for PHRS Board.",
        "FUNDERS/BOARD if applicable": "ORR; Washington Department of Commerce; Ballmer Group; PHRS Board of Directors",
        "Key demographics for equity breakdowns": [
          "Country/region of origin",
          "Primary language",
          "Gender",
          "Age",
          "Education level",
          "Immigration status (Refugee/Asylee/SIV/Parolee)",
          "Time since arrival (\u226424 months, >24 months)"
        ],
        "Main data sources available": [
          "Program administrative database (ETO)",
          "Washington State wage/unemployment insurance (UI) records",
          "Intake and exit surveys (English + 7 languages)",
          "Employer satisfaction survey",
          "Focus groups with clients (Arabic, Dari, Somali, Ukrainian)",
          "Case notes and credential evaluation outcomes (WES)"
        ],
        "TEAM SIZE/RESOURCES": "65 staff across workforce and ESL; Evaluation Unit (3 analysts); 120 volunteer mentors; program budget $3.2M",
        "Partnerships": [
          "Seattle Colleges and Highline College",
          "World Education Services (WES)",
          "75 employer partners (healthcare, logistics, IT, hospitality)",
          "Seattle-King County Workforce Development Council"
        ],
        "Budget range": "$3.2M program; organizational budget ~$15M",
        "Program aims; target population; high-level needs/context": "Support newly arrived refugees and asylees to secure quality employment aligned with skills through ESL, credential evaluation, and employer partnerships.",
        "# served; eligibility; participation intensity/dosage; key demographics": "1,085 clients (54% women) from 46 countries; top languages Arabic, Dari, Somali, Ukrainian. Eligibility: Refugee/asylee/SIV or humanitarian parole, within 5 years of arrival. Average 14 weeks of services; 48 ESL instructional hours; median 6 career coaching sessions.",
        "Quantitative KPI highlights with %/#; qualitative themes with brief quote": "Job placement within 90 days: 63% (target 60%). 90-day retention: 72% of placements. Median starting wage: $21.80. Credential equivalency achieved for 214 clients. \u201cMy mentor helped me translate my nursing experience to U.S. terms.\u201d \u2014 Client U-221 (consented).",
        "Most actionable next steps": [
          "Pilot childcare stipend for job seekers (Q2 2025)",
          "Increase evening ESL sections by 25% (Q2 2025)",
          "Add employer cohort in healthcare support roles (Q3 2025)"
        ],
        "Balanced summary; what worked; what to improve": "Strong placement and retention with robust employer partnerships. Wage and placement gaps persist for women and clients with limited English; credential evaluation backlogs slow sector-aligned hiring.",
        "Brief aims; core assumptions": "Contextualized ESL, targeted coaching, and employer cohorts reduce barriers and accelerate quality job entry.",
        "Age/grade; geography; barriers addressed": "Adults (18\u201364) across King County; barriers include English proficiency, childcare, credential recognition, limited networks, and transportation costs.",
        "What, how often, by whom; training/credentials": "Contextualized ESL (4\u20136 hrs/week), career coaching (biweekly), credential evaluation support, employer cohort hiring events, paid work experiences; staff are certified employment specialists and ESL instructors.",
        "TEAM SIZE/RESOURCES; partnerships; budget range": "65 staff; 120 mentors; colleges and 75 employers; $3.2M budget.",
        "Relevant policy/school-year cycles; community factors": "Seattle minimum wage increases; tech sector volatility; growing demand in healthcare support roles; new arrivals from Ukraine and Afghanistan.",
        "Appendix reference": "Appendix A: Logic model; Appendix B: Instruments; Appendix C: Indicator definitions",
        "YEAR": 2024,
        "PROGRAM": "Career Pathways for New Americans",
        "#": 1085,
        "KEY ACTIVITIES": [
          "Contextualized ESL and bridge courses",
          "Career coaching and job readiness workshops",
          "Credential evaluation and licensing navigation",
          "Employer cohort hiring and paid work experience",
          "Mentor matching and retention coaching"
        ],
        "OUTCOMES": [
          {
            "name": "Job placement within 90 days",
            "definition": "Share of enrolled job-seeking clients placed within 90 days of intake.",
            "kpis": [
              {
                "indicator": "% placed within 90 days",
                "target": 60,
                "actual": 63,
                "%_achieved": 105,
                "data_source": "ETO admin data; employer verification",
                "notes": "Cohort-wide, includes unsubsidized and subsidized placements"
              }
            ],
            "baseline": null,
            "endline": 63,
            "n": 1085,
            "disaggregation": {
              "Gender": {
                "Women": 59,
                "Men": 67
              },
              "English_proficiency": {
                "Limited": 58,
                "Advanced": 69
              },
              "Nationality_examples": {
                "Ukrainian": 65,
                "Afghan": 60,
                "Somali": 61
              }
            },
            "themes": [
              "Employer cohorts accelerated hiring decisions.",
              "Mentorship improved application quality and interview confidence."
            ],
            "quotes": [
              {
                "text": "My mentor helped me translate my nursing experience to U.S. terms.",
                "id": "U-221",
                "consent": "Yes"
              }
            ],
            "equity_gap_analysis": "Women placed at 59% vs 67% for men; childcare and scheduling cited. Action: childcare stipend pilot in Q2 2025; advocate flexible shifts with employer partners.",
            "mixed_negative_results": {
              "what_we_learned": "Limited English proficiency slowed sector-aligned placement.",
              "why_this_matters": "Delays can push clients into lower-wage jobs below skill level.",
              "what_we_are_changing": "Add evening ESL and targeted sector vocabulary modules (Q2 2025)."
            },
            "evidence_tags": [
              "Admin placement record",
              "Employer survey",
              "Focus Group: ESL Cohort B"
            ]
          },
          {
            "name": "90-day job retention",
            "definition": "Share of placed clients retained at 90 days post-start.",
            "kpis": [
              {
                "indicator": "% retained at 90 days",
                "target": 70,
                "actual": 72,
                "%_achieved": 103,
                "data_source": "Employer verification; case notes",
                "notes": "n=678 placed clients"
              }
            ],
            "baseline": null,
            "endline": 72,
            "n": 678,
            "disaggregation": {
              "Industry": {
                "Healthcare_support": 76,
                "Warehouse_logistics": 68,
                "IT_support": 81,
                "Hospitality": 70
              }
            },
            "themes": [
              "Supervisor check-ins and mentor support reduced early churn.",
              "Transportation subsidies improved punctuality in the first month."
            ],
            "quotes": [
              {
                "text": "Weekly check-ins helped me solve small issues before they got big.",
                "id": "R-310",
                "consent": "Yes"
              }
            ],
            "equity_gap_analysis": "Lower retention in warehouse roles suggests mismatch with client expectations and schedules. Action: strengthen job preview and coach employer leads on shift flexibility.",
            "mixed_negative_results": {
              "what_we_learned": "Retention lowest in warehouse/logistics.",
              "why_this_matters": "Early attrition disrupts income stability.",
              "what_we_are_changing": "Expand retention coaching to 120 days for warehouse placements (Q3 2025)."
            },
            "evidence_tags": [
              "Employer verification",
              "Case notes",
              "Survey Q12 (mentor helpfulness)"
            ]
          },
          {
            "name": "Wages and credential utilization",
            "definition": "Starting wages and credential recognition outcomes for clients with prior professional training.",
            "kpis": [
              {
                "indicator": "Median starting wage (USD)",
                "target": 21.0,
                "actual": 21.8,
                "%_achieved": 104,
                "data_source": "Admin payroll verification; WA UI wage file (lagged)",
                "notes": "County minimum wage context considered"
              },
              {
                "indicator": "# clients with credential equivalency",
                "target": 200,
                "actual": 214,
                "%_achieved": 107,
                "data_source": "WES credential outcomes",
                "notes": "Nursing, engineering, and teaching most common"
              }
            ],
            "baseline": 17.4,
            "endline": 21.1,
            "n": 312,
            "disaggregation": {
              "Gender_median_wage_USD": {
                "Women": 20.1,
                "Men": 23.0
              },
              "English_proficiency_median_USD": {
                "Limited": 20.4,
                "Advanced": 23.2
              }
            },
            "themes": [
              "Credential evaluation boosted wage offers in healthcare.",
              "Negotiation coaching correlated with higher offers in IT support."
            ],
            "quotes": [
              {
                "text": "Once my degree was recognized, employers took my application seriously.",
                "id": "D-144",
                "consent": "Yes"
              }
            ],
            "equity_gap_analysis": "Gender wage gap persists ($2.90). Action: salary negotiation workshops tailored for women; advocate childcare supports with employers.",
            "mixed_negative_results": {
              "what_we_learned": "Credential evaluation timelines caused job start delays.",
              "why_this_matters": "Delays risk clients accepting lower-wage stopgap jobs.",
              "what_we_are_changing": "Batch WES submissions monthly and pre-screen credential pathways at intake (Q1 2025)."
            },
            "evidence_tags": [
              "WA UI wage file",
              "WES outcomes",
              "Employer survey"
            ]
          }
        ],
        "Evaluation questions": [
          "To what extent did clients achieve rapid, quality employment and retention?",
          "Which program components (ESL, mentoring, employer cohorts, credentialing) most contributed to outcomes?",
          "Where do equity gaps persist (gender, language, origin), and what are feasible changes to close them?",
          "How do wage outcomes compare across sectors and demographics?"
        ],
        "Design/approach": "Cohort tracking with administrative data; contribution not attribution; wage verification via UI records where available.",
        "DATA SOURCES: surveys, interviews, focus groups, admin records, observations; instrument names": "ETO admin logs; WA UI wage file; employer satisfaction survey; multilingual intake/exit surveys; focus group guides (Arabic/Dari/Somali/Ukrainian).",
        "Sampling and timing": "All 1,085 clients tracked; wage verification available for 71% due to UI data lag; focus groups n=42 across four languages (Oct\u2013Nov 2024).",
        "Data quality checks": "Data validation rules in ETO; 5% random case note audit; employer verification cross-check; UI match rate reporting.",
        "Consent process; privacy; IRB status if applicable": "Written consent in 7 languages; privacy statement aligned with ORR; quotes used only with written permission; IRB not required.",
        "Whose voices shaped questions? Any community reviewers? Accessibility considerations": "Client Advisory Council (12 members) co-designed survey items; interpreters and childcare provided at focus groups.",
        "In plain language: brief description of indicators and how collected": "We checked how many people got jobs, stayed in them for 90 days, how much they earned starting out, and whether their past degrees were recognized.",
        "Define; list KPIs and targets": "Placement within 90 days (target 60%); 90-day retention (70%); median starting wage ($21.00); credential equivalencies (200).",
        "Which components likely drove change, for whom, and why": "Employer cohort hiring and mentor support accelerated placements; credentialing plus sector ESL improved wages for healthcare-bound clients.",
        "How quantitative and qualitative converge/diverge": "Admin data matches employer feedback on readiness; clients reported childcare and language as persistent barriers explaining observed gaps.",
        "School calendar, transportation, policy shifts": "Higher minimum wage and transit expansions aided outcomes; tech sector layoffs shifted some clients to IT support pathways.",
        "What was unexpected and how we validated it": "Faster wage gains in healthcare support roles than expected; validated by employer wage surveys and UI files.",
        "Missingness, self-report bias": "UI wage data missing for 29% (recent arrivals or SSN gaps); self-reported wages cross-checked when possible.",
        "Design constraints: No comparison group; short follow-up window": "No counterfactual; most retention measured only to 90 days.",
        "All quotes used with explicit permission; data stored securely": "Yes \u2014 documented multi-language consents; secure servers.",
        "participant reviewers; co-interpretation sessions": "Two co-interpretation workshops with staff and Client Advisory Council (December 2024).",
        "Caption variables example": {
          "X": 3.7,
          "OUTCOME": "Median starting wage (USD) for clients with prior US employment",
          "BASELINE": 17.4,
          "ENDLINE": 21.1,
          "N": 312
        },
        "AUTHOR NAME/TITLE": "Lina Nguyen, Senior Evaluation Manager",
        "EVALUATOR NAME/ORGANIZATION, if external": "PHRS Impact & Learning Unit (internal)",
        "DATE": "2025-02-05",
        "PRIMARY/SECONDARY/FUNDERS-BOARD": "Primary: PHRS program leadership and employment specialists; Secondary: employer partners and community colleges; Funders/Board: ORR, WA Dept. of Commerce, Ballmer Group, PHRS Board",
        "BRACKETS": "Use [ ] to indicate fill-in prompts throughout the template"
      }
    }
  ],
  "outputs": [
    {
      "scenario_id": "scenario_1",
      "model": "gemini",
      "model_display_name": "Gemini 2.5 Flash",
      "content": "Here is the comprehensive evaluation report template for Southside Fresh Food Collective (SFFC)\u2019s Corner Store Produce Vouchers & Nutrition Circles, designed with a WARM tone and incorporating all specified requirements.\n\n---\n\n**[DOCUMENT TITLE: Southside Fresh Food Collective (SFFC) Corner Store Produce Vouchers & Nutrition Circles Program Evaluation Report, 2024]**\n\n**Prepared by:** Jada Morris, Program Manager\n**In collaboration with:** Marisol Reyes, MPH (contract evaluator)\n**Date:** 2025-01-30\n**Report Covers:** January 1\u2013December 31, 2024\n**Geographic Scope:** Chicago South Side (Englewood, Washington Park, Bronzeville, Woodlawn)\n\n**Audiences and Uses:**\n*   **Primary Audience:** SFFC program staff and Community Advisory Council to improve program delivery, inform annual planning, and strengthen community relationships.\n*   **Secondary Audience:** Partner corner store owners, SFFC volunteers, and community partners to foster collaboration and share impact.\n*   **Funders/Board:** Chicago Community Trust (Food Equity Fund), Aldi Community Giving, and SFFC Board of Directors to demonstrate accountability, report on grant objectives, and inform future funding decisions.\n\n---\n\n## 1. Executive Summary\n\n**(350\u2013600 words)**\n\nThis section tells busy readers what changed, for whom, and what we\u2019ll do next.\n\nIn 2024, Southside Fresh Food Collective (SFFC)\u2019s Corner Store Produce Vouchers & Nutrition Circles empowered Chicago South Side residents to access fresh, healthy food right in their neighborhoods. Our program focused on increasing affordable access to fresh produce and building food skills among low-income households facing high rates of diet-related disease and limited healthy retail options in Englewood, Washington Park, Bronzeville, and Woodlawn. We successfully engaged **320 households**, with **76% identifying as SNAP-eligible, 61% as Black, 29% as Latinx, and 23% as Spanish-speaking**, ensuring we reached those most in need. Participants received up to six monthly $20 produce vouchers and engaged in four peer-led nutrition circles per cohort, with optional cooking demonstrations complementing the learning.\n\nOur evaluation found heartening evidence of positive change! On average, participants increased their fruit and vegetable consumption from **2.3 to 3.5 servings per day (+1.2 servings)**, a significant step toward healthier eating habits (n=246). We also saw a meaningful reduction in household food insecurity, which dropped from **68% at baseline to 52% at the end of the program** (n=238), indicating that the vouchers provided crucial support for families. The program's practical design shone through with a strong **83% voucher redemption rate** (1,587 of 1,920 issued vouchers), reflecting both participant engagement and the accessibility of our partner stores. As one participant shared, \u201c*The Wednesday text about greens reminded me to stop by the store*.\u201d \u2014 Participant P-114. This highlights how targeted communication can effectively bridge intention and action.\n\nWhile overall progress was strong, we learned that participation and outcomes lagged slightly for Spanish-speaking participants and older adults. Access barriers, such as limited evening store hours and transportation challenges, likely played a role. Despite these points for growth, the program effectively combined financial incentives with invaluable peer-to-peer support, leading to increased produce intake and reduced food insecurity.\n\nLooking ahead, we recommend:\n*   **Add a Spanish-speaking co-facilitator for all nutrition circles by March 2025**, ensuring culturally and linguistically appropriate support.\n*   **Pilot extended evening store hours with two partner stores in Q2 2025**, improving access for working families.\n*   **Launch a \u2018produce-of-the-month\u2019 text campaign with quick, bilingual recipe cards in Q1 2025** to boost engagement and culinary skills.\n\nWe are committed to continuous learning and adaptation, ensuring that the Corner Store Produce Vouchers & Nutrition Circles program truly serves the diverse needs of our South Side community.\n\n**How to adapt for funders/board:** Lead with outcomes tied to grant objectives; keep to one page; include grant KPIs and cost-per-outcome if available.\n\n---\n\n## 2. Program Overview\n\n**(300\u2013450 words)**\n\nIn 2024, the Corner Store Produce Vouchers & Nutrition Circles program was designed to make healthy eating easier and more accessible for families in Chicago\u2019s South Side. We believe that when healthy produce is affordable and available close to home, and people have the knowledge and support to use it, they will naturally eat more fruits and vegetables, leading to healthier lives.\n\nOur program\u2019s **goals and theory of change** are rooted in the idea that financial incentives (vouchers) paired with peer learning (nutrition circles) and improved access at nearby corner stores will directly increase healthy purchasing and consumption. We know that many residents face barriers like the high cost of fresh food, limited options in local stores, inconvenient store hours, and a lack of culturally relevant produce.\n\nThe **target population and eligibility** for our program included adults 18 and older, and caregivers, residing in the defined South Side neighborhoods (Englewood, Washington Park, Bronzeville, Woodlawn), with household incomes at or below 200% of the Federal Poverty Level.\n\nKey **activities and dosage** delivered in 2024 included:\n*   **Monthly $20 produce vouchers** (QR-coded for easy redemption).\n*   **Twice-monthly nutrition circles** led by certified Community Health Workers, fostering a supportive learning environment.\n*   **Store-owner coaching** on produce handling, stocking, and display to ensure quality and variety.\n*   **Quarterly cooking demonstrations** by trained volunteers with food safety certification, offering practical skills and delicious ideas.\n*   **Bilingual text nudges** providing tips and store specials.\n\nOur dedicated **staffing and resources** for this program included 4 full-time equivalent staff members (with 0.5 FTE dedicated to evaluation), supported by 35 passionate volunteers. We partnered with 7 local corner stores and 3 essential community organizations, operating on a total program budget of $180,000.\n\nThe **context** for our work is shaped by local realities, including persistent inflation that impacts produce costs, ongoing corner-store closures affecting neighborhood access, and supportive city-wide initiatives like the Healthy Corner Store Initiative that align with our goals. We recognize that our work happens within this larger ecosystem.\n\nFor a deeper dive into our program design, please refer to **Appendix A: Logic Model** for a visual representation of how our activities lead to desired outcomes, and **Appendix B: Instruments** for details on our data collection tools.\n\nHere\u2019s a snapshot of our program\u2019s key outcomes and how we measured success in 2024:\n\nSFFC Corner Store Produce Vouchers & Nutrition Circles Program Outcomes \u2013 2024\n\n| Outcome                                 | Definition                                                                     | Baseline | Endline | N   |\n| :-------------------------------------- | :----------------------------------------------------------------------------- | :------- | :------ | :-- |\n| **Increased fruit and vegetable consumption** | Daily servings of fruits and vegetables among enrolled adults.                 | 2.3      | 3.5     | 246 |\n| **Reduced household food insecurity**   | Household-level food security measured via USDA 6-Item module.                 | 68%      | 52%     | 238 |\n| **Store healthy inventory**             | Number of partner stores meeting SFFC healthy stocking standard (\u226510 fresh produce SKUs). | 7.2      | 9.8     | 7   |\n\n**How to adapt for funders/board:** Align goals and activities with funded objectives and approved budget. Highlight how resources were efficiently utilized to achieve these outcomes.\n\n---\n\n## 3. Evaluation Questions & Methodology\n\n**(300\u2013500 words)**\n\nThis section explains how we gathered information to understand if and how the program is working. We wanted to make sure our findings are trustworthy and truly reflect the experiences of our community.\n\nOur evaluation focused on answering these key questions:\n1.  To what extent did participants increase their fruit and vegetable consumption and improve food insecurity levels after participating in the program?\n2.  Which program components (vouchers, nutrition circles, cooking demos, text nudges) were most and least helpful in driving healthy food choices for different participant groups?\n3.  How did the program influence the availability and variety of fresh produce in partner corner stores?\n4.  What access barriers or facilitators emerged for participants when trying to use vouchers and engage with partner stores?\n5.  What unintended positive or negative consequences resulted from the program for participants or partner stores?\n\nOur **design and approach** utilized a pre-post cohort tracking methodology, allowing us to observe changes in participant outcomes over time. We emphasize \"contribution, not attribution,\" acknowledging that while our program contributes to positive changes, other factors in participants' lives also play a role. We did not employ a separate comparison group, which is a common approach for community-based program evaluations given resource constraints.\n\nWe collected data from several crucial **data sources**:\n*   **SFFC Intake & Follow-Up Survey v2 (English/Spanish):** Administered at enrollment and program completion, capturing demographics, fruit/vegetable consumption (24-hour recall adaptation), and program impact.\n*   **USDA 6-Item Food Security Survey Module:** Embedded in our surveys to measure changes in household food insecurity.\n*   **Corner Store Audit Checklist:** Completed quarterly by SFFC staff to assess produce stocking, variety, and display in partner stores.\n*   **Voucher Redemption Logs:** QR scan data provided detailed, real-time insights into voucher usage, frequency, and products purchased.\n*   **Twilio SMS Logs:** Analysis of text message engagement and message types.\n*   **Focus Groups:** Two semi-structured focus groups with participants (one English-speaking, one Spanish-speaking) to gather in-depth qualitative insights on experiences, challenges, and successes.\n\n**Sampling and timing:** We aimed to survey all enrolled participants. Our intake survey (n=320) was completed upon enrollment. Follow-up surveys were conducted between [DATE] and [DATE] with a\n**77% response rate (n=246 matched pre-post data for consumption; n=238 for food security data)**. Store audits were conducted quarterly in all 7 partner stores. Focus groups each included [NUMBER] participants and were held in [MONTH].\n\nTo ensure **data quality**, we conducted regular checks, including a review for missing data, spot audits of survey entries against paper forms, and thorough data cleaning steps. Reliability checks for the store audit checklist were performed among staff.\n\nOur approach to **ethics and consent** was paramount. All participants provided written informed consent at enrollment, understanding how their data would be used and their right to withdraw. We ensured all analysis was de-identified, and all quotes are attributed using anonymous IDs with explicit consent. All data is stored securely on encrypted drives. As a program evaluation, formal IRB review was not required, but we adhered to the highest ethical standards.\n\nWe made conscious efforts to embed **equity and participation** throughout the evaluation. Our Community Advisory Council (comprising 12 diverse South Side residents) played a vital role, prioritizing key measures and helping shape survey questions to be culturally relevant. All surveys and focus group materials were provided in both English and Spanish. We offered childcare and $25 gift cards for focus group participants to remove barriers to participation and acknowledge their valuable time.\n\nIn plain language: We measured success by asking participants about their eating habits and experiences, tracking what they bought with the vouchers, checking what food was in the stores, and listening to their stories in groups.\n\n| Method                    | Sample/Response Rate                                                               | Timeline                                 | Purpose/Question(s) Informed                                                                 |\n| :------------------------ | :--------------------------------------------------------------------------------- | :--------------------------------------- | :------------------------------------------------------------------------------------------- |\n| SFFC Intake & Follow-Up Survey v2 (English/Spanish) | Intake: 320 participants (100%); Follow-up: 246 (77% of matched pairs)             | Enrollment, End of 4-month cohort        | Q1, Q2, Q4, Q5 (Consumption, Food Security, Program Value, Barriers)                         |\n| USDA 6-Item Module        | 238 matched pre-post pairs                                                         | Enrollment, End of 4-month cohort        | Q1 (Food Security)                                                                           |\n| Corner Store Audit Checklist | 7 stores, 4 audits each (n=28)                                                     | Quarterly (March, June, Sept, Dec)       | Q3 (Store Inventory)                                                                         |\n| Voucher Redemption Logs   | 1,587 of 1,920 issued vouchers redeemed (83%)                                      | Ongoing throughout program               | Q1, Q2, Q4 (Usage, Popularity of produce, Store choice, Access timing)                       |\n| Twilio SMS Logs           | All sent messages (approx. 12,000)                                                 | Ongoing throughout program               | Q2 (Effectiveness of nudges, Engagement patterns)                                            |\n| Focus Groups (2)          | 16 participants total (8 English, 8 Spanish)                                       | [Month, Year]                            | Q1, Q2, Q4, Q5 (Qualitative insights on all questions, lived experience)                     |\n\n**How to adapt for funders/board:** Keep design description concise, emphasize validity, consent, and alignment with grant indicators. Frame the methodology as rigorous and ethical.\n\n---\n\n## 4. Findings by Outcome Area\n\nThis section shares what we found! We\u2019ve broken it down by our main goals, showing both the numbers and the stories behind them.\n\n### Outcome Area 1: Increased fruit and vegetable consumption\n\n**Definition:** Daily servings of fruits and vegetables among enrolled adults.\n\n| Indicator                                   | Target | Actual | % Achieved | Data Source                    | Notes                                             |\n| :------------------------------------------ | :----- | :----- | :--------- | :----------------------------- | :------------------------------------------------ |\n| % of participants consuming \u22655 servings/day | 35%    | 31%    | 89%        | SFFC Survey Q5 (24-hr recall adaptation) | Matched pre-post sample; see Appendix D.          |\n| Average daily servings (mean)               | 3.4    | 3.5    | 103%       | SFFC Survey Q5                 | Baseline 2.3 \u2192 Endline 3.5 (from a matched n=246) |\n\n*   **Quantitative Results:** Participants showed a significant increase in average daily fruit and vegetable servings, rising from 2.3 servings at baseline to 3.5 servings at the program's conclusion (n=246). This represents a 52% increase in consumption. While we aimed for 35% of participants to reach 5 servings per day, 31% achieved this, demonstrating substantial progress toward a key health target.\n\n    **Visual Placeholder 1.1: Paired Bar Chart - Average Daily Fruit & Vegetable Servings (Pre vs. Post Program)**\n    *Caption: Participants showed a 52% improvement in fruit and vegetable consumption from baseline (2.3 servings/day) to endline (3.5 servings/day) (n=246).*\n\n    **Visual Placeholder 1.2: Simple Bar Chart - Percentage of Participants Consuming \u22655 Servings/Day (Target vs. Actual)**\n    *Caption: While falling slightly short of our target, 31% of participants achieved the daily recommendation of 5+ servings of fruits and vegetables, an increase from [BASELINE PERCENTAGE] at the start of the program (n=246).*\n\n*   **Qualitative Insights:** Participants often credited the nutrition circles and cooking demos for expanding their culinary repertoire and confidence.\n    *   **Themes:**\n        *   **Expanded Palates & Confidence:** Many participants tried new vegetables or fruits they hadn't purchased before, feeling more confident with preparation.\n        *   **Practicality of Vouchers:** The voucher system allowed for spontaneity and purchasing \"in-the-moment\" based on needs or desire.\n    *   **Quotes:**\n        *   \u201c*The Wednesday text about greens reminded me to stop by the store. I never thought I\u2019d be buying collards for a smoothie!*\u201d \u2014 P-114 (consented)\n        *   \u201c*Learning how to chop onions without crying was a game-changer. Now I use them in everything!*\u201d \u2014 P-198 (consented)\n        *   \u201c*My kids actually eat the kale now. The recipe from the demo was so good.*\u201d \u2014 P-072 (consented)\n    *   Evidence tags: Survey Q5, Workshop attendance sheet, Text log export, Focus Group 1\n\n*   **Equity Lens:**\n    *   **Disaggregation:**\n        *   Race/Ethnicity: Black participants saw average servings increase to 3.6, while Latinx participants increased to 3.4.\n        *   Language: English-speaking participants reached 3.6 average servings, compared to 3.3 for Spanish-speaking participants.\n        *   Household with Children: Households with children averaged 3.6 servings, while those without averaged 3.2.\n        *   ZIP Code: 60621: 3.6, 60637: 3.4, 60653: 3.3, 60615: 3.5.\n    *   Whose outcomes improved least? Spanish-speaking participants showed a smaller improvement in average daily servings. This gap highlights a potential area for targeted support. Possible drivers include a lag in fully translating all support materials, and fewer nutrition circles being conducted entirely in Spanish, leading to less engagement or comprehension.\n    *   Actionable responses? SFFC aims to address this directly by improving language access.\n\n*   **Mixed/Negative Results Framing:**\n    *   **What we learned:** Improvements in fruit and vegetable intake were smaller among Spanish-speaking participants compared to English-speaking participants.\n    *   **Why this matters:** Language and cultural accessibility are crucial for equitable health outcomes. If materials or discussions are not fully comprehensible or relevant, it creates an unnecessary barrier to participation and tangible health gains for a significant portion of our community.\n    *   **What we\u2019re changing:** We are actively recruiting and onboarding a dedicated bilingual (Spanish/English) facilitator to co-lead all nutrition circles by March 2025. Additionally, we will prioritize translating all text nudges and recipe cards into Spanish immediately, with full implementation by Q1 2025, ensuring no information gap.\n\n*   Evidence tags: Survey Q5, Workshop attendance sheet, Text log export\n\n### Outcome Area 2: Reduced household food insecurity\n\n**Definition:** Household-level food security measured via USDA 6-Item module.\n\n| Indicator                                   | Target | Actual | % Achieved | Data Source                    | Notes                                                       |\n| :------------------------------------------ | :----- | :----- | :--------- | :----------------------------- | :---------------------------------------------------------- |\n| % households \u2018food secure\u2019 at endline       | 55%    | 48%    | 87%        | USDA 6-Item                    | Movement from high/very low to marginal/secure.             |\n| Food insecurity rate (any insecurity) (`from 68% at baseline`) | 55%    | 52%    | 106%       | USDA 6-Item                    | Baseline 68% \u2192 Endline 52% (\u221216 points, from a matched n=238) |\n\n*   **Quantitative Results:** The program significantly reduced household food insecurity among participants. At baseline, 68% reported some level of food insecurity, which dropped to 52% by endline (n=238), a notable 16-point decrease. While the target for households to be fully 'food secure' was 55%, we reached 48%, still a substantial achievement given baseline rates.\n\n    **Visual Placeholder 2.1: Simple Bar Chart - Food Insecurity Rate (Pre vs. Post Program)**\n    *Caption: The program contributed to a 16-point decrease in overall food insecurity among participants, from 68% at baseline to 52% at endline (n=238).*\n\n    **Visual Placeholder 2.2: Stacked Bar Chart - Percentage of Households by Food Security Status (Pre vs. Post Program)**\n    *Caption: The number of households experiencing high or very low food security significantly decreased, with a corresponding increase in those classified as marginally or fully food secure (n=238).*\n\n*   **Qualitative Insights:** Participants frequently highlighted the vouchers\u2019 role in managing monthly budgets, especially when other resources ran thin.\n    *   **Themes:**\n        *   **\"Bridging the Gap\":** Vouchers were often seen as critical support during the last week of the month when other grocery budgets were depleted.\n        *   **Stress Reduction:** Knowing consistent healthy food access was available reduced the mental burden of finding affordable options.\n    *   **Quotes:**\n        *   \u201c*The $20 kept us from skipping dinner that last week. It made a real difference for peace of mind.*\u201d \u2014 P-207 (consented)\n        *   \u201c*It\u2019s not just the food, it\u2019s not having to worry so much about getting a healthy meal on the table for my kids. That\u2019s huge.*\u201d \u2014 P-091 (consented)\n    *   Evidence tags: USDA 6-Item, Store redemption logs, Focus Group 1\n\n*   **Equity Lens:**\n    *   **Disaggregation:**\n        *   Household with Children: 49% of households with children were food secure at endline.\n        *   SNAP Status: 51% of SNAP-enrolled households were food secure at endline, compared to 44% of households not on SNAP.\n        *   Age: 45% of participants 55+ were food secure at endline, compared to 49% of those 18-54.\n    *   Whose outcomes improved least? Older adults (55+) showed slightly less improvement in food security. This disparity may be linked to unique challenges such as mobility limitations, fixed incomes, and less flexibility with shopping times, which can impact frequent store visits.\n    *   Actionable responses? We are exploring community partnerships to address these specific needs for our senior populations.\n\n*   **Mixed/Negative Results Framing:**\n    *   **What we learned:** While overall food insecurity decreased, limited evening access at some partner stores remained a barrier for shift workers, hindering their ability to use vouchers efficiently.\n    *   **Why this matters:** If individuals cannot access the benefits at times that align with their work schedules, the program's full potential is not realized, disproportionately affecting those with demanding jobs. This limits choice and perpetuates an equity gap for working individuals.\n    *   **What we\u2019re changing:** In Q2 2025, two of our key partner stores will pilot extended evening hours (until 9 PM) on Wednesdays, a day identified as having high voucher redemption, to better accommodate participants with less flexible daytime schedules. We will monitor usage closely.\n\n*   Evidence tags: USDA 6-Item, Store redemption logs, Focus Group 1\n\n### Outcome Area 3: Store healthy inventory\n\n**Definition:** Number of partner stores meeting SFFC healthy stocking standard (\u226510 fresh produce SKUs).\n\n| Indicator                        | Target | Actual | % Achieved | Data Source         | Notes                                |\n| :------------------------------- | :----- | :----- | :----- | :------------------ | :----------------------------------- |\n| # of stores \u226510 SKUs             | 6      | 5      | 83%    | Store audit checklist | Quarterly audits by staff.           |\n| Average produce SKUs per store   | 10     | 9.8    | 98%    | Store audit checklist | Baseline 7.2 \u2192 Endline 9.8 (n=7)     |\n\n*   **Quantitative Results:** Our partner stores significantly increased their fresh produce inventory. The average number of produce SKUs (stock-keeping units) per store rose from 7.2 at baseline to 9.8 at endline (n=7), nearly reaching our target of 10. Five out of seven partner stores successfully met our target of stocking at least 10 different fresh produce items, an 83% achievement rate.\n\n    **Visual Placeholder 3.1: Simple Bar Chart - Average Produce SKUs Per Store (Pre vs. Post Program)**\n    *Caption: Partner stores increased their average produce SKUs by 36% (from 7.2 to 9.8) during the program period (n=7).*\n\n    **Visual Placeholder 3.2: Simple Bar Chart - Number of Stores Meeting \u226510 Produce SKUs Target**\n    *Caption: Five out of seven SFFC partner stores successfully met or exceeded the target of stocking 10 or more fresh produce SKUs.*\n\n*   **Qualitative Insights:** Store owners highlighted the importance of predictable demand and the physical space to expand offerings.\n    *   **Themes:**\n        *   **Microgrants Impact:** Small financial incentives for better refrigeration were key to expanding perishable offerings.\n        *   **Demand Confidence:** Increased and steady demand from voucher users boosted store owners' confidence in stocking a wider variety, reducing fear of spoilage.\n    *   **Quotes:**\n        *   \u201c*The small cooler let us try cilantro without it wilting in two days. Before, it was too risky.*\u201d \u2014 Store-03 (consented)\n        *   \u201c*Knowing people would buy the kale helped. I wouldn\u2019t have ordered it otherwise, just too much waste if it doesn't sell.*\u201d \u2014 Store-05 (consented)\n    *   Evidence tags: Store audit, Redemption logs, Observation checklist\n\n*   **Equity Lens:**\n    *   **Disaggregation:**\n        *   Store type: Independent bodegas averaged 9.5 SKUs, while franchise corner stores averaged 10.2 SKUs.\n    *   Whose outcomes improved least? Stores located in ZIP code 60653 lagged slightly in increasing their SKUs. Possible drivers include lower foot traffic, less visibility, or higher competition from other food sources, making it harder for owners to justify additional produce inventory.\n    *   Actionable responses? SFFC plans to initiate targeted marketing campaigns for these stores.\n\n*   **Mixed/Negative Results Framing:**\n    *   **What we learned:** Two partner stores fell short of the 10-SKU target due to persistent concerns about spoilage and managing perishable inventory.\n    *   **Why this matters:** Limited variety at these stores reduces participant choice and the cultural relevance of available produce, potentially impacting their overall consumption and program satisfaction. This also creates an equity gap if certain neighborhoods continue to have fewer options.\n    *   **What we\u2019re changing:** To mitigate spoilage risks and encourage greater variety, we will offer a $500 'spoilage offset' mini-grant to eligible stores and develop a 'produce-of-the-month' marketing campaign to drive predictable demand for specific items starting in Q2 2025.\n\n*   Evidence tags: Store audit, Redemption logs, Observation checklist\n\n---\n\n## 5. Discussion/Interpretation\n\n**(300\u2013500 words)**\n\nHere we make sense of why results look the way they do \u2014 connecting the dots between our activities and what we learned.\n\nThe 2024 evaluation shows a strong \"contribution not attribution\" narrative for the Corner Store Produce Vouchers & Nutrition Circles program. Our findings largely align with our **program theory**: the combination of financial incentives (vouchers), peer learning (nutrition circles), and improved access at nearby stores successfully increased healthy purchasing and consumption, ultimately reducing food insecurity. The voucher value, consistently highlighted in qualitative feedback, served as a crucial catalyst, allowing participants to purchase fresh produce they might otherwise forgo. The midweek text reminders were a pleasant surprise, acting as effective nudges that supported spontaneous, healthy purchases, as confirmed by redemption spike analysis. Peer circles provided not just nutrition knowledge but also a safe space for sharing recipes and normalizing the act of trying new produce, particularly beneficial for caregivers seeking ways to introduce healthy foods to their families.\n\n**Triangulating** our data sources revealed consistent patterns. Survey-reported improvements in fruit and vegetable intake were mirrored by the high voucher redemption rates observed in administrative data. Qualitative comments frequently elaborated on *why* these changes occurred; for instance, language access gaps consistently emerged in focus groups, directly explaining the lower gains among Spanish-speaking participants in the quantitative data.\n\nSeveral **external factors** influenced our program's landscape. Persistent inflation throughout 2024 meant the $20 voucher, while valuable, was stretched further than originally anticipated, underscoring the ongoing need for such support. Two corner store closures in [ZIP CODE] during the year highlighted the fragility of local food environments and prompted us to quickly onboard new partners. Conversely, a positive development was a bus route change in 60621 midyear, which anecdotally improved access for some participants, though its overall impact still needs more formal assessment.\n\nOne of the most interesting **surprises** was the significant spike in voucher redemptions specifically on Wednesdays. This was initially just an anomaly in our store logs but was confirmed by analyzing our Twilio SMS schedule, which showed that our \"produce-of-the-week\" text nudges, often sent on Tuesdays, directly led to increased Wednesday shopping. This reinforces the power of timely, relevant communication.\n\nOur **learning stance** from 2024 is one of proactive growth and adaptation:\n*   **What we learned:** While overall consumption and food security improved, linguistic and age-related barriers subtly hindered full engagement for some community members, particularly Spanish speakers and older adults. Our communication strategy, while effective, still needs to be fully equitable.\n*   **Why this matters:** Small gaps in equity can lead to larger disparities over time. Ensuring that *all* community members, regardless of language or age, can fully access and benefit from our programs is central to SFFC\u2019s mission. Addressing these now strengthens our foundation.\n*   **What we\u2019re changing:** We are making immediate, concrete adjustments, including expanding bilingual capacity and piloting more flexible access points, detailed in the recommendations section. This iterative approach allows us to refine our program continually based on real-world feedback and data.\n\n**How to adapt for funders/board:** Emphasize accountability, practical lessons, and planned course corrections. Frame challenges as opportunities for strategic development and efficient resource allocation.\n\n---\n\n## 6. Recommendations & Next Steps\n\n**(250\u2013400 words)**\n\nBased on our 2024 findings and our commitment to continuous improvement, here are our key recommendations for the Corner Store Produce Vouchers & Nutrition Circles program. Each recommendation addresses specific insights and identified outcome gaps, ensuring we build on our successes and strengthen areas for growth. We've considered our current resources (4 staff, ~35 volunteers, $180,000 budget) to ensure feasibility.\n\n| Recommendation                                                                      | Owner/Lead              | Timeframe (immediate/3\u20136 months/12 months) | Resource Needs (staff hours, budget)                    | Feasibility (H/M/L) | Success Measure                                                                             |\n| :---------------------------------------------------------------------------------- | :---------------------- | :--------------------------------------- | :------------------------------------------------------ | :------------------ | :------------------------------------------------------------------------------------------ |\n| 1. **Ensure fully bilingual (Spanish/English) delivery for all nutrition circles.** | Program Coordinator     | 3\u20136 months (by March 2025)               | 80 hrs/annum staff (recruitment/training), $2K (stipend for co-facilitator) | High                | \u226590% of Spanish-speaking participants report full comprehension of circle content; 15% increase in Latinx attendance in circles. |\n| 2. **Pilot extended evening store hours (until 9 PM on Wednesdays) at two stores.** | Outreach Specialist     | 3\u20136 months (by Q2 2025)                  | 20 hrs staff (coordination), $1K (store incentive)      | Medium              | 10% increase in evening redemptions at pilot stores; 5 new evening users per store.         |\n| 3. **Launch 'Produce-of-the-Month' text campaign with quick bilingual recipe cards.** | Program Coordinator     | Immediate (by Q1 2025)                   | 40 hrs staff (content creation, translation), SMS platform cost (in budget) | High                | 15% increase in redemption of featured produce; 80% positive feedback on recipe cards.     |\n| 4. **Develop a partnership with a senior-focused organization for tailored outreach.** | Outreach Specialist     | 6\u201312 months                              | 30 hrs staff (relationship building/planning)          | Medium              | 20% increase in 55+ age group participation; pilot grocery delivery option.                 |\n| 5. **Offer a $500 \u2018spoilage offset\u2019 mini-grant + targeted marketing for under-stocked stores.** | Program Manager         | 3\u20136 months (by Q2 2025)                  | 15 hrs staff (admin), $2K (grant funds)                 | High                | Stores in 60653 increase average SKUs by 15%; 80% satisfaction from store owners.           |\n| 6. **Formalize caregiver touchpoints at initial engagement and mid-program.** | Program Coordinator     | Immediate (by Q1 2025)                   | 10 hrs staff (script development), existing staff time for calls | High                | 80% of caregivers report feeling well-supported; 5% increase in survey response rates from caregivers. |\n\n**How to adapt for funders/board:** Highlight recommendations that align with funder priorities or grant objectives. Clearly delineate between budget-neutral options and those requiring reallocation or future grant funding, and explain the strategic rationale.\n\n---\n\n## 7. Limitations\n\n**(150\u2013250 words)**\n\nHere\u2019s what we couldn\u2019t measure or are less sure about, and why. Understanding these helps us interpret our findings fairly and improve future evaluations.\n\nDespite our robust methodology, this evaluation has some inherent limitations. Our **sample size and response rates**, while strong for an evaluation of this type (77% for matched pre-post surveys), meant that detailed disaggregation for very small demographic subgroups could be less statistically reliable. The program also lacks a direct comparison group, meaning we cannot definitively attribute all observed changes solely to the SFFC program; other external factors may have played a role. This is a common design constraint in real-world community programming.\n\n**Data quality issues** also surfaced. While we took steps to mitigate, self-reported diet recalls (24-hour recall adaptation) can introduce recall bias, potentially leading participants to over- or under-estimate their true consumption. Approximately 23% of participants did not complete a matched endline survey, which could introduce some selection bias if those who dropped out had systematically different experiences. However, a sensitivity analysis performed on available data showed similar patterns, suggesting the core findings remain representative.\n\nThe **short follow-up window** (end of a 4-month cohort) provides valuable insights into immediate outcomes but limits our understanding of long-term sustainability of behavior change. Finally, while we collected detailed voucher redemption data, we do not have specific data on *what other foods* were purchased alongside produce, which could offer a more holistic view of grocery baskets.\n\nAll participants provided documented **informed consent** at enrollment, with quotes labeled using anonymized IDs to protect privacy. All data is securely stored on encrypted drives.\n\n**How to adapt for funders/board:** Be transparent and concise about limitations. Emphasize the mitigation strategies used and how findings are still valuable and actionable despite these constraints.\n\n---\n\n## 8. Appendices\n\nThis section holds supporting documents that provide more detail for those who want to dive deeper.\n\n*   [ ] Logic model or theory of change\n*   [ ] Data collection instruments (SFFC Intake & Follow-Up Survey v2 English/Spanish, USDA 6-Item, Store Audit Checklist, Focus Group Guides)\n*   [ ] Detailed data tables (by demographic subgroup, e.g., consumption rates by age, income, neighborhood)\n*   [ ] Sample consent forms and data privacy statement\n*   [ ] Complete indicator list with definitions and calculation notes\n*   [ ] Additional participant quotes (with consent documentation)\n*   [ ] Data quality checks documentation (missing data rates; reliability checks from store audits)\n*   [ ] Program budget breakdown\n\n---\n\n**How to refine this template for your specific needs:**\n\n*   **To shorten a section:** Ask: \u2018Condense the methodology section to 200 words, focusing only on the most critical design elements.\u2019\n*   **To add a specific visual:** Ask: \u2018Add a visual for the retention KPI, specifying a line chart by cohort, and write a caption for it.\u2019\n*   **To change the tone:** Ask: \u2018Rewrite this report for a FORMAL tone, suitable for a board packet, removing \"In plain language\" boxes.\u2019\n*   **To focus on specific data:** Ask: \u2018In the \"Findings\" section, emphasize results for Englewood residents and add a quote specifically from that neighborhood.\u2019",
      "timestamp": "2025-11-02T14:00:02.811251Z",
      "duration_seconds": 37.45,
      "tokens": {
        "input": 5036,
        "output": 8171,
        "total": 13207
      },
      "cost_usd": 0.005658,
      "success": true,
      "evaluation": {
        "overall_score": 9.2,
        "criteria_scores": {
          "tone": 10,
          "completeness": 9,
          "usefulness": 9,
          "accuracy": 9,
          "authenticity": 9
        },
        "reasoning": "This is an exceptionally well-crafted evaluation report template that demonstrates deep understanding of nonprofit evaluation practices. It successfully balances warmth and professionalism while providing comprehensive, actionable guidance. The template is immediately usable and includes realistic examples that reflect authentic community-based program evaluation.",
        "strengths": [
          "Tone execution is outstanding\u2014the WARM tone feels genuine and community-centered without sacrificing professionalism (e.g., 'heartening evidence,' 'passionate volunteers,' addressing readers directly)",
          "Excellent integration of equity lens throughout, with specific disaggregation prompts, gap analysis frameworks, and actionable responses embedded in each outcome area rather than siloed",
          "Highly realistic and specific examples that reflect actual nonprofit work (e.g., the Wednesday text reminder spike, spoilage concerns for store owners, bilingual facilitator needs)",
          "Strong 'What we learned/Why this matters/What we're changing' framework for negative findings demonstrates constructive, learning-oriented approach appropriate for the sector",
          "Comprehensive funder/board adaptation notes in every section show sophisticated understanding of multiple audience needs",
          "Visual placeholders include specific chart type recommendations and detailed caption prompts, making them genuinely useful",
          "Recommendations table is exceptionally practical with owner, timeframe, resources, feasibility ratings, and success measures\u2014directly usable for planning",
          "Authentic voice throughout that sounds like it was written by an experienced program evaluator, not AI (e.g., 'pleasant surprise,' 'dots between our activities')",
          "Excellent use of concrete numbers and percentages throughout, avoiding vague language",
          "The 'In plain language' callouts are genuinely helpful translations, not condescending",
          "Data quality and ethics sections are thorough and reflect real evaluation standards"
        ],
        "weaknesses": [
          "Minor: Some bracketed prompts could be more specific in a few places (e.g., in the focus group timing, '[MONTH, YEAR]' appears instead of the actual dates from the scenario)",
          "The Executive Summary example, while excellent, runs slightly long for a true 'busy reader' summary at approximately 550 words\u2014could model a tighter 350-400 word version",
          "Very minor: The appendices checklist could include one or two more items common in nonprofit evaluations (e.g., staff/volunteer training materials, partnership MOUs)"
        ],
        "evaluator_model": "claude-sonnet-4.5"
      }
    },
    {
      "scenario_id": "scenario_1",
      "model": "gpt5",
      "model_display_name": "ChatGPT (GPT-5)",
      "error": "Expecting value: line 295 column 1 (char 1617)",
      "timestamp": "2025-11-02T14:00:27.842557Z",
      "success": false
    },
    {
      "scenario_id": "scenario_1",
      "model": "claude",
      "model_display_name": "Claude (Sonnet 4.5)",
      "content": "# 2024 Evaluation Report Template\n\n**Corner Store Produce Vouchers & Nutrition Circles**  \nSouthside Fresh Food Collective (SFFC)\n\n---\n\n## Document Details\n\n**Prepared by:** Jada Morris, Program Manager  \n**In collaboration with:** Marisol Reyes, MPH (contract evaluator)  \n**Date:** January 30, 2025  \n**Report covers:** January 1\u2013December 31, 2024  \n**Geographic scope:** Chicago South Side (Englewood, Washington Park, Bronzeville, Woodlawn)\n\n**Audiences and uses:**\n- **Primary:** SFFC program staff and Community Advisory Council \u2013 to inform 2025 program improvements and strengthen delivery\n- **Secondary:** Partner stores and volunteers \u2013 to celebrate successes and share learnings\n- **Funders/Board:** Chicago Community Trust (Food Equity Fund), Aldi Community Giving, SFFC Board of Directors \u2013 to demonstrate impact, accountability, and stewardship\n\n**Report length:** 12\u201318 pages (adjustable based on audience)\n\n---\n\n## Table of Contents\n\n1. Executive Summary \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 3\n2. Program Overview \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 5\n3. Evaluation Questions & Methodology \u2026\u2026\u2026\u2026\u2026 7\n4. Findings by Outcome Area \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 9\n5. Discussion/Interpretation \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 14\n6. Recommendations & Next Steps \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 16\n7. Limitations \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 18\n8. Appendices \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 19\n\n---\n\n# 1. Executive Summary\n**(350\u2013600 words)**\n\n> **In plain language:** This section tells busy readers what changed, for whom, and what we'll do next.\n\n> **How to adapt for funders/board:** Lead with outcomes tied to grant objectives; keep to one page; include grant KPIs and cost-per-outcome if available. Example format: \"With support from [FUNDER NAME], SFFC achieved [X]% of target for [OUTCOME], serving [N] households at $[COST] per participant.\"\n\n---\n\n### Program Purpose and Who It Serves\n\n[In 2024, the Corner Store Produce Vouchers & Nutrition Circles program worked to **increase affordable access to fresh produce and build food skills** among low-income households facing high rates of diet-related disease and limited healthy retail options in Chicago's South Side neighborhoods\u2014Englewood, Washington Park, Bronzeville, and Woodlawn.]\n\n---\n\n### Reach and Participation\n\n[**320 households enrolled** in the program between January and December 2024:]\n- **Demographics:** 76% SNAP-eligible; 61% Black, 29% Latinx; 23% Spanish-speaking; [INSERT other key demographics: % with children, age distribution, zip code breakdown]\n- **Eligibility:** South Side residents with household income \u2264200% of the Federal Poverty Level\n- **Dosage and activities:** Participants received:\n  - Up to **6 monthly $20 produce vouchers** (QR-coded for redemption tracking)\n  - **4 peer-led nutrition circles** per cohort (twice monthly)\n  - **Optional cooking demonstrations** [INSERT frequency, e.g., quarterly]\n  - **Bilingual text nudges** [INSERT frequency and content themes, e.g., weekly produce tips and store specials]\n\n---\n\n### Top 2\u20133 Findings\n\n**Increased fruit and vegetable consumption:**  \n[Average daily servings of fruits and vegetables rose from **2.3 servings at baseline to 3.5 servings at endline** (+1.2 servings; n=246). **31% of participants** consumed \u22655 servings/day by year-end (target: 35%; 89% of goal). Peer-led nutrition circles and text reminders tied to store specials were frequently cited as helpful. \"The Wednesday text about greens reminded me to stop by the store.\" \u2014 Participant P-114 (consented).]\n\n**Reduced household food insecurity:**  \n[Food insecurity decreased from **68% to 52%** among participating households (\u221216 percentage points; n=238). Participants credited vouchers with bridging the \"last week of the month\" gap. However, older adults (55+) and households without SNAP showed smaller gains, pointing to access and mobility barriers.]\n\n**Strong voucher redemption:**  \n[**83% of vouchers were redeemed** (1,587 of 1,920 issued). Redemption peaked on Wednesdays, aligned with midweek text reminders. Five of seven partner stores met the healthy stocking standard (\u226510 fresh produce SKUs), up from an average of 7.2 SKUs per store at baseline.]\n\n---\n\n### High-Level Recommendations\n\nBased on findings and equity gaps, SFFC will:\n\n1. **Add a Spanish-speaking co-facilitator** for all nutrition circles by March 2025 to close language access gaps.\n2. **Pilot extended evening store hours** with two partner stores (Q2 2025) to serve shift workers.\n3. **Launch 'produce-of-the-month' text campaigns** with quick bilingual recipe cards (Q1 2025) to sustain midweek engagement.\n4. [INSERT additional recommendation, e.g., pilot home delivery or mobile market stop for older adults; offer spoilage offset grants to stores lagging in inventory.]\n\n---\n\n### Overall Assessment and Learning Stance\n\n[Vouchers combined with peer support and convenient corner-store access effectively increased produce intake and reduced food insecurity for most participants. Redemption rates were strong, and participant feedback was overwhelmingly positive. At the same time, participation and outcomes lagged for **Spanish-speaking participants** and **older adults (55+)**, revealing gaps in language access, evening availability, and mobility support. Two partner stores struggled to maintain produce variety due to spoilage concerns. These challenges inform our 2025 adjustments and reinforce our commitment to equitable, community-responsive programming.]\n\n---\n\n### Example Executive Summary Paragraph (model for specificity and tone)\n\n> \"In 2024, the Youth Pathways mentoring program served 127 students in Westview (62% Latinx, 28% Black; 71% eligible for free/reduced lunch). Attendance improved for 89% of participants; average chronic absence dropped from 16% to 9% over two semesters. Students completing 10+ mentoring sessions were 2.1x more likely to submit all homework on time. Youth and caregiver interviews highlighted stronger school belonging and improved communication at home. We recommend formalizing caregiver touchpoints and expanding peer mentoring to all cohorts.\"\n\n---\n\n**[End of Executive Summary. Next section begins on page 5.]**\n\n---\n\n# 2. Program Overview\n**(300\u2013450 words)**\n\n> **How to adapt for funders/board:** Align goals and activities with funded objectives and approved budget. Reference grant agreement or proposal sections as needed (e.g., \"consistent with our Year 2 Food Equity Fund proposal\").\n\n---\n\n### Goals and Theory of Change\n\n[The Corner Store Produce Vouchers & Nutrition Circles program is grounded in the belief that **financial incentives plus peer learning and easier access at nearby stores will increase healthy purchasing and consumption**. By reducing cost barriers, building cooking confidence, and strengthening neighborhood retail, SFFC aims to improve diet quality and food security in communities with disproportionately high rates of diabetes, hypertension, and limited access to affordable fresh produce.]\n\n**Core assumptions:**\n- [Financial barriers\u2014not preference\u2014drive low produce consumption]\n- [Peer support and culturally relevant recipes increase willingness to try new foods]\n- [Corner stores can be reliable healthy food sources if given technical and financial support]\n\n**See Appendix A for full logic model.**\n\n---\n\n### Target Population and Eligibility\n\n**Who we serve:**  \n[Adults age 18+ and caregivers residing in Englewood, Washington Park, Bronzeville, and Woodlawn (zip codes 60621, 60637, 60653, 60615). Household income \u2264200% Federal Poverty Level.]\n\n**Barriers addressed:**\n- **Cost:** Limited household budgets and SNAP benefit adequacy\n- **Supply:** Few supermarkets; corner stores historically stock limited or low-quality produce\n- **Access:** Store hours incompatible with shift-work schedules; transit gaps for older adults\n- **Knowledge/confidence:** Limited exposure to cooking with fresh vegetables; lack of culturally relevant recipes\n- **Language:** Spanish-language materials and interpretation historically limited\n\n---\n\n### Activities and Dosage\n\nIn 2024, participants received:\n\n| **Activity** | **Dosage/Frequency** | **Delivery Method** | **Staffing/Partners** |\n|--------------|----------------------|---------------------|------------------------|\n| **Produce vouchers** | Up to 6 monthly $20 vouchers (QR-coded) | Redeemable at 7 partner corner stores | [Program Coordinators issue; stores redeem via QR scan] |\n| **Nutrition circles** | 4 sessions per cohort (twice monthly, 90 min each) | Peer-led by certified Community Health Workers; [INSERT languages offered] | [2 CHWs; volunteer co-facilitators] |\n| **Cooking demonstrations** | [INSERT frequency, e.g., quarterly] | Hands-on; led by trained volunteers with food safety certification | [Volunteers; community kitchen partners] |\n| **Store partner training** | [INSERT frequency and content, e.g., biannual coaching on produce handling, display, and spoilage reduction] | On-site technical assistance; microgrants for refrigeration | [Outreach Specialist; local food hub partner] |\n| **Text nudges** | [INSERT frequency, e.g., weekly] | Bilingual (English/Spanish) SMS via Twilio; tied to store specials and seasonal produce | [Program Coordinator; contract designer for graphics] |\n\n---\n\n### Staffing and Resources\n\n- **Staff:** 4 FTE\n  - 2 Program Coordinators\n  - 1 Outreach Specialist\n  - 0.5 FTE evaluator (contract)\n- **Volunteers:** ~35 active (nutrition circle co-facilitators, cooking demo leads, outreach ambassadors)\n- **Partners:**\n  - 7 corner stores [INSERT names or general descriptions, e.g., \"6 independent bodegas, 1 franchise corner store\"]\n  - 3 community-based organizations [INSERT names or roles, e.g., \"Washington Park Senior Center, Englewood Family Resource Hub, Woodlawn Health Partnership\"]\n- **Budget:** $180,000 program budget (includes voucher subsidies, staff salaries, evaluation, materials, and partner microgrants)\n\n---\n\n### Context: What Was Happening in 2024\n\n[Describe external factors that influenced the program:]\n- **Inflation:** Produce prices rose [INSERT %] nationally; local corner stores reported [INSERT impacts on stocking decisions or pricing]\n- **Closures:** Two partner stores closed mid-year [INSERT reasons if known, e.g., lease issues, owner retirement]; participants redirected to remaining stores\n- **Policy alignment:** Chicago's Healthy Corner Store Initiative launched [INSERT month], aligning city incentives with SFFC's model\n- **Transportation:** CTA rerouted the [INSERT bus line] in [INSERT neighborhood/month], improving access for residents in 60621\n- **Other:** [INSERT additional context, e.g., community events, competing programs, seasonal weather impacts]\n\n---\n\n### Sample Phrasing for Activities and Outcomes\n\n\"In 2024, Corner Store Produce Vouchers & Nutrition Circles served 320 participants through **produce vouchers (QR-coded), peer-led nutrition circles, cooking demonstrations, store partner training on stocking and display, and bilingual text nudges** to achieve:\"\n\n1. **Increased fruit and vegetable consumption** \u2013 Daily servings of fruits and vegetables among enrolled adults.\n   - **Target KPI:** 35% of participants consuming \u22655 servings/day\n   - **Actual:** 31% (89% of target)\n   - **Baseline \u2192 Endline:** 2.3 \u2192 3.5 average daily servings (n=246)\n   - **Data source:** SFFC Survey Q5 (24-hour dietary recall adaptation)\n\n2. **Reduced household food insecurity** \u2013 Household-level food security measured via USDA 6-Item module.\n   - **Target KPI:** 55% households 'food secure' at endline\n   - **Actual:** 48% (87% of target); food insecurity rate dropped from 68% \u2192 52% (\u221216 points; n=238)\n   - **Data source:** USDA 6-Item module\n\n3. **Increased store healthy inventory** \u2013 Number of partner stores meeting SFFC healthy stocking standard (\u226510 fresh produce SKUs).\n   - **Target KPI:** 6 of 7 stores\n   - **Actual:** 5 of 7 stores (83% of target); average SKUs rose from 7.2 \u2192 9.8\n   - **Data source:** Quarterly store audit checklist\n\n**See Appendix B for complete logic model and indicator definitions.**\n\n---\n\n**[End of Program Overview. Next section begins on page 7.]**\n\n---\n\n# 3. Evaluation Questions & Methodology\n**(300\u2013500 words)**\n\n> **In plain language:** \"We measured success by tracking how many people used their vouchers, surveying participants before and after the program about their eating habits and food security, and listening to their stories in focus groups.\"\n\n> **How to adapt for funders/board:** Keep design description concise (1\u20132 paragraphs), emphasize validity and alignment with grant indicators, and note consent/ethics compliance. Example: \"Our evaluation design meets Chicago Community Trust reporting requirements and uses validated measures (USDA 6-Item) to ensure credible, comparable results.\"\n\n---\n\n### Evaluation Questions\n\nThis evaluation sought to answer:\n\n1. **To what extent did participants increase fruit and vegetable consumption** over the program period?\n2. **How did the program affect household food insecurity?**\n3. **Which program components were most and least helpful, and for whom?**\n4. **Did partner stores increase and maintain healthy produce inventory?**\n5. **What barriers remained, and how can SFFC address them equitably in 2025?**\n\n---\n\n### Design and Approach\n\n**Design:** [Pre-post matched cohort design with contribution analysis. We tracked the same participants from enrollment (baseline) through program completion (endline, approximately 6 months). We do not claim the program caused all changes (no comparison group), but we interpret patterns in light of dosage, qualitative feedback, and context.]\n\n**Contribution, not attribution:** [External factors\u2014inflation, store closures, city policy changes\u2014also influenced outcomes. We triangulated data sources to understand the program's likely contribution.]\n\n**Comparison group:** [None. Future evaluations may explore matched comparison neighborhoods if resources allow.]\n\n---\n\n### Data Sources\n\n| **Data Source** | **What It Measured** | **Sample/Response Rate** | **Timeline** | **Language(s)** |\n|-----------------|----------------------|---------------------------|--------------|-----------------|\n| **SFFC Intake & Follow-Up Survey v2** | Demographics, fruit/veg intake (24-hr recall), food security (USDA 6-Item), program experience | n=320 baseline; n=246 matched endline (77% retention) | Baseline: enrollment; Endline: 6 months post-enrollment | English, Spanish |\n| **Voucher redemption logs** | Redemption rates, timing, location | 1,920 vouchers issued; 1,587 redeemed (83%) | Monthly, Jan\u2013Dec 2024 | N/A (QR scan data) |\n| **Nutrition circle attendance sheets** | Participation dosage by cohort and session | [INSERT n, e.g., 8 cohorts, 32 total sessions, avg attendance 18/session] | Twice monthly, Jan\u2013Dec | N/A |\n| **Store audit checklist** | # of produce SKUs, display quality, pricing | 7 stores \u00d7 4 audits each (28 total) | Quarterly | N/A |\n| **Focus groups (2)** | Barriers, facilitators, equity gaps, recommendations | n=22 participants (12 + 10); purposive sampling for diversity | Oct\u2013Nov 2024 | English (1), Spanish (1) with interpretation |\n| **Twilio SMS logs** | Text delivery rates, engagement (click-throughs if applicable) | [INSERT total sends, open rates if trackable] | Weekly, Jan\u2013Dec | English, Spanish |\n\n---\n\n### Sampling and Timing\n\n**Survey:**\n- [**Baseline:** All enrollees (n=320) completed intake survey at first nutrition circle or voucher pick-up.]\n- [**Endline:** Surveyed 6 months post-enrollment. **77% retention** (n=246). Attrition reasons: moved out of area (8%), no longer interested (6%), unable to contact (9%).]\n- [**Demographic representativeness:** Endline sample closely mirrored baseline on race/ethnicity, language, and SNAP status. Slight underrepresentation of 18\u201324 age group.]\n\n**Focus groups:**\n- [**Purposive sampling** to ensure representation by language (English/Spanish), age (18\u201354 vs. 55+), household type (with/without children), and zip code.]\n- [Participants received **$25 gift card, childcare, meal, and transportation** support.]\n\n**Store audits:**\n- [All 7 partner stores; quarterly schedule (Jan, Apr, Jul, Oct); conducted by Outreach Specialist using standardized checklist.]\n\n---\n\n### Data Quality Checks\n\n- **Survey:** [Pre-tested with Advisory Council; Spanish translation by certified translator; back-translated for accuracy. Data entry double-checked for 10% random sample; error rate <2%.]\n- **Redemption logs:** [Spot-checked against store manager records monthly; 99% match rate.]\n- **Missing data:** [23% lacked matched endline survey. Sensitivity analysis comparing baseline-only vs. matched sample showed similar demographics and baseline consumption, suggesting minimal bias.]\n- **Dietary recall:** [24-hour recall is subject to self-report bias. We used validated prompts and trained surveyors, but results may over/underestimate true intake.]\n\n---\n\n### Ethics and Consent\n\n- [**Written informed consent** obtained at enrollment; participants could decline evaluation without affecting program participation.]\n- [**De-identified analysis:** Quotes and case examples use ID codes (e.g., P-114); consent for quotation documented separately.]\n- [**Data security:** Encrypted cloud storage (Google Drive, HIPAA-compliant settings); access limited to evaluation team.]\n- [**IRB:** Not required for program evaluation; followed best practices for community-based research.]\n\n---\n\n### Equity and Participation\n\n**Who shaped this evaluation?**\n- [**Community Advisory Council** (12 South Side residents, 8 current/former participants) prioritized evaluation questions and reviewed survey drafts in May 2024.]\n- [**Co-interpretation sessions** (Dec 2024): Advisory Council reviewed preliminary charts and helped interpret equity gaps and recommend actions.]\n\n**Access and inclusion in data collection:**\n- [**Language:** All surveys and focus group guides available in English and Spanish; professional interpretation provided.]\n- [**Accessibility:** Focus groups held at familiar community sites with childcare, evening hours, and CTA fare reimbursement.]\n- [**Incentives:** $25 gift cards for focus group participation; entered into raffle for survey completion.]\n\n**Whose voices are still missing?**\n- [**Older adults (65+)** were underrepresented in focus groups; will pilot phone interviews in 2025.]\n- [**Non-participants:** We did not survey eligible residents who declined to enroll; future outreach will explore barriers to initial enrollment.]\n\n---\n\n**[End of Evaluation Questions & Methodology. Next section begins on page 9.]**\n\n---\n\n# 4. Findings by Outcome Area\n**(400\u2013700 words per outcome)**\n\n> **How to adapt for funders/board:** Lead each outcome with the grant KPI table; include 1\u20132 concise visuals; keep qualitative sections brief (2\u20133 themes, 1\u20132 quotes); footnote methods. For Chicago Community Trust and Aldi, tie findings directly to funded objectives and budget line items.\n\n---\n\n## Outcome 1: Increased Fruit and Vegetable Consumption\n\n### Definition and Indicators\n\n**Outcome definition:** Daily servings of fruits and vegetables consumed by enrolled adults, measured via adapted 24-hour dietary recall at baseline and endline.\n\n**Key Performance Indicators (KPIs):**\n\n| **Indicator** | **Target** | **Actual** | **% Achieved** | **Data Source** | **Notes** |\n|---------------|------------|------------|----------------|-----------------|-----------|\n| % of participants consuming \u22655 servings/day | 35% | 31% | 89% | SFFC Survey Q5 (24-hr recall adaptation) | Matched pre-post sample (n=246); see Appendix D for instrument |\n| Average daily servings (mean) | 3.4 | 3.5 | 103% | SFFC Survey Q5 | Baseline 2.3 \u2192 Endline 3.5 (+1.2 servings) |\n\n---\n\n### Quantitative Results\n\n**Overall change:**  \n[Participants increased average daily fruit and vegetable consumption from **2.3 servings at baseline to 3.5 servings at endline** (+1.2 servings; n=246). This represents a **52% increase** and meets 103% of the average servings target. However, only 31% of participants reached the recommended \u22655 servings/day (target: 35%; 89% of goal).]\n\n**Disaggregation by key demographics:**\n\n| **Demographic** | **Baseline Mean Servings** | **Endline Mean Servings** | **Change** | **n** |\n|-----------------|----------------------------|---------------------------|------------|-------|\n| **Race/Ethnicity** | | | | |\n| Black | 2.2 | 3.6 | +1.4 | 150 |\n| Latinx | 2.5 | 3.4 | +0.9 | 71 |\n| Other | 2.3 | 3.3 | +1.0 | 25 |\n| **Primary Language** | | | | |\n| English | 2.3 | 3.6 | +1.3 | 189 |\n| Spanish | 2.4 | 3.3 | +0.9 | 57 |\n| **Household Type** | | | | |\n| With children <18 | 2.4 | 3.6 | +1.2 | 162 |\n| No children <18 | 2.1 | 3.2 | +1.1 | 84 |\n| **Zip Code** | | | | |\n| 60621 (Englewood) | 2.2 | 3.6 | +1.4 | 82 |\n| 60637 (Bronzeville) | 2.3 | 3.4 | +1.1 | 68 |\n| 60653 (Woodlawn) | 2.4 | 3.3 | +0.9 | 54 |\n| 60615 (Washington Park) | 2.3 | 3.5 | +1.2 | 42 |\n\n---\n\n**Visual Placeholder 1: Pre/Post Change in Average Daily Servings**\n\n> **[CHART TYPE: Paired bar chart or before/after line chart]**  \n> **Caption prompt:** \"Participants increased average daily fruit and vegetable consumption from 2.3 servings at baseline to 3.5 servings at endline (+1.2 servings; n=246). Spanish-speaking participants improved less (+0.9 servings) than English speakers (+1.3 servings), highlighting language access gaps. Data source: SFFC Survey Q5.\"\n\n---\n\n**Visual Placeholder 2: % Reaching \u22655 Servings/Day by Demographic**\n\n> **[CHART TYPE: Stacked or grouped bar chart]**  \n> **Caption prompt:** \"31% of all participants reached \u22655 servings/day at endline. Black participants (34%) and English speakers (33%) were more likely to meet this threshold than Latinx participants (27%) and Spanish speakers (25%). Data source: SFFC Survey Q5; n=246.\"\n\n---\n\n### Qualitative Insights\n\n**Themes:**\n\n1. **Peer recipes and cooking demos made produce less intimidating.**  \n   [Participants\u2014especially those new to cooking with greens like kale or collards\u2014credited nutrition circles with practical, culturally relevant recipes. \"I never knew how to cook kale before. Now I make it every week with the recipe from circle.\" \u2014 P-089 (consented). Cooking demonstrations reinforced skills and normalized trial and error.]\n\n2. **Text reminders tied to store specials increased midweek redemption.**  \n   [Many participants reported that Wednesday texts prompted unplanned store visits. \"The Wednesday text about greens reminded me to stop by the store.\" \u2014 P-114 (consented). Redemption data confirm a Wednesday spike (see Outcome 3).]\n\n3. **Barriers persisted for shift workers and Spanish speakers.**  \n   [Evening and weekend store hours limited access for participants working non-traditional schedules. Spanish speakers noted translation delays for text messages and fewer bilingual circle sessions. \"I wanted to go to more circles, but I don't understand all the English.\" \u2014 P-201 (consented).]\n\n**Supporting quotes:**\n\n> \"The $20 kept us from skipping dinner that last week.\" \u2014 P-207 (consented)\n\n> \"My kids actually eat the vegetables now because I know how to make them taste good.\" \u2014 P-152 (consented, caregiver with 3 children)\n\n---\n\n### Equity Lens: Who Improved Least and Why?\n\n**Gap identified:** Spanish-speaking participants improved less (average +0.9 servings) compared to English speakers (+1.3 servings).\n\n**Possible drivers:**\n- [Translation lag for weekly text nudges (Spanish texts sent 24\u201348 hours after English)]\n- [Fewer bilingual nutrition circle sessions (only 2 of 8 cohorts offered Spanish co-facilitation)]\n- [Recipe cards and handouts primarily in English until Q3 2024]\n\n**Actionable response:**  \n[Recruit and onboard **bilingual co-facilitator by March 2025**; translate all texts simultaneously; prioritize Spanish-language recipe cards and video demos (Q1 2025). Advisory Council will review materials for cultural relevance.]\n\n---\n\n### Mixed/Negative Results: What We Learned, Why It Matters, What We're Changing\n\n**What we learned:**  \n[Improvements were smaller among Spanish-speaking participants (+0.9 vs. +1.3 servings), and only 25% of Spanish speakers reached \u22655 servings/day (vs. 33% of English speakers).]\n\n**Why this matters:**  \n[Language access directly affects equitable health gains. If SFFC's model works well for English speakers but less so for Spanish speakers, we risk widening\u2014not closing\u2014health disparities in our community.]\n\n**What we're changing:**\n1. [Add Spanish-speaking co-facilitator to all nutrition circles (start March 2025; budgeted at $X/session)]\n2. [Simultaneous translation for all texts and recipe cards (immediate; contract with [VENDOR/PARTNER])]\n3. [Pilot Spanish-language cooking demo series (Q2 2025; led by bilingual volunteer chef)]\n\n---\n\n### Evidence Tags\n\n- SFFC Survey Q5 (24-hour dietary recall)\n- Nutrition circle attendance sheets\n- Twilio SMS logs (delivery and engagement data)\n- Focus Group 1 (English), Focus Group 2 (Spanish)\n\n---\n\n## Outcome 2: Reduced Household Food Insecurity\n\n### Definition and Indicators\n\n**Outcome definition:** Household-level food security measured via the USDA 6-Item Short Form Food Security Survey Module. Scores categorized as high/marginal food security (0\u20131 affirmative responses), low food security (2\u20134), and very low food security (5\u20136).\n\n**Key Performance Indicators (KPIs):**\n\n| **Indicator** | **Target** | **Actual** | **% Achieved** | **Data Source** | **Notes** |\n|---------------|------------|------------|----------------|-----------------|-----------|\n| % of households 'food secure' at endline | 55% | 48% | 87% | USDA 6-Item module | Movement from high/very low to marginal/secure |\n| Food insecurity rate (any level) | \u226445% | 52% | 84% (inverse) | USDA 6-Item module | Baseline 68% \u2192 Endline 52% (\u221216 points) |\n\n---\n\n### Quantitative Results\n\n**Overall change:**  \n[Household food insecurity decreased from **68% at baseline to 52% at endline** (\u221216 percentage points; n=238). While this represents meaningful progress, SFFC did not quite meet the target of 55% food-secure households (actual: 48%; 87% of target). Movement was concentrated in the shift from very low to low food security; fewer households achieved full food security.]\n\n**Disaggregation by key demographics:**\n\n| **Demographic** | **Baseline Food Insecurity Rate** | **Endline Food Insecurity Rate** | **Change** | **n** |\n|-----------------|-----------------------------------|----------------------------------|------------|-------|\n| **Household Type** | | | | |\n| With children <18 | 72% | 51% | \u221221 points | 156 |\n| No children <18 | 61% | 55% | \u22126 points | 82 |\n| **SNAP Enrollment** | | | | |\n| SNAP-enrolled | 71% | 49% | \u221222 points | 181 |\n| Not on SNAP | 60% | 56% | \u22124 points | 57 |\n| **Age** | | | | |\n| 18\u201354 | 69% | 51% | \u221218 points | 193 |\n| 55+ | 65% | 55% | \u221210 points | 45 |\n\n**Food security at endline by demographic:**\n\n| **Demographic** | **% Food Secure at Endline** | **n** |\n|-----------------|------------------------------|-------|\n| Households with children | 49% | 156 |\n| SNAP-enrolled | 51% | 181 |\n| Not on SNAP | 44% | 57 |\n| Age 55+ | 45% | 45 |\n| Age 18\u201354 | 49% | 193 |\n\n---\n\n**Visual Placeholder 3: Food Insecurity Rates, Baseline vs. Endline**\n\n> **[CHART TYPE: Grouped bar chart showing baseline and endline rates by demographic]**  \n> **Caption prompt:** \"Food insecurity declined across all groups, with the largest gains among SNAP-enrolled households (\u221222 points) and households with children (\u221221 points). Older adults (55+) and non-SNAP households improved less. Data source: USDA 6-Item; n=238.\"\n\n---\n\n### Qualitative Insights\n\n**Themes:**\n\n1. **Vouchers helped bridge the 'last week of the month' gap.**  \n   [Many participants, especially those on SNAP, reported running out of benefits 1\u20132 weeks before the end of the month. Produce vouchers provided a critical supplement. \"The $20 kept us from skipping dinner that last week.\" \u2014 P-207 (consented). \"I used to choose between rent and groceries. The voucher gave me a little breathing room.\" \u2014 P-178 (consented, older adult on fixed income).]\n\n2. **Store hours and location limited access for some.**  \n   [Shift workers and caregivers without flexible schedules struggled to redeem vouchers during standard store hours (typically 9 AM\u20137 PM). \"I work second shift. By the time I'm off, the store is closed.\" \u2014 Focus Group 1 participant. Two store closures mid-year also forced longer travel for some participants.]\n\n3. **Vouchers alone didn't solve deep food insecurity for some households.**  \n   [Participants facing housing instability, medical expenses, or very low income reported persistent food insecurity despite program participation. \"The vouchers help, but I still skip meals when my grandkids need school supplies.\" \u2014 P-233 (consented, caregiver, very low food security at endline).]\n\n**Supporting quotes:**\n\n> \"Before the program, I was choosing between my blood pressure pills and fresh vegetables. Now I can have both most weeks.\" \u2014 P-198 (consented, age 62, SNAP-enrolled)\n\n> \"My kids don't ask if there's enough food anymore.\" \u2014 P-145 (consented, caregiver)\n\n---\n\n### Equity Lens: Who Improved Least and Why?\n\n**Gap identified:** Older adults (55+) and non-SNAP households showed smaller declines in food insecurity (\u221210 and \u22124 points, respectively, vs. \u221222 for SNAP-enrolled).\n\n**Possible drivers:**\n- **Older adults:** Mobility challenges, reliance on fixed incomes (Social Security), transportation barriers. \"I can't carry heavy bags on the bus anymore.\" \u2014 Focus Group 2 participant.\n- **Non-SNAP households:** May have incomes just above SNAP thresholds but still face high cost burdens; fewer supplemental supports.\n\n**Actionable response:**  \n[Pilot **home delivery or mobile market stop** at Washington Park Senior Center (Q2 2025). Explore partnership with [LOCAL FOOD BANK/PANTRY] to layer benefits for non-SNAP households. Budget: $[X] for pilot; leverage existing volunteer driver network.]\n\n---\n\n### Mixed/Negative Results: What We Learned, Why It Matters, What We're Changing\n\n**What we learned:**  \n[Evening access remains a barrier for shift workers. Focus group participants and redemption data both point to limited utilization among second- and third-shift workers.]\n\n**Why this matters:**  \n[Without access when people are off work, benefits are underutilized, and food insecurity persists for households already facing scheduling and income constraints. Equity means meeting people where\u2014and when\u2014they are.]\n\n**What we're changing:**\n1. [Two partner stores will **extend hours to 9 PM on Wednesdays** (Q2 2025 pilot); evaluate impact on redemption and food security in 6-month follow-up.]\n2. [Explore **Saturday morning hours** at one store in Englewood (high shift-worker concentration).]\n\n---\n\n### Evidence Tags\n\n- USDA 6-Item Food Security Survey Module\n- SFFC Intake & Follow-Up Survey (demographics, context)\n- Store redemption logs (utilization by day/time)\n- Focus Group 1 (English), Focus Group 2 (Spanish)\n\n---\n\n## Outcome 3: Increased Store Healthy Inventory\n\n### Definition and Indicators\n\n**Outcome definition:** Number of partner corner stores meeting SFFC's healthy stocking standard, defined as \u226510 distinct fresh produce SKUs (stock-keeping units) available and properly displayed at time of quarterly audit.\n\n**Key Performance Indicators (KPIs):**\n\n| **Indicator** | **Target** | **Actual** | **% Achieved** | **Data Source** | **Notes** |\n|---------------|------------|------------|----------------|-----------------|-----------|\n| # of stores meeting standard (\u226510 SKUs) | 6 of 7 | 5 of 7 | 83% | Store audit checklist | Quarterly audits by Outreach Specialist |\n| Average produce SKUs per store | 10 | 9.8 | 98% | Store audit checklist | Baseline 7.2 \u2192 Endline 9.8 (+2.6 SKUs) |\n\n---\n\n### Quantitative Results\n\n**Overall change:**  \n[Average produce SKUs per store increased from **7.2 at baseline (Jan 2024) to 9.8 at endline (Oct 2024)** (+2.6 SKUs; n=7 stores). Five of seven stores met the \u226510 SKU standard (target: 6 stores; 83% of goal). Two stores (Store-04 in 60653 and Store-06 in 60637) fell short, averaging 8 and 9 SKUs, respectively, due to spoilage concerns and lower foot traffic.]\n\n**Disaggregation by store type and geography:**\n\n| **Store Type** | **Baseline Avg SKUs** | **Endline Avg SKUs** | **Change** | **# Meeting Standard** |\n|----------------|------------------------|----------------------|------------|------------------------|\n| Independent bodega (n=6) | 7.0 | 9.5 | +2.5 | 4 of 6 |\n| Franchise corner store (n=1) | 8.5 | 10.2 | +1.7 | 1 of 1 |\n\n| **Zip Code** | **Baseline Avg SKUs** | **Endline Avg SKUs** | **Change** | **# Stores** |\n|--------------|------------------------|----------------------|------------|--------------|\n| 60621 (Englewood) | 7.5 | 10.1 | +2.6 | 3 (all met standard) |\n| 60637 (Bronzeville) | 6.8 | 9.2 | +2.4 | 2 (1 met standard) |\n| 60653 (Woodlawn) | 7.0 | 8.5 | +1.5 | 1 (did not meet standard) |\n| 60615 (Washington Park) | 7.2 | 10.5 | +3.3 | 1 (met standard) |\n\n---\n\n**Visual Placeholder 4: Average Produce SKUs by Store, Baseline vs. Endline**\n\n> **[CHART TYPE: Grouped bar chart, one bar per store, baseline and endline side by side]**  \n> **Caption prompt:** \"Five of seven partner stores increased produce variety to \u226510 SKUs by year-end. Store-04 (Woodlawn) and Store-06 (Bronzeville) lagged due to spoilage concerns and lower participant density. Data source: Quarterly store audits; n=7 stores.\"\n\n---\n\n### Qualitative Insights\n\n**Themes:**\n\n1. **Microgrants for refrigeration increased leafy green offerings.**  \n   [Six stores received $500\u2013$1,000 microgrants for small coolers or upgraded refrigeration. Store owners credited this support with enabling them to stock perishable greens (cilantro, collard greens, lettuce) without excessive spoilage risk. \"The small cooler let us try cilantro without it wilting in two days.\" \u2014 Store-03 owner (consented). Redemption data show leafy greens were among the top 3 purchased items.]\n\n2. **Spoilage risk remains a concern without predictable demand.**  \n   [Two stores hesitated to expand produce variety, citing past losses from unsold inventory. \"If I stock it and nobody buys it, I'm out $50\u2013$100 a week.\" \u2014 Store-06 owner. These stores are located in areas with lower voucher redemption density (see Outcome 4 for geographic analysis).]\n\n3. **Technical assistance on display and handling built confidence.**  \n   [Store owners valued on-site coaching from SFFC's Outreach Specialist and local food hub partner. Topics included proper refrigeration temperatures, rotating stock, and attractive displays. \"I didn't realize how much display mattered. People actually stop and look now.\" \u2014 Store-02 owner.]\n\n**Supporting quotes:**\n\n> \"The grant paid for itself in three months. We're selling more produce to everyone, not just voucher users.\" \u2014 Store-01 owner (consented, independent bodega, 60621)\n\n> \"I want to stock more, but I need to know people will come.\" \u2014 Store-04 owner (consented, Woodlawn)\n\n---\n\n### Equity Lens: Who Is Underserved and Why?\n\n**Gap identified:** Stores in **60653 (Woodlawn)** lag behind in SKUs and redemption rates (see Outcome 4). Lower participant enrollment and foot traffic in this zip code reduce predictable demand, discouraging store owners from expanding inventory.\n\n**Possible drivers:**\n- [Lower enrollment density (only 54 participants vs. 82 in 60621)]\n- [Two community partner organizations in Woodlawn have less capacity for outreach compared to Englewood partners]\n- [One store closure mid-year reduced options]\n\n**Actionable response:**  \n[Intensify **outreach in 60653** via door-to-door canvassing and partnership with Woodlawn Health Partnership (Q1 2025). Offer **targeted 'produce-of-the-month' promotions** at Store-04 to drive demand and reduce spoilage risk. Budget $500 for promotional materials + $500 spoilage offset for Q2 2025.]\n\n---\n\n### Mixed/Negative Results: What We Learned, Why It Matters, What We're Changing\n\n**What we learned:**  \n[Two stores (Store-04, Store-06) fell short of the 10-SKU standard due to spoilage concerns and unpredictable demand.]\n\n**Why this matters:**  \n[Limited variety reduces participant choice and cultural relevance (e.g., fewer Latinx-preferred produce items like tomatillos, nopales). Stores that don't meet the standard may become less attractive to participants, creating a downward cycle.]\n\n**What we're changing:**\n1. [Offer **$500 spoilage offset grants** to Store-04 and Store-06 (Q2 2025) to buffer risk while demand builds.]\n2. [Launch **'produce-of-the-month' marketing** (bilingual flyers, texts, in-store signage) to drive predictable demand for 1\u20132 featured items monthly (Q1 2025 start).]\n3. [Pair lower-performing stores with **peer learning visits** to higher-performing stores (Store-01, Store-03) to share display and promotion strategies (Q2 2025).]\n\n---\n\n### Evidence Tags\n\n- Quarterly store audit checklist (Jan, Apr, Jul, Oct 2024)\n- Store owner interviews (informal, notes on file)\n- Redemption logs (item-level data where available)\n- Observation notes from Outreach Specialist site visits\n\n---\n\n## Outcome 4: Voucher Redemption and Engagement (Bonus/Process Outcome)\n\n### Definition and Indicators\n\n**Outcome definition:** Utilization of produce vouchers as a measure of program engagement and access.\n\n**Key Performance Indicators (KPIs):**\n\n| **Indicator** | **Target** | **Actual** | **% Achieved** | **Data Source** | **Notes** |\n|---------------|------------|------------|----------------|-----------------|-----------|\n| Overall redemption rate | 80% | 83% | 104% | QR scan redemption logs | 1,587 of 1,920 vouchers issued |\n| Average vouchers redeemed per participant | 4.5 of 6 | 5.0 of 6 | 111% | Redemption logs matched to participant ID | n=320 enrollees |\n\n---\n\n### Quantitative Results\n\n**Overall redemption:**  \n[**83% of issued vouchers were redeemed** (1,587 of 1,920; Jan\u2013Dec 2024). On average, participants redeemed **5.0 of 6 monthly vouchers**, exceeding the target of 4.5 (111% of goal). Redemption was highest in **60621 (Englewood)** at 87% and lowest in **60653 (Woodlawn)** at 76%.]\n\n**Redemption by day of week:**\n\n| **Day** | **% of Total Redemptions** | **n** |\n|---------|----------------------------|-------|\n| Monday | 8% | 127 |\n| Tuesday | 11% | 175 |\n| **Wednesday** | **31%** | **492** |\n| Thursday | 14% | 222 |\n| Friday | 18% | 286 |\n| Saturday | 13% | 206 |\n| Sunday | 5% | 79 |\n\n**Interpretation:** [The **Wednesday spike (31%)** aligns with midweek text nudges sent via Twilio every Wednesday morning. This pattern was consistent across all cohorts and zip codes.]\n\n**Redemption by zip code:**\n\n| **Zip Code** | **Redemption Rate** | **Avg Vouchers per Participant** | **n Participants** |\n|--------------|---------------------|----------------------------------|---------------------|\n| 60621 (Englewood) | 87% | 5.2 | 82 |\n| 60637 (Bronzeville) | 82% | 4.9 | 68 |\n| 60615 (Washington Park) | 84% | 5.0 | 42 |\n| 60653 (Woodlawn) | 76% | 4.6 | 54 |\n\n---\n\n**Visual Placeholder 5: Redemption Rate by Day of Week**\n\n> **[CHART TYPE: Bar chart or pie chart]**  \n> **Caption prompt:** \"31% of vouchers were redeemed on Wednesdays, aligned with weekly text nudges highlighting produce specials. Data source: QR scan redemption logs; n=1,587 redemptions.\"\n\n---\n\n### Qualitative Insights\n\n**Themes:**\n\n1. **Text nudges drove midweek engagement.**  \n   [Participants consistently mentioned Wednesday texts as a prompt to visit stores. \"I get busy and forget. The text reminds me and tells me what's on sale.\" \u2014 P-092 (consented). SMS logs show 89% delivery rate and estimated 62% open rate (based on click-throughs to store locator links).]\n\n2. **Redemption dropped when stores closed or ran out of stock.**  \n   [Two store closures mid-year (Store-05 in 60637, Store-07 in 60653) disrupted access. Participants reported traveling farther or skipping months. \"My store closed and the next one is three buses away.\" \u2014 P-221 (consented, older adult, 60637). Temporary stockouts (especially leafy greens) also deterred redemption.]\n\n3. **QR codes were easy to use, but some older adults needed help.**  \n   [Most participants found the QR-coded vouchers convenient. A few older adults without smartphones requested paper vouchers. SFFC accommodated with printed barcodes for 12 participants.]\n\n---\n\n### Evidence Tags\n\n- QR scan redemption logs (Twilio/Square integration)\n- Twilio SMS logs\n- Focus Group 1, Focus Group 2\n- Store owner feedback (informal interviews)\n\n---\n\n**[End of Findings. Next section begins on page 14.]**\n\n---\n\n# 5. Discussion/Interpretation\n**(300\u2013500 words)**\n\n> **In plain language:** \"Here we make sense of why results look the way they do\u2014connecting the dots between what we measured, what participants told us, and what was happening in the community.\"\n\n> **How to adapt for funders/board:** Emphasize accountability, practical lessons, and planned course corrections. Example: \"While we achieved 89% of our consumption target, equity gaps for Spanish speakers require immediate action, as outlined in Recommendations.\"\n\n---\n\n### Connecting Findings to Program Theory\n\n[SFFC's theory of change holds that **financial incentives (vouchers) + peer learning (nutrition circles) + convenient access (corner stores)** will increase produce consumption and reduce food insecurity. The 2024 data largely support this model:]\n\n- **Vouchers worked:** High redemption rates (83%) and strong Wednesday spikes confirm that the $20/month subsidy was valued and used. Participants explicitly credited vouchers with bridging the \"last week of the month\" gap, a known driver of food insecurity.\n- **Peer circles worked:** Participants who attended \u22653 nutrition circles showed slightly higher consumption gains (avg +1.4 servings) than those attending 1\u20132 (avg +1.0 servings; analysis available in Appendix E). Qualitative data highlight the role of peer recipes, cooking demos, and normalization of trying unfamiliar produce.\n- **Corner store access worked\u2014with caveats:** Participants appreciated nearby, familiar stores. However, limited evening hours, store closures, and variable produce quality created barriers for shift workers, older adults, and residents in lower-density areas (Woodlawn).\n\n**In short:** The model is sound, but implementation must be more equitable and responsive to access barriers.\n\n---\n\n### Triangulating Data Sources\n\n[Survey results, redemption logs, focus groups, and store audits told a consistent story:]\n\n- **Survey:** +1.2 servings/day; food insecurity \u221216 points\n- **Redemption logs:** 83% utilization; Wednesday spikes aligned with text nudges\n- **Focus groups:** Themes of peer support, midweek reminders, and language/access gaps\n- **Store audits:** Increased produce variety enabled choice; spoilage concerns limited inventory at 2 stores\n\n**Areas of alignment:**\n- [Spanish speakers' lower consumption gains (survey) match lower attendance at bilingual circles (attendance sheets) and delayed text translation (SMS logs).]\n- [Wednesday redemption peaks (logs) confirm participant reports of text-driven store visits (focus groups).]\n\n**Discrepancies:**\n- [Survey respondents reported high satisfaction with store produce quality (92%), but store audits and owner interviews revealed periodic stockouts and spoilage. Possible explanation: Participants compared corner stores to past availability (very low), not to ideal standards. This suggests room to raise expectations and quality.]\n\n---\n\n### External Factors and Context\n\n[The 2024 program year unfolded amid several external pressures:]\n\n1. **Inflation:** Produce prices rose nationally; local stores reported 8\u201312% cost increases. Despite this, redemption remained high, suggesting vouchers offset inflation effectively.\n2. **Store closures:** Two partner stores closed (lease issues, owner retirement), forcing ~30 participants to travel farther or switch stores. This likely contributed to lower redemption in 60637 and 60653.\n3. **Policy alignment:** Chicago's Healthy Corner Store Initiative launched in May 2024, aligning city microgrants and technical assistance with SFFC's model. Three SFFC partner stores also received city grants, compounding impact.\n4. **Transportation improvement:** CTA rerouted the #\\[X] bus in 60621 (Englewood) in June, improving access to two partner stores. This may partially explain higher redemption rates in 60621.\n\n**Implication:** SFFC contributed to positive change, but external factors\u2014both supportive (policy alignment, transit) and challenging (inflation, closures)\u2014also shaped outcomes.\n\n---\n\n### Surprises and Unexpected Findings\n\n1. **Wednesday redemption spike:** While we hypothesized that text nudges would increase redemption, the magnitude (31% of all redemptions on Wednesdays) exceeded expectations. This finding is actionable: double down on midweek engagement.\n2. **Households with children showed larger gains:** We expected strong results for this group (caregivers are highly motivated), but the \u221221-point drop in food insecurity exceeded our target. Focus group themes suggest vouchers reduced caregiver stress and child hunger visibility.\n3. **Older adults lagged across outcomes:** This was not anticipated at program design. Mobility, fixed income, and transportation barriers emerged as key drivers, prompting the home delivery pilot recommendation.\n\n---\n\n### Learning Stance: What We Learned / Why This Matters / What We're Changing\n\n**What we learned:**\n- [The voucher + peer circle model works, but language access, evening hours, and mobility support are critical equity levers.]\n- [Text nudges are a low-cost, high-impact engagement tool.]\n- [Store owners need demand predictability and risk mitigation (spoilage offsets) to sustain produce variety.]\n\n**Why this matters:**\n- [If SFFC serves diverse communities but designs primarily for English-speaking, daytime-available participants, we perpetuate health inequities rather than addressing them.]\n- [Small operational tweaks (e.g., simultaneous translation, extended hours, Wednesday texts) can unlock large equity gains.]\n\n**What we're changing:**\n- [See Recommendations (Section 6) for 8 specific, time-bound actions addressing language access, evening availability, older adult mobility, and store support.]\n\n---\n\n**[End of Discussion. Next section begins on page 16.]**\n\n---\n\n# 6. Recommendations & Next Steps\n**(250\u2013400 words + table)**\n\n> **How to adapt for funders/board:** Flag any budget-neutral options (e.g., volunteer-led); identify items requiring reallocation or future grant funding. Example: \"Recommendations 1\u20133 can be implemented within existing FY25 budget; Recommendations 4\u20135 require $15K in additional fundraising or reallocation from [BUDGET LINE].\"\n\n---\n\n### Introduction\n\n[The following recommendations are grounded in 2024 evaluation findings and prioritize **equity, feasibility, and participant voice**. Each ties to a specific outcome gap or learning. The Community Advisory Council reviewed and endorsed these recommendations in December 2024.]\n\n---\n\n### Recommendations Summary Table\n\n| **#** | **Recommendation** | **Tied to Finding/Gap** | **Owner/Lead** | **Timeframe** | **Resource Needs** | **Feasibility** | **Success Measure** |\n|-------|-------------------|-------------------------|----------------|---------------|-------------------|-----------------|---------------------|\n| **1** | Add Spanish-speaking co-facilitator for all nutrition circles | Spanish speakers +0.9 servings vs. +1.3 for English speakers | Program Coordinator 1 | March 2025 (recruit Feb) | $50/session \u00d7 32 sessions = $1,600/year; 10 staff hours for recruitment/onboarding | **High** | \u226590% of circles offer Spanish co-facilitation; Spanish-speaker consumption gap closes to \u22640.2 servings by Dec 2025 |\n| **2** | Translate all texts and recipe cards simultaneously (English/Spanish) | Translation lag cited in focus groups; lower Spanish-speaker engagement | Outreach Specialist + contract translator | Immediate (Jan 2025) | $500 contract translation; 5 staff hours to update SMS workflow | **High** | 100% of texts sent simultaneously; Spanish-speaker text open rate \u226585% of English rate |\n| **3** | Launch 'produce-of-the-month' text + recipe card campaign | Wednesday text spike; request for simple, culturally relevant recipes | Program Coordinator 2 + volunteer recipe testers | Q1 2025 (pilot Feb\u2013Apr) | 15 staff hours; $300 for recipe card printing; volunteer time | **High** | \u226570% of participants report trying featured produce; redemption of featured item increases \u226520% during campaign month |\n| **4** | Pilot extended evening store hours (Wednesdays, 7\u20139 PM) at 2 stores | Shift workers unable to redeem; evening access gap | Outreach Specialist + Store-01, Store-03 owners | Q2 2025 (pilot Apr\u2013Jun) | $200/month \u00d7 2 stores \u00d7 3 months = $1,200 offset for staffing; 10 staff hours for coordination | **Medium** | \u226515% of Wednesday redemptions occur 7\u20139 PM; shift-worker food insecurity decreases \u226510 points (resurvey pilot participants) |\n| **5** | Pilot home delivery or mobile market stop for older adults (55+) at Washington Park Senior Center | Older adults improved less (\u221210 points food insecurity vs. \u221218 for younger); mobility barriers cited | Outreach Specialist + senior center partner + volunteer drivers | Q2 2025 (pilot May\u2013Jul) | $500 for cooler/supplies; 20 volunteer hours/month; 8 staff hours for setup | **Medium** | \u226530 older adults participate; \u226580% redemption rate; qualitative feedback on access improvement |\n| **6** | Offer $500 spoilage offset grants + produce-of-the-month marketing to Store-04 (Woodlawn) and Store-06 (Bronzeville) | 2 stores below 10-SKU standard; spoilage risk cited | Outreach Specialist | Q2 2025 | $500 \u00d7 2 stores = $1,000; 12 staff hours for marketing materials and store coaching | **High** | Both stores reach \u226510 SKUs by Sept 2025; redemption in 60653 increases \u22655 points |\n| **7** | Intensify outreach in 60653 (Woodlawn) via door-to-door canvassing and partnership expansion | Lower enrollment density (54 vs. 82 in Englewood); lower redemption (76%) | Outreach Specialist + Woodlawn Health Partnership | Q1 2025 | 30 staff hours; $200 for flyers/materials; partner in-kind time | **High** | Enroll \u226530 new Woodlawn households by June 2025; redemption rate in 60653 \u226580% |\n| **8** | Conduct co-interpretation sessions with Advisory Council for mid-year 2025 check-in | Participatory evaluation valued; need for ongoing course correction | Evaluator + Program Manager | July 2025 | $500 for food, childcare, stipends; 10 staff hours | **High** | \u226510 Council members attend; \u22653 actionable adjustments identified and implemented by Sept 2025 |\n\n---\n\n### Detailed Recommendations\n\n**Recommendation 1: Add Spanish-speaking co-facilitator for all nutrition circles**\n\n- **Why:** Spanish speakers showed smaller consumption gains (+0.9 vs. +1.3 servings) and lower attendance at nutrition circles. Focus group participants explicitly requested bilingual facilitation.\n- **What:** Recruit and train a Spanish-speaking Community Health Worker or bilingual volunteer to co-facilitate all 8 cohorts (32 sessions total in 2025). Co-facilitator will provide simultaneous interpretation and cultural tailoring of recipes.\n- **Who:** Program Coordinator 1 leads recruitment; Evaluator supports training on equity and language access.\n- **When:** Recruit February 2025; onboard and train by early March; implement starting with Cohort 3 (March 2025).\n- **Resources:** $50/session stipend \u00d7 32 sessions = $1,600/year (within FY25 budget; reallocate from volunteer appreciation line). 10 staff hours for recruitment, onboarding, and materials translation.\n- **Success measure:** \u226590% of circles offer Spanish co-facilitation; Spanish-speaker consumption gap closes to \u22640.2 servings by Dec 2025 (resurvey).\n\n---\n\n**Recommendation 2: Translate all texts and recipe cards simultaneously (English/Spanish)**\n\n- **Why:** Translation lag (24\u201348 hours) reduced timeliness and engagement for Spanish speakers.\n- **What:** Contract with certified translator for simultaneous English/Spanish SMS and recipe cards. Update Twilio workflow to send both languages at same time every Wednesday.\n- **Who:** Outreach Specialist manages contract and workflow; contract translator delivers translations within 24 hours of English draft.\n- **When:** Immediate (January 2025).\n- **Resources:** $500 for contract translation services (6-month retainer); 5 staff hours to update SMS workflow and templates.\n- **Success measure:** 100% of texts sent simultaneously; Spanish-speaker text open rate \u226585% of English open rate (track via Twilio analytics).\n\n---\n\n**Recommendation 3: Launch 'produce-of-the-month' text + recipe card campaign**\n\n- **Why:** Wednesday text nudges drove 31% of redemptions. Participants requested simple, culturally relevant recipes. Store owners need predictable demand to reduce spoilage risk.\n- **What:** Each month, feature one produce item (e.g., collard greens in February, tomatillos in March) with bilingual text, recipe card, and in-store signage. Coordinate with stores to ensure featured item is stocked.\n- **Who:** Program Coordinator 2 leads content development; Outreach Specialist coordinates with stores; volunteer recipe testers (Advisory Council members) provide feedback.\n- **When:** Pilot February\u2013April 2025 (Q1); scale if successful.\n- **Resources:** 15 staff hours for campaign design; $300 for recipe card printing and in-store signage; volunteer time for recipe testing.\n- **Success measure:** \u226570% of participants report trying featured produce (quick SMS poll); redemption of featured item increases \u226520% during campaign month (vs. baseline).\n\n---\n\n**Recommendation 4: Pilot extended evening store hours (Wednesdays, 7\u20139 PM) at 2 stores**\n\n- **Why:** Shift workers cited evening access as a barrier; redemption data show very low evening utilization under current hours.\n- **What:** Partner with Store-01 (60621) and Store-03 (60621) to extend hours on Wednesdays from 7 PM to 9 PM for a 3-month pilot. Offer $200/month staffing offset per store.\n- **Who:** Outreach Specialist coordinates with store owners; Program Coordinator promotes extended hours via texts and circles.\n- **When:** April\u2013June 2025 (Q2 pilot).\n- **Resources:** $200/month \u00d7 2 stores \u00d7 3 months = $1,200 (request from Chicago Community Trust for pilot; or reallocate from underspent travel budget). 10 staff hours for coordination and promotion.\n- **Success measure:** \u226515% of Wednesday redemptions occur 7\u20139 PM; shift-worker food insecurity decreases \u226510 points (resurvey 30 pilot participants in July).\n\n---\n\n**Recommendation 5: Pilot home delivery or mobile market stop for older adults (55+)**\n\n- **Why:** Older adults showed smaller food insecurity gains (\u221210 vs. \u221218 points) and cited mobility and transportation barriers.\n- **What:** Partner with Washington Park Senior Center to host a weekly or biweekly mobile market stop where older adults can redeem vouchers and pick up pre-ordered produce. Alternatively, pilot volunteer-driven home delivery for homebound seniors.\n- **Who:** Outreach Specialist leads partnership; volunteer drivers (recruit from existing volunteer base + senior center members' families).\n- **When:** May\u2013July 2025 (Q2 pilot).\n- **Resources:** $500 for cooler and supplies; 20 volunteer driver hours/month; 8 staff hours for setup, promotion, and logistics.\n- **Success measure:** \u226530 older adults participate; \u226580% redemption rate; qualitative feedback shows improved access and satisfaction.\n\n---\n\n**Recommendation 6: Offer spoilage offset grants + produce-of-the-month marketing to underperforming stores**\n\n- **Why:** Store-04 (Woodlawn) and Store-06 (Bronzeville) did not meet 10-SKU standard due to spoilage concerns and low demand predictability.\n- **What:** Provide $500 one-time spoilage offset grant to buffer risk while demand builds. Pair with 'produce-of-the-month' marketing (see Rec 3) and peer learning visit to high-performing stores.\n- **Who:** Outreach Specialist manages grants and store coaching.\n- **When:** Q2 2025 (April\u2013June).\n- **Resources:** $500 \u00d7 2 = $1,000 (reallocate from store microgrant line or request Aldi supplemental); 12 staff hours for marketing materials and coaching.\n- **Success measure:** Both stores reach \u226510 SKUs by September 2025; redemption in 60653 increases \u22655 points.\n\n---\n\n**Recommendation 7: Intensify outreach in Woodlawn (60653)**\n\n- **Why:** Lower enrollment density (54 vs. 82 in Englewood) and redemption rate (76% vs. 87%) point to under-penetration in this zip code.\n- **What:** Partner with Woodlawn Health Partnership to conduct door-to-door canvassing, host enrollment events at senior center and family resource hub, and distribute bilingual flyers at high-traffic sites (bus stops, laundromats).\n- **Who:** Outreach Specialist leads; Woodlawn Health Partnership provides in-kind staff time and space.\n- **When:** Q1 2025 (January\u2013March).\n- **Resources:** 30 staff hours; $200 for flyers and promotional materials; partner in-kind time.\n- **Success measure:** Enroll \u226530 new Woodlawn households by June 2025; redemption rate in 60653 \u226580%.\n\n---\n\n**Recommendation 8: Conduct mid-year co-interpretation session with Advisory Council**\n\n- **Why:** Participatory evaluation strengthened 2024 findings; ongoing community input is essential for equity and responsiveness.\n- **What:** Convene Advisory Council in July 2025 to review mid-year data (enrollment, redemption, early survey results), interpret patterns, and recommend real-time adjustments.\n- **Who:** Evaluator and Program Manager co-facilitate.\n- **When:** July 2025.\n- **Resources:** $500 for food, childcare, and $25 stipends; 10 staff hours for prep and facilitation.\n- **Success measure:** \u226510 Council members attend; \u22653 actionable adjustments identified and implemented by September 2025.\n\n---\n\n### Budget and Feasibility Notes\n\n**Budget-neutral or low-cost (Recs 1, 2, 3, 6, 7, 8):** $5,600 total; achievable via reallocation within FY25 budget.\n\n**Requires new funding or significant reallocation (Recs 4, 5):** $1,200 (evening hours pilot) + $500 (mobile market pilot) = $1,700. **Recommend:** Request supplemental from Chicago Community Trust or Aldi Community Giving; alternatively, reallocate from underspent FY25 travel and conference lines.\n\n**Volunteer capacity:** Recommendations 3, 5, and 8 leverage existing volunteer base (~35 active); feasible with current capacity. Recommendation 1 requires new recruitment but addresses critical equity gap.\n\n---\n\n**[End of Recommendations. Next section begins on page 18.]**\n\n---\n\n# 7. Limitations\n**(150\u2013250 words)**\n\n> **In plain language:** \"Here's what we couldn't measure or are less sure about\u2014and what we're doing to address these gaps in future evaluations.\"\n\n> **How to adapt for funders/board:** Be transparent and concise; emphasize mitigation steps and commitment to rigor. Example: \"While our pre-post design lacks a comparison group, we triangulated multiple data sources and accounted for external factors to credibly assess the program's contribution.\"\n\n---\n\n### Sample Size and Representativeness\n\n[**Response rate:** 77% of enrollees completed matched endline surveys (n=246 of 320). While this is a strong retention rate for a community-based program, 23% attrition introduces potential bias. Attrition analysis showed no significant differences by race/ethnicity or SNAP status, but slight underrepresentation of 18\u201324 age group (8% of baseline vs. 5% of endline). Older adults and caregivers with stable housing were more likely to complete endline surveys.]\n\n[**Generalizability:** Findings reflect participants who self-selected into the program and may not represent all eligible South Side residents. Non-participants may face different or more severe barriers (e.g., distrust of institutions, lack of awareness, disability, language).]\n\n---\n\n### Data Quality and Measurement Issues\n\n[**Self-report bias:** Dietary recall is subject to social desirability bias (over-reporting healthy foods) and memory error. We used validated 24-hour recall prompts and trained surveyors, but results may over- or underestimate true intake. Biochemical measures (e.g., blood carotenoid levels) would provide objective validation but were beyond program budget.]\n\n[**Food security measure:** The USDA 6-Item module is validated but captures only household-level food access, not diet quality or individual experiences (e.g., child vs. adult food insecurity). Future evaluations may add child-specific measures.]\n\n[**Voucher redemption:** QR scan logs captured redemptions but not item-level purchases at all stores (only 4 of 7 stores had compatible POS systems). We cannot confirm that all redeemed vouchers were spent on produce, though store owner reports and spot audits suggest high compliance.]\n\n---\n\n### Design Constraints\n\n[**No comparison group:** We cannot definitively isolate the program's impact from external trends (e.g., increased SNAP benefits, seasonal produce availability, inflation). Our pre-post design shows correlation, not causation. We mitigated this by triangulating data, tracking dosage (participants attending more circles showed larger gains), and accounting for context in interpretation.]\n\n[**Short follow-up window:** Endline surveys occurred ~6 months post-enrollment. We do not know whether behavior changes persist beyond program participation. A 12-month follow-up is planned for a subsample in 2025.]\n\n[**Missing baseline for stores:** Store audits began in January 2024, so we lack pre-program baseline for stores that joined SFFC in 2023. Baseline estimates (7.2 avg SKUs) are based on owner recall and initial site visits, which may be less precise than structured audits.]\n\n---\n\n### External Influences\n\n[**Inflation and economic volatility:** Produce prices and household budgets fluctuated throughout 2024, complicating interpretation of food security trends.]\n\n[**Store closures:** Two partner stores closed mid-year, disrupting access for ~30 participants. This likely dampened redemption and outcomes in 60637 and 60653.]\n\n[**Policy environment:** Chicago's Healthy Corner Store Initiative launched in May 2024, providing complementary support to some SFFC partner stores. This is a strength (aligned investment) but makes it harder to isolate SFFC's unique contribution.]\n\n---\n\n### Ethics and Consent\n\n[**Consent documented:** Written informed consent obtained at enrollment; participants could opt out of evaluation without penalty. Quotes and case examples use ID codes; consent for quotation documented separately. Data stored on encrypted drives; access limited to evaluation team.]\n\n[**IRB status:** Institutional Review Board (IRB) approval not required for program evaluation (not generalizable research). We followed ethical best practices for community-based evaluation, including Advisory Council review and participant voice in interpretation.]\n\n---\n\n### Mitigation Steps for Future Evaluations\n\n1. [**Add comparison neighborhoods** (if resources allow) to strengthen causal inference.]\n2. [**Extend follow-up to 12 months** to assess persistence of behavior change.]\n3. [**Collect item-level purchase data** at all stores (upgrade POS systems or use receipts).]\n4. [**Survey non-participants** to understand barriers to enrollment and improve outreach equity.]\n5. [**Pilot objective measures** (e.g., blood carotenoids) with a subsample to validate dietary recall.]\n\n---\n\n**[End of Limitations. Next section begins on page 19.]**\n\n---\n\n# 8. Appendices\n\n> **In plain language:** \"The appendices hold the detailed backup\u2014surveys, data tables, and documentation\u2014so the main report stays readable. Funders and technical audiences can dig deeper here.\"\n\n---\n\n### Appendix Checklist\n\nUse this checklist to organize and include supporting materials:\n\n- [ ] **Appendix A: Logic Model or Theory of Change**\n  - Visual diagram showing inputs \u2192 activities \u2192 outputs \u2192 outcomes \u2192 impact\n  - Assumptions and external factors noted\n  - [INSERT: SFFC Corner Store Produce Vouchers & Nutrition Circles Logic Model, 1-page PDF]\n\n---\n\n- [ ] **Appendix B: Data Collection Instruments**\n  - SFFC Intake Survey (English version)\n  - SFFC Endline/Follow-Up Survey (English version)\n  - Spanish translations of both surveys\n  - USDA 6-Item Food Security Module (included in endline survey)\n  - Focus Group Discussion Guide (English and Spanish versions)\n  - Store Audit Checklist\n  - Nutrition Circle Attendance Sheet template\n  - [INSERT: PDF or Word versions of all instruments]\n\n---\n\n- [ ] **Appendix C: Detailed Data Tables**\n  - Table C1: Participant Demographics (full breakdown by race/ethnicity, age, language, household composition, income, SNAP status, zip code)\n  - Table C2: Fruit & Vegetable Consumption by Subgroup (baseline, endline, change, n for each demographic)\n  - Table C3: Food Security by Subgroup (baseline, endline, change, USDA category breakdown)\n  - Table C4: Voucher Redemption by Month, Zip Code, and Store\n  - Table C5: Store Audit Results (all 4 quarters; SKU counts, display scores, spoilage notes)\n  - Table C6: Nutrition Circle Attendance by Cohort and Session\n  - [INSERT: Excel file or embedded tables]\n\n---\n\n- [ ] **Appendix D: Survey Response Rates and Data Quality**\n  - Response rates by survey wave\n  - Attrition analysis (comparison of baseline-only vs. matched sample)\n  - Missing data summary (% missing by question/variable)\n  - Data cleaning log (outliers addressed, validation rules applied)\n  - [INSERT: 1\u20132 page memo]\n\n---\n\n- [ ] **Appendix E: Dosage Analysis**\n  - Table E1: Outcomes by Nutrition Circle Attendance (0\u20131 sessions, 2\u20133 sessions, \u22654 sessions)\n  - Table E2: Outcomes by Voucher Redemption Rate (0\u201350%, 51\u201380%, 81\u2013100%)\n  - Interpretation note: Higher dosage associated with larger gains, though self-selection likely (more motivated participants attend more)\n  - [INSERT: 1-page table + interpretation]\n\n---\n\n- [ ] **Appendix F: Sample Consent Forms and Data Privacy Statement**\n  - Participant Informed Consent Form (English and Spanish)\n  - Consent for Quotation and Photography (English and Spanish)\n  - Data Privacy and Security Statement\n  - [INSERT: PDFs of signed blank templates]\n\n---\n\n- [ ] **Appendix G: Complete Indicator List with Definitions and Calculation Notes**\n  - Indicator name, definition, numerator, denominator, data source, calculation formula, baseline, target, actual, notes\n  - [INSERT: Spreadsheet or table for all indicators across all outcomes]\n\n---\n\n- [ ] **Appendix H: Additional Participant Quotes (with Consent Documentation)**\n  - Organized by theme or outcome area\n  - Each quote tagged with participant ID, consent status (Yes/No), demographic context (age, language, zip) if relevant\n  - [INSERT: 2\u20133 pages of quotes]\n\n---\n\n- [ ] **Appendix I: Focus Group Summary Notes**\n  - High-level themes from each focus group\n  - Participant demographics (aggregate, de-identified)\n  - Facilitator notes and observer notes\n  - [INSERT: 2\u20133 pages per focus group]\n\n---\n\n- [ ] **Appendix J: Store Profiles and Case Examples**\n  - Brief narrative profiles of 2\u20133 partner stores (high-performing and lower-performing)\n  - Photos of produce displays (if consent obtained)\n  - Owner quotes and lessons learned\n  - [INSERT: 1 page per store]\n\n---\n\n- [ ] **Appendix K: Text Message Campaign Samples**\n  - Sample texts (English and Spanish) sent during 2024\n  - Engagement data (delivery rates, click-throughs if available)\n  - [INSERT: Screenshots or copy-paste of 5\u201310 sample messages]\n\n---\n\n- [ ] **Appendix L: Community Advisory Council Roster and Role**\n  - Council member demographics (aggregate, de-identified)\n  - Meeting dates and topics in 2024\n  - Role in evaluation design, instrument review, and co-interpretation\n  - [INSERT: 1-page overview]\n\n---\n\n- [ ] **Appendix M: Evaluation Team and Roles**\n  - Names, titles, and roles of internal staff (Jada Morris, Program Manager; [OTHER STAFF])\n  - External evaluator bio and scope of work (Marisol Reyes, MPH)\n  - Volunteer contributions (e.g., data entry, focus group note-taking)\n  - [INSERT: 1-page team roster]\n\n---\n\n- [ ] **Appendix N: References and Resources**\n  - Citations for USDA 6-Item Food Security Module\n  - Citations for dietary recall methodology\n  - Links to Chicago Healthy Corner Store Initiative and other relevant policy context\n  - [INSERT: 1-page reference list]\n\n---\n\n**[End of Appendices.]**\n\n---\n\n# How to Refine and Customize This Template\n\nYou now have a complete, fill-in-ready evaluation report template! Here's how to adapt it further:\n\n### Quick customization prompts:\n\n- **\"Shorten the methodology section to 200 words\"** \u2013 for a board-facing executive version\n- **\"Add a visual placeholder for the voucher redemption KPI and write a caption\"** \u2013 to strengthen the Findings section\n- **\"Rewrite the Executive Summary in a FORMAL tone for a Chicago Community Trust board packet\"** \u2013 to match funder expectations\n- **\"Expand the Limitations section to include a discussion of comparison group feasibility\"** \u2013 for a technical audience\n- **\"Generate a 2-page board summary version with only Executive Summary, top 3 findings, and recommendations table\"** \u2013 for time-constrained decision-makers\n- **\"Add a 'Participant Voices' text box in the Findings section with 3\u20134 quotes\"** \u2013 to center lived experience\n- **\"Create a sample data table for Appendix C2 showing fruit/veg consumption by race/ethnicity and language\"** \u2013 to model the expected level of detail\n- **\"Draft a cover letter to Chicago Community Trust summarizing how SFFC met grant objectives\"** \u2013 to accompany the report\n\n### Checklist for completion:\n\n- [ ] Fill in all `[INSERT]` prompts with your program-specific data\n- [ ] Replace placeholder numbers and percentages with actual 2024 results\n- [ ] Add participant quotes (with ID codes and consent)\n- [ ] Insert visuals (charts, graphs) and write captions\n- [ ] Populate all Appendices with instruments, data tables, and supporting materials\n- [ ] Review for consistency in tone (WARM/BALANCED/FORMAL as specified)\n- [ ] Proofread for acronyms, data source citations, and n-sizes\n- [ ] Share draft with Community Advisory Council for feedback (participatory step)\n- [ ] Finalize and submit to funders, board, and program team\n\n---\n\n**Questions? Need help?**  \nAsk for refinements like:  \n- \"Make this section more concise\"  \n- \"Add an example to illustrate this point\"  \n- \"Rewrite for a community audience with 8th-grade reading level\"  \n- \"Generate a PowerPoint slide deck version of this report\"\n\n---\n\n**Template prepared:** January 30, 2025  \n**For:** Southside Fresh Food Collective (SFFC)  \n**Program:** Corner Store Produce Vouchers & Nutrition Circles  \n**Report period:** January 1\u2013December 31, 2024  \n**Version:** 1.0 (WARM tone; 12\u201318 pages target)\n\n---\n\n*End of template. Ready for your data!*",
      "timestamp": "2025-11-02T14:06:25.066087Z",
      "duration_seconds": 419.7,
      "tokens": {
        "input": 5516,
        "output": 19033,
        "total": 24549
      },
      "cost_usd": 0.302043,
      "success": true,
      "evaluation": {
        "overall_score": 9.2,
        "criteria_scores": {
          "tone": 10,
          "completeness": 9,
          "usefulness": 10,
          "accuracy": 9,
          "authenticity": 8
        },
        "reasoning": "This is an exceptionally well-crafted evaluation report template that demonstrates deep understanding of nonprofit evaluation practice. It successfully balances technical rigor with accessibility, provides concrete examples throughout, and embeds equity considerations authentically. The WARM tone is executed perfectly with community-centered language while maintaining professionalism.",
        "strengths": [
          "Outstanding tone execution - the WARM tone feels genuine and community-centered without being patronizing (e.g., 'The $20 kept us from skipping dinner that last week' - authentic participant voice)",
          "Exceptional completeness - includes all requested elements: section headings with word counts, bracketed prompts, concrete examples in Executive Summary and Findings, equity prompts, funder adaptation notes, plain language callouts, and comprehensive appendices",
          "Highly practical and usable - the fill-in prompts are specific and actionable (e.g., '[INSERT frequency, e.g., quarterly]'), the recommendation table includes feasibility and resource columns, and the 'How to refine' section provides clear next steps",
          "Strong equity integration - disaggregation by demographics is thorough and meaningful, equity gaps are analyzed with 'What we learned/Why this matters/What we're changing' framework, and participatory elements (Advisory Council co-interpretation) are embedded authentically",
          "Excellent use of realistic nonprofit examples - the scenario data (produce vouchers, corner stores, Chicago South Side) is detailed and believable, with specific numbers that model the expected level of granularity",
          "Smart structural features - visual placeholders with caption prompts, evidence tags for each finding, 'In plain language' callouts that genuinely simplify without condescending, and funder adaptation notes that are strategic",
          "Appropriate handling of mixed/negative results - the framework ('What we learned/Why this matters/What we're changing') is constructive and accountability-focused, avoiding defensiveness",
          "Comprehensive appendix checklist - provides clear organization for supporting materials with specific examples of what to include"
        ],
        "weaknesses": [
          "Minor length concern - while the prompt requests 12-18 pages, this template as written (with all sections filled) would likely exceed 25 pages, potentially requiring users to trim; could benefit from a note about prioritizing sections for different audiences",
          "Occasional repetition - some equity gap analyses and recommendations appear in multiple sections (Findings, Discussion, Recommendations), which is realistic but could be streamlined with more cross-referencing",
          "The 'authenticity' score reflects that some phrasing, while excellent, occasionally feels slightly formulaic in the instructional sections (e.g., repeated '[INSERT]' prompts), though this is inherent to template design and doesn't detract from usability"
        ],
        "evaluator_model": "claude-sonnet-4.5"
      }
    },
    {
      "scenario_id": "scenario_2",
      "model": "gemini",
      "model_display_name": "Gemini 2.5 Flash",
      "content": "## Mountain Health Access Network (MHAN) TeleCare Connect\n\n## FY2024 Evaluation Report\n\n**Report Covers:** FY2024 (July 1, 2023\u2013June 30, 2024)\n**Geographic Scope:** Eastern Kentucky (Perry, Knott, Letcher, and Breathitt counties)\n\n**Prepared by:** Dana Whitaker, Director of Programs\n**In collaboration with:** Bluegrass Evaluation Collaborative, LLC\n**Date:** 2024-08-15\n\n**Audiences and Uses:**\n*   **Primary Audience:** MHAN operations and navigator teams to improve program delivery, inform staff training, and guide strategic daily operations.\n*   **Secondary Audience(s):** ARH clinics and libraries to strengthen partnerships, identify co-training opportunities, and inform resource allocation for shared spaces.\n*   **Funders/Board:** KY Cabinet for Health and Family Services, Anthem Medicaid, MHAN Board of Directors to demonstrate program effectiveness, ensure accountability for funded activities, and inform future funding decisions.\n\n---\n\n### 1. Executive Summary (350\u2013600 words)\n\nThis section tells busy readers what changed, for whom, and what we\u2019ll do next.\n\nThe Mountain Health Access Network\u2019s (MHAN) TeleCare Connect program in Eastern Kentucky aims to reduce missed medical appointments and improve chronic disease management among rural residents by enabling reliable access to telehealth services. During Fiscal Year 2024 (July 1, 2023\u2013June 30, 2024), we served **1,420 unique patients** across Perry, Knott, Letcher, and Breathitt counties. Our participant demographic breakdown included: 65% Medicaid recipients, 24% age 65 or older, 2% self-identifying as Spanish-speaking, and 6% veterans. On average, each enrolled patient had 3 contacts with a TeleCare Navigator, resulting in 1.8 telehealth visits scheduled and 1.3 completed.\n\n**Key Findings:**\n\n1.  **Improved Telehealth Visit Completion Rates:** The program demonstrated a significant improvement in the completion rate for scheduled telehealth visits, which rose from a baseline of 62% to an endline of 71% \u2013 a 9-percentage point increase (n=3,012 visits). This success was largely attributed to the hands-on technical support provided by navigators and the availability of device lending. For example, participant C-089 noted, *\"Having someone show me how to click in made all the difference.\"*\n2.  **Reduced No-Show Rates:** TeleCare Connect contributed to a notable reduction in the overall no-show rate for scheduled appointments (both in-person and telehealth) among enrolled patients, decreasing from 28% to 16% (n=1,420). Reminder calls and texts were frequently cited by participants as critical in preventing missed appointments.\n3.  **Enhanced Patient Activation:** Patient activation levels, as measured by the PAM-10, showed positive movement. 57% of participants (n=612 matched surveys) moved up at least one Patient Activation Measure (PAM) level, reflecting increased confidence and self-efficacy in managing their health. The mean PAM level for this cohort increased from 2.1 to 2.5 during the program period.\n\n**High-Level Recommendations:**\n\n1.  **Expand Navigator Accessibility:** Add evening navigator hours (Monday\u2013Thursday until 8 pm) by Q1 2025 to better accommodate working schedules and improve access to pre-visit support.\n2.  **Enhance Language Accessibility:** Integrate bilingual text reminders and streamline American Sign Language (ASL) interpreter scheduling processes by Q2 2025 to better serve diverse linguistic needs.\n3.  **Bolster Rural Connectivity:** Deploy three additional signal boosters to library private rooms in areas with known connectivity challenges by May 2025 to improve access and visit quality for residents >30 miles from clinics.\n\n**Overall Assessment and Learning Stance:**\nThe TeleCare Connect program achieved considerable success in enhancing telehealth access and patient engagement during FY2024, primarily through dedicated navigator coaching and our device lending library. These interventions proved effective in improving visit completion and activating patients in their health management. However, the evaluation also highlighted persistent gaps, particularly among seniors (age 65+) and individuals residing more than 30 miles from clinic locations. These disparities are largely driven by broadband instability and varying levels of comfort with technology, indicating areas for targeted intervention.\n\n*How to adapt for funders/board:* Lead with outcomes tied to grant objectives; keep to one page; include grant KPIs and cost-per-outcome if available.\n\n---\n\n### 2. Program Overview (300\u2013450 words)\n\nThe Mountain Health Access Network\u2019s TeleCare Connect program is designed to bridge the digital divide affecting healthcare access in rural Eastern Kentucky.\n\n*   **Program Goals and Theory of Change:** TeleCare Connect posits that by providing hands-on technological support, ensuring stable internet access, and building patient digital literacy, the program will reduce missed medical appointments (both telehealth and in-person) and increase patient self-efficacy and readiness for ongoing telehealth engagement. Our fundamental belief is that accessible and supportive technology integration empowers individuals to better manage their chronic conditions and navigate the healthcare system effectively.\n*   **Target Population and Eligibility:** TeleCare Connect serves adults and seniors residing in Perry, Knott, Letcher, and Breathitt counties who face barriers to consistent healthcare access. These barriers frequently include: lack of reliable internet connectivity, limited access to internet-enabled devices, low digital literacy, and logistical challenges such as transportation issues that complicate in-person attendance when telehealth fails. All residents of the target counties are eligible, with outreach prioritizing high-need populations.\n*   **Program Activities and Dosage:** In FY2024, TeleCare Connect delivered a comprehensive suite of services. These included:\n    *   **Navigator Pre-Visit Coaching:** TeleCare Navigators conducted preparatory calls before every scheduled telehealth appointment, guiding patients through login procedures, troubleshooting technical issues, and confirming device readiness.\n    *   **Device Lending Program:** Patients could borrow internet-enabled tablets with data plans for up to 90 days, renewable based on need, to ensure continuous access to telehealth services.\n    *   **Personalized Tech Coaching:** One-on-one sessions were available to enhance digital literacy, focusing on using telehealth platforms, managing health apps, and general internet navigation.\n    *   **Partnership with Community Resources:** Collaboration with Appalachian Regional Healthcare (ARH) and local libraries facilitated private room usage for telehealth visits and integrated support services.\n    *   **Staff Training:** All program staff, including navigators, underwent rigorous training in HIPAA compliance, patient privacy protocols, and chronic care management principles to provide informed and respectful support.\n*   **Staffing and Resources:** The program operates with a dedicated team of 18 full-time equivalent (FTE) staff members, comprising 10 navigators, 2 Community Health Worker (CHW) leads, 1 evaluation manager, 3 administrative staff, and 2 IT specialists. Key partnerships with ARH clinics, local libraries, and the UK Telehealth Lab provided essential infrastructure and expertise. The total program budget for FY2024 was $600,000.\n*   **Contextual Factors:** The program operated within a dynamic environment. State policy changes supporting telehealth parity payments significantly expanded the availability of telehealth services from providers. However, the region continued to experience challenges such as ongoing flood recovery efforts and periodic power outages, which directly impacted internet connectivity and patient access, necessitating adaptable program responses.\n*   **Logic Model Reference:** A detailed logic model outlining inputs, activities, outputs, and short- to long-term outcomes for TeleCare Connect is provided in Appendix A. Further details on evaluation instruments are in Appendix B, and comprehensive data tables in Appendix C.\n\n*Sample phrasing:* \u201cIn 2024, TeleCare Connect served 1420 participants through Telehealth readiness screening, Navigator pre-visit coaching and reminders, Device lending (tablets + data), Library private room reservations, Broadband mapping and troubleshooting to achieve:\n\n*   **Completed telehealth visits:** Proportion of scheduled telehealth visits that are completed among enrolled patients.\n    *   **KPIs:** Telehealth completion rate (%), # completed telehealth visits\n    *   **Baseline:** 62% \u2192 **Endline:** 71% (n=3012)\n    *   **Disaggregation:** >30 miles completion rate: 66%; \u226430 miles completion rate: 73%; 65+ completion rate: 68%; Under 65 completion rate: 72%; Medicaid completion rate: 70%; Medicare completion rate: 69%; Commercial completion rate: 74%\n    *   **Themes:** Hands-on device coaching reduced login failures. Library private rooms increased privacy and confidence.\n    *   **Quotes:** \"Having someone show me how to click in made all the difference.\" \u2014 Client C-089 (consented).\n    *   **Equity Gap Analysis:** Seniors (65+) and those >30 miles had lower completion. Drivers: connectivity instability and tech comfort. Action: in-home setup visits for 65+ starting March 2025; expanded signal boosters in three libraries.\n    *   **Mixed/Negative Results:** What we learned: Completion still below 75% target. Why this matters: Missed care exacerbates chronic disease complications. What we are changing: Evening navigator hours and pre-visit test calls for all first-time users (Q1 2025).\n    *   **Evidence Tags:** EHR attendance export, Navigator log audit, Interview: Clinic Manager #2\n*   **Reduced no-show rates:** No-show rate for scheduled clinic and telehealth visits among enrolled patients.\n    *   **KPIs:** No-show rate (%)\n    *   **Baseline:** 28% \u2192 **Endline:** 16% (n=1420)\n    *   **Disaggregation:** >30 miles no-show: 18%; \u226430 miles no-show: 15%; Spanish no-show: 22%; English no-show: 16%\n    *   **Themes:** Reminder texts reduced day-of no-shows. Backup plan for in-person conversion helped during broadband outages.\n    *   **Quotes:** \"If the video fails, they switch me to a call right away\u2014no more missing the doctor.\" \u2014 Client C-231 (consented).\n    *   **Equity Gap Analysis:** Spanish speakers underrepresented and higher no-shows (22%). Plan to hire bilingual navigator and integrate interpreter scheduling by Q2 2025.\n    *   **Mixed/Negative Results:** What we learned: Language access gaps persist. Why this matters: Lower engagement risks widening disparities. What we are changing: Bilingual navigator hire approved; Spanish/English automated reminders (Q2 2025).\n    *   **Evidence Tags:** EHR attendance, Navigator logs, Focus Group: Library Staff\n*   **Patient activation:** Patient Activation Measure (PAM-10) level change among participants with matched surveys.\n    *   **KPIs:** % moving up \u22651 PAM level, Mean PAM level\n    *   **Baseline:** Mean 2.1 \u2192 **Endline:** Mean 2.5 (n=612)\n    *   **Disaggregation:** 65+ gain levels: 0.3; Under 65 gain levels: 0.5; Medicaid gain levels: 0.5; Medicare gain levels: 0.3\n    *   **Themes:** Simple checklists increased confidence logging in. Printed instructions helpful for low digital literacy.\n    *   **Quotes:** \"The step-by-step sheet stayed by my computer. I don\u2019t panic anymore.\" \u2014 Client C-477 (consented).\n    *   **Equity Gap Analysis:** Seniors advanced less in activation. Action: add in-home first-session setup and family caregiver coaching (Q2 2025).\n    *   **Mixed/Negative Results:** What we learned: Activation gains fell short by 3 points from target of 60%. Why this matters: Lower self-efficacy predicts future missed care. What we are changing: Navigator script revised with teach-back method, starting March 2025.\n    *   **Evidence Tags:** PAM-10, Navigator call audit, Interview: Navigator Lead\u201d\n\n*How to adapt for funders/board:* Align goals and activities with funded objectives and approved budget.\n\n---\n\n### 3. Evaluation Questions & Methodology (300\u2013500 words)\n\nHere we describe how we measured success by [brief description of indicators and how collected].\n\nThis evaluation aimed to systematically assess the effectiveness and impact of MHAN\u2019s TeleCare Connect program during FY2024. The primary evaluation questions guiding this assessment were:\n\n1.  To what extent did TeleCare Connect improve telehealth visit completion rates and reduce missed appointments among enrolled patients in Eastern Kentucky?\n2.  Did participation in TeleCare Connect enhance patient activation and digital literacy for health management, and were there differential impacts across demographic groups?\n3.  Which specific components of TeleCare Connect (e.g., navigator coaching, device lending, library access) were most and least helpful in achieving desired outcomes, and for whom?\n4.  What are the key barriers and facilitators experienced by patients in accessing and utilizing telehealth services through TeleCare Connect?\n\n**Evaluation Design and Approach:**\nA quasi-experimental evaluation design was employed, primarily utilizing a pre-post comparison for enrolled patients to track changes in visit completion, no-show rates, and patient activation. This approach allowed for cohort tracking of participants over the program period. While a true comparison group was not feasible given the program\u2019s community-wide access model, the evaluation focuses on contribution, not attribution, by measuring observable changes directly linked to program activities.\n\n**Data Sources:**\nA mixed-methods approach utilized both quantitative and qualitative data sources:\n*   **Electronic Health Records (EHR) Exports:** Provided data on appointment scheduling, attendance, completion rates, and visit types for TeleCare Connect patients.\n*   **Salesforce Navigator Logs:** Detailed navigator contacts, support activities, device lending records, and troubleshooting notes.\n*   **Patient Activation Measure (PAM-10):** Administered pre- and post-program to assess changes in patient activation levels.\n*   **Post-Visit Patient Surveys:** Short surveys collected immediate feedback on the usefulness of navigator support and technical experience after telehealth appointments.\n*   **Key Informant Interview Guides:** Structured interviews with clinic staff, library partners, and TeleCare Navigators explored operational insights, challenges, and perceived program impact.\n*   **Patient Focus Group/Interviews:** Gathered in-depth qualitative data on patient experiences, perceived benefits, and enduring barriers.\n\n**Sampling and Timing:**\n*   **Quantitative Data:** All 1,420 enrolled patients with completed pre-assessments were included in analyses for visit completion and no-show rates. PAM-10 data included 612 patients with matched pre- and post-surveys (43% response rate).\n*   **Qualitative Data:** A purposive sample of [Number] clinic managers and [Number] library staff were interviewed in [Month, Year]. [Number] TeleCare Navigators participated in a focus group in [Month, Year]. [Number] patients (stratified by geography and age) participated in individual interviews or focus groups in [Month, Year]. Patient satisfaction surveys were collected on an ongoing basis after telehealth visits (average response rate [X]%).\n\n**Data Quality Checks:**\nRigorous data quality checks were implemented, including:\n*   **Missing Data Review:** Assessment of missing data rates across all datasets and imputation strategies where appropriate.\n*   **Reliability Checks:** Cross-referencing data points between EHR exports and navigator logs to ensure consistency (e.g., visit completion status).\n*   **Spot Audits:** Random audits of navigator log entries against recorded patient interactions.\n*   **Data Cleaning Steps:** Standardized procedures for identifying and rectifying data entry errors or inconsistencies.\n\n**Ethics and Consent:**\nAll participants provided informed consent. For patient data, consent was obtained verbally via a standardized phone script and documented in Salesforce. All data was stored on HIPAA-compliant encrypted servers, and a Business Associate Agreement (BAA) was in place with partners sharing patient health information. An IRB review was not required for this program evaluation as it focused on program improvement using routinely collected data.\n\n**Equity and Participation:**\nAn equity lens was integrated into the evaluation from the outset.\n*   **Patient Advisory Council (PAC):** An 8-member PAC, comprising diverse community members, reviewed evaluation questions and contributed to the design of patient-facing surveys and interview guides to ensure cultural relevance and clarity.\n*   **Accessibility:** Large-print guides were available for PAM-10 administration. Provision was made for ASL interpreter scheduling when requested by participants for interviews or focus groups.\n*   **Disaggregation:** Data was disaggregated by key demographic indicators (age, insurance type, geography, language) to identify and understand equity gaps in outcomes.\n\n| Method                       | Sample/Response Rate                                   | Timeline                     | Purpose/Question(s) Informed                                                          |\n| :--------------------------- | :----------------------------------------------------- | :--------------------------- | :------------------------------------------------------------------------------------ |\n| EHR Exports                  | All 1,420 enrolled patients                            | FY2024 (Ongoing)             | Q1, Q2 (Completion, No-shows)                                                         |\n| Salesforce Navigator Logs    | All 1,420 enrolled patients                            | FY2024 (Ongoing)             | Q1, Q3, Q4 (Support activities, helpful components)                                   |\n| PAM-10 Survey                | 612 matched pre-post (43% response)                    | July 2023, June 2024         | Q2 (Patient activation)                                                               |\n| Post-Visit Patient Surveys   | [X]% average response rate (N=[Y] surveys)             | FY2024 (Ongoing)             | Q3, Q4 (Helpfulness, barriers/facilitators)                                           |\n| Key Informant Interviews     | [Number] Clinic Managers, [Number] Library Staff      | [Month, Year]                | Q3, Q4 (Operational insights, partner perspectives)                                   |\n| Patient Group Interviews     | [Number] (Purposive sample by age/geo)                   | [Month, Year]                | Q3, Q4 (Patient experiences, perceived benefits)                                      |\n\n*How to adapt for funders/board:* Keep design description concise, emphasize validity, consent, and alignment with grant indicators.\n\n---\n\n### 4. Findings by Outcome Area (400\u2013700 words per outcome)\n\n#### 4.1 Outcome: Completed Telehealth Visits\n\n*Outcome Definition:* The proportion of scheduled telehealth visits that are completed among enrolled patients, reflecting improved access and successful utilization of virtual care.\n*Indicator(s):* Telehealth Completion Rate (%), Number of Completed Telehealth Visits\n\n**Table 4.1: Telehealth Visit Completion Rates (FY2024)**\n\n| Indicator               | Target | Actual | % Achieved | Data Source         | Notes                                   |\n| :---------------------- | :----- | :----- | :--------- | :------------------ | :-------------------------------------- |\n| Telehealth Completion (%) | 75%    | 71%    | 95%        | EHR attendance export | Pre 62% \u2192 Post 71% (+9 points)          |\n| # Completed Telehealth  | 2,200  | 2,120  | 96%        | EHR attendance export | Across 1,420 patients                   |\n\n**Quantitative Results:**\nParticipants in the TeleCare Connect program demonstrated a 9-percentage point improvement in the completion rate for scheduled telehealth visits, rising from a baseline of 62% in Q1 FY2024 to an endline of 71% by Q4 (n=3,012 visits). While this represents robust improvement, it fell slightly short of the 75% target, achieving 95% of the set goal. The program facilitated a total of 2,120 completed telehealth visits across its 1,420 enrolled patients, approaching the target of 2,200.\n\n**Figure 4.1: Telehealth Visit Completion Rate Before and After Intervention**\n(Paired bar or line chart showing 62% pre-intervention and 71% post-intervention completion rates (n=3,012). Y-axis: Completion Rate (%), X-axis: Time Period (Pre/Post).)\n*Caption:* Participants showed a 9% improvement in telehealth visit completion from 62% (pre-program) to 71% (post-program) (n=3,012).\n\n**Qualitative Insights:**\n*   **Themes:** Navigator-led instruction and support significantly reduced technical login failures. The availability of private, internet-enabled rooms in partner libraries enhanced patient comfort and confidence during telehealth appointments. Patients frequently mentioned that knowing someone was there to troubleshoot reduced their anxiety.\n*   **Quote:** *\"Having someone show me how to click in made all the difference. I used to just give up, but now I know I can get help if it freezes.\"* \u2014 Client C-089 (consented)\n\n**Equity Lens:**\n*   **Disaggregation:**\n    *   Patients residing >30 miles from a clinic had a completion rate of 66%, compared to 73% for those \u226430 miles.\n    *   Patients aged 65 and older had a completion rate of 68%, slightly lower than the 72% for those under 65.\n    *   Medicaid (70%), Medicare (69%), and Commercial (74%) insurance groups showed varying, but generally high, completion rates, indicating broad program accessibility regardless of payer.\n*   **Interpretation of Gaps:** Seniors (65+) and individuals living further from urban centers showed lower completion rates. Possible drivers include greater technophobia among older adults, and more pronounced broadband instability in very rural areas, which could disrupt connections despite temporary device lending.\n*   **Actionable Responses:** MHAN is implementing in-home setup visits for seniors (65+) starting March 2025 to provide personalized device configuration and troubleshooting. We are also expanding signal boosters in three key library locations identified as serving areas with high numbers of patients >30 miles from clinics.\n\n**Mixed/Negative Results:**\n*   **What we learned:** Despite significant gains, the telehealth completion rate remained just below the 75% target.\n*   **Why this matters:** Each missed care opportunity can exacerbate chronic disease complications and undermine patient trust in telehealth as a viable care option.\n*   **What we are changing:** We will implement evening navigator hours (Monday\u2013Thursday until 8 pm) and pre-visit *test calls* for all first-time telehealth users by Q1 2025 to proactively address technical barriers before the actual appointment.\n*   **Evidence Tags:** EHR attendance export, Navigator log audit, Interview: Clinic Manager #2\n\n*How to adapt for funders/board:* Lead with grant KPIs; include 1-2 concise visuals; footnote methods; keep quotes brief.\n\n#### 4.2 Outcome: Reduced No-Show Rates\n\n*Outcome Definition:* The overall reduction in the proportion of scheduled medical appointments (both in-person clinic visits and telehealth visits) that enrolled patients fail to attend without prior cancellation, indicating improved patient adherence and engagement.\n*Indicator(s):* No-Show Rate (%)\n\n**Table 4.2: Program No-Show Rates (FY2024)**\n\n| Indicator      | Target | Actual | % Achieved | Data Source         | Notes                                |\n| :------------- | :----- | :----- | :--------- | :------------------ | :----------------------------------- |\n| No-Show Rate (%) | 18%    | 16%    | 112%       | EHR scheduling/attendance | Pre 28% \u2192 Post 16% (\u221212 points)      |\n\n**Quantitative Results:**\nThe TeleCare Connect program successfully reduced the overall no-show rate for all scheduled medical appointments by 12 percentage points, dropping from a baseline of 28% to an endline of 16% among the 1,420 enrolled patients. This achievement surpassed the target of 18%, indicating a strong positive impact on appointment adherence.\n\n**Figure 4.2: Comparison of Pre and Post Program No-Show Rates**\n(Bar chart showing 28% pre-program and 16% post-program no-show rates (n=1,420). Y-axis: No-Show Rate (%), X-axis: Time Period (Pre/Post).)\n*Caption:* The program significantly reduced the overall no-show rate from 28% to 16% for enrolled patients (N=1,420).\n\n**Qualitative Insights:**\n*   **Themes:** Automated reminder texts and personalized calls from navigators were frequently cited as crucial for reducing day-of no-shows. Additionally, the program's emphasis on creating a \"backup plan\" for in-person conversion when telehealth connectivity failed helped patients feel more secure and less likely to abandon an appointment.\n*   **Quote:** *\"If the video fails, they switch me to a call right away\u2014no more missing the doctor. It used to be I\u2019d just give up, but now I stick with it.\"* \u2014 Client C-231 (consented)\n\n**Equity Lens:**\n*   **Disaggregation:**\n    *   Patients residing >30 miles from a clinic still had a slightly higher no-show rate of 18% compared to 15% for those \u226430 miles, again pointing to persistent geographic access challenges.\n    *   A notable disparity was observed among the small subset of Spanish-speaking patients, who exhibited a higher no-show rate of 22% compared to 16% for English-speaking patients.\n*   **Interpretation of Gaps:** The higher no-show rate among Spanish speakers, coupled with their underrepresentation in the program (2%), suggests significant language access gaps, potentially impacting comprehension of reminders or comfort with navigating the appointment system.\n*   **Actionable Responses:** MHAN has approved the hiring of a bilingual navigator to directly support Spanish-speaking patients. We will also integrate Spanish/English automated appointment reminders by Q2 2025 to ensure equitable messaging.\n\n**Mixed/Negative Results:**\n*   **What we learned:** Despite overall improvement, language access gaps remain a significant barrier, particularly for Spanish-speaking patients, leading to higher no-show rates within this subgroup.\n*   **Why this matters:** Lower engagement stemming from language barriers risks widening health disparities and limits the program's ability to serve the entire community effectively.\n*   **What we are changing:** The bilingual navigator hire has been approved, and we are actively working with our EHR vendor to implement automated Spanish/English appointment reminders by Q2 2025.\n*   **Evidence Tags:** EHR attendance, Navigator logs, Focus Group: Library Staff\n\n*How to adapt for funders/board:* Lead with grant KPIs; include 1-2 concise visuals; footnote methods; keep quotes brief.\n\n#### 4.3 Outcome: Patient Activation\n\n*Outcome Definition:* The level of confidence, knowledge, and skills an individual possesses to manage their own health, as measured by movement on the Patient Activation Measure (PAM-10).\n*Indicator(s):* % Moving up \u22651 PAM Level, Mean PAM Level\n\n**Table 4.3: Patient Activation Measure (PAM-10) Results (FY2024)**\n\n| Indicator                  | Target | Actual | % Achieved | Data Source | Notes                                 |\n| :------------------------- | :----- | :----- | :----- | :---------- | :------------------------------------ |\n| % Moving up \u22651 PAM Level   | 60%    | 57%    | 95%    | PAM-10 survey | Matched n=612                         |\n| Mean PAM Level             | 2.5    | 2.5    | 100%   | PAM-10 survey | Baseline 2.1 \u2192 Endline 2.5            |\n\n**Quantitative Results:**\nThe TeleCare Connect program demonstrated positive, albeit slightly under target, improvements in patient activation. Among the 612 participants with matched pre- and post-PAM-10 surveys, 57% moved up at least one PAM level. This was just shy of the 60% target. The mean PAM level for this cohort increased from 2.1 at baseline to 2.5 at endline, successfully meeting the program\u2019s target.\n\n**Figure 4.3: Change in Mean Patient Activation Measure (PAM) Level**\n(Stacked bar chart or column chart showing mean PAM level at baseline (2.1) and endline (2.5) for n=612 matched participants.)\n*Caption:* The mean PAM level increased from 2.1 to 2.5 among matched participants (n=612), demonstrating improved patient activation.\n\n**Qualitative Insights:**\n*   **Themes:** Participants frequently reported that simple, step-by-step checklists provided by navigators significantly increased their confidence in logging into telehealth appointments. Printed instructions were especially valued by those with lower digital literacy, serving as readily accessible memory aids.\n*   **Quote:** *\"The step-by-step sheet stayed by my computer, right next to my pharmacy list. I don\u2019t panic anymore if the doctor asks me to click something new because I know I have my instructions.\"* \u2014 Client C-477 (consented)\n\n**Equity Lens:**\n*   **Disaggregation:**\n    *   Seniors (65+) showed an average gain of 0.3 PAM levels, which was lower than the 0.5 PAM level gain observed in participants under 65.\n    *   Medicaid recipients experienced an average gain of 0.5 PAM levels, while Medicare recipients showed a 0.3 PAM level gain, aligning with the pattern observed with age.\n*   **Interpretation of Gaps:** The lower activation gains among seniors (65+), predominantly Medicare recipients, suggest that current strategies may not fully address their unique learning styles or technological comfort levels. This may be linked to initial tech anxiety or less consistent practice between visits.\n*   **Actionable Responses:** To address this, MHAN will introduce in-home first-session setup for seniors and offer direct family caregiver coaching starting Q2 2025, empowering support networks to assist with ongoing tech challenges.\n\n**Mixed/Negative Results:**\n*   **What we learned:** While the mean PAM level target was met, the percentage of patients moving up at least one PAM level fell slightly short of the 60% target, indicating there\u2019s room for deeper activation.\n*   **Why this matters:** Lower self-efficacy in health management can predict future missed care opportunities and poorer chronic disease outcomes. Ensuring robust activation is crucial for long-term health.\n*   **What we are changing:** The navigator script has been revised to incorporate the \"teach-back\" method more consistently, ensuring patients fully understand and can demonstrate how to perform key digital health tasks, starting March 2025.\n*   **Evidence Tags:** PAM-10 survey, Navigator call audit, Interview: Navigator Lead\n\n*How to adapt for funders/board:* Lead with grant KPIs; include 1-2 concise visuals; footnote methods; keep quotes brief.\n\n---\n\n### 5. Discussion/Interpretation (300\u2013500 words)\n\nHere we make sense of why results look the way they do.\n\nThe FY2024 evaluation of MHAN\u2019s TeleCare Connect program demonstrates a strong connection between program activities and observed outcomes. The program\u2019s theory of change\u2014that hands-on technical support and stable access reduce missed visits and increase patient readiness for telehealth\u2014was largely validated. Pre-visit coaching by navigators, with their focused instruction and troubleshooting, directly contributed to the increased confidence reported by patients and was a primary driver for the improved telehealth visit completion rates and patient activation. Similarly, the device lending library directly removed a significant access barrier, particularly for patients who lacked suitable devices or reliable data plans.\n\n**Triangulation:**\nKey findings were robustly supported by triangulated data sources. Improvements in EHR-recorded telehealth completion rates were corroborated by positive feedback in post-visit patient surveys regarding navigator support, and by navigator logs detailing successful technical assistance. The qualitative insights from patient interviews, which highlighted broadband issues in specific geographic clusters, aligned with EHR data showing lower completion rates among patients residing >30 miles from clinics. This consistent narrative across different data types strengthens the validity of our conclusions.\n\n**External Factors:**\nSeveral external factors influenced program delivery and outcomes. The state policy allowing telehealth parity payments significantly expanded the range of providers offering telehealth, thereby increasing opportunities for TeleCare Connect patients to utilize the service. This policy created a favorable environment for program success. Conversely, the region's ongoing recovery from floods and persistent, though intermittent, power outages periodically disrupted broadband service, particularly affecting patients in the most remote areas. For instance, a noticeable dip in telehealth completion rates in February 2024 was directly correlated with a series of severe winter storms causing widespread power outages. This underscores the fragility of digital access in rural contexts.\n\n**Surprises:**\nOne notable surprise was the exceptionally high success rate and positive patient feedback associated with using designated private rooms in partner libraries for telehealth visits. While anticipated to be helpful, the extent to which patients preferred and benefited from these spaces\u2014citing increased privacy, fewer interruptions, and more reliable internet\u2014was beyond initial expectations. This was confirmed by speed test logs from library locations showing consistent high-bandwidth connections, and by appointment completion timestamps in the EHR, which indicated fewer technical dropouts in these settings. This suggests that the structured environment provided a critical psychological and technical boost beyond simply providing a device.\n\n**Learning Stance \u2013 What We Learned, Why It Matters, What We\u2019re Changing:**\n\n*   **What we learned:** Dedicated, personalized technical and logistical support from navigators is indispensable for reducing barriers to telehealth adoption among rural, low-digital-literacy populations.\n*   **Why this matters:** Without this hands-on support, the promise of telehealth\u2014especially for chronic disease management\u2014remains inaccessible to those who need it most, perpetuating health disparities.\n*   **What we are changing:** We are formalizing the \"Navigator Support Plan\" to include dedicated follow-up for new users post-first visit and exploring partnerships to expand technical support into patients' homes for device setup.\n\n*   **What we learned:** Geographic and language-based disparities persist in telehealth completion and no-show rates.\n*   **Why this matters:** These disparities indicate that the benefits of TeleCare Connect are not reaching all community members equitably, risking the widening of the digital health divide.\n*   **What we are changing:** We are actively recruiting a bilingual navigator and implementing multi-language automated reminders to address identified linguistic barriers. We are also deploying additional signal boosters in strategically selected community hubs to improve connectivity in underserved areas.\n\n*How to adapt for funders/board:* Emphasize accountability, practical lessons, and planned course corrections.\n\n---\n\n### 6. Recommendations & Next Steps (250\u2013400 words)\n\nThe following recommendations are designed to build upon the successes of TeleCare Connect in FY2024, address identified gaps, and maximize program impact in the coming year. Each recommendation is linked to specific insights from this evaluation and aims to enhance equity, efficiency, and effectiveness.\n\n| Recommendation                                               | Owner/Lead              | Timeframe (immediate/3\u20136 months/12 months) | Resource Needs (staff hours, budget)                                                    | Feasibility (H/M/L) | Success Measure                                                                          |\n| :----------------------------------------------------------- | :---------------------- | :----------------------------------------- | :-------------------------------------------------------------------------------------- | :------------------ | :--------------------------------------------------------------------------------------- |\n| **1. Expand Evening Navigator Hours:** Implement evening support (Mon-Thu until 8 pm) to better accommodate patient work schedules. | CHW Leads             | Within 3 months (Q1 2025)             | 20 hours/week (equivalent to 0.5 (FTE) Navigator; ~ $25K/year for new/overtime staff)  | High                | 15% increase in appointments scheduled/completed outside 9-5 hours; Patient satisfaction scores (evening) > 90% |\n| **2. Enhance Language Accessibility:** Hire a dedicated bilingual (Spanish/English) navigator and integrate multi-language automated reminders. | CHW Leads, Admin Staff | Within 6 months (Q2 2025)             | 1 FTE Navigator (~$50K/year); EHR vendor fees for multi-language reminders (~$5K one-time) | Medium              | 25% increase in Spanish-speaking patient enrollment; 10% reduction in no-show rate for Spanish-speaking patients |\n| **3. Bolster Frontier Broadband Access:** Deploy three additional signal boosters in partner library private rooms in high-need, rural areas. | IT Specialists          | Within 6 months (by May 2025)         | $15K (3 boosters @ $5K each); 40 staff hours (IT installation)                          | High                | 5% increase in telehealth completion for patients >30 miles from clinics; Reduced reported connectivity issues |\n| **4. Implement In-Home Senior Support:** Pilot in-home device setup and first-telehealth-session support for older adults (65+) and offer caregiver coaching. | Navigators, CHW Leads | Within 6 months (Q2 2025)             | 2 Navigators for 10 hours/week (dedicated to in-home); mileage reimbursement (~$10K/year)  | Medium              | 15% increase in PAM level gains for 65+ cohort; 10% reduction in tech support calls from 65+ patients |\n| **5. Revise Navigator Script with Teach-Back:** Integrate the teach-back method across all navigator interactions, with focused training. | CHW Leads             | Immediate (March 2025)              | 20 staff hours (training development/delivery)                                          | High                | 10% increase in patient self-reported confidence in using telehealth platforms; Reduced repeat troubleshooting calls for same issue |\n| **6. Establish Formal Caregiver Touchpoints:** Develop standardized protocols and materials for engaging family caregivers in supporting patient telehealth literacy. | Program Manager         | Within 3 months (Q1 2025)             | 30 staff hours (material development, training); small print budget (~$500)                 | High                | 20% increase in caregiver engagement (e.g., calls/sessions); Qualitative themes of improved family support |\n\n*How to adapt for funders/board:* Flag any budget-neutral options; identify items requiring reallocation or future grant funding.\n\n---\n\n### 7. Limitations (150\u2013250 words)\n\nHere\u2019s what we couldn\u2019t measure or are less sure about.\n\nThis evaluation provides valuable insights into the TeleCare Connect program\u2019s performance in FY2024, but it is important to acknowledge certain limitations that may influence the interpretation of results:\n\n1.  **Sample Size and Representativeness for PAM-10:** While overall program reach was robust, the matched PAM-10 survey data (n=612) represents 43% of enrolled patients. Non-response was higher among the oldest patients (75+), which may introduce a slight positive bias in activation gains, as those less comfortable with surveys might also be less activated, potentially leading to an overestimation of average activation improvement. Sensitivity checks were conducted to assess the impact of this missing data.\n2.  **Lack of a Counterfactual Group:** The evaluation employed a pre-post design without a concurrent comparison group drawn from a similar population not receiving TeleCare Connect services. This limits our ability to definitively attribute all observed changes solely to the program, as other external factors (e.g., general trends in telehealth adoption, broader community resources) could have played a role. However, the internal consistency of findings and direct patient feedback strongly indicate program contribution.\n3.  **Data Quality Issues / Self-Reported Bias:** While EHR data is generally reliable, some qualitative data relies on self-reported patient experiences, which can be subject to recall bias or social desirability bias. Specifically, patient satisfaction with navigators might be slightly inflated. Efforts were made to mitigate this through anonymous survey options and careful probing during interviews.\n4.  **Short Follow-Up Window:** The evaluation covered one fiscal year (12 months), providing a snapshot of immediate and short-term impacts. Longer-term effects on chronic disease management or sustained digital literacy beyond the device lending period could not be fully assessed.\n5.  **External Influences:** As noted in the discussion, regional flood recovery efforts and power outages were significant external variables. While their impact was acknowledged, precisely quantifying their influence on individual patient outcomes or isolating program effects during these periods proved challenging.\n6.  **Ethics/Consent Status:** All data collection adhered to ethical guidelines, obtaining explicit consent from participants and ensuring HIPAA-compliant data handling. Consent for all interviewees and survey respondents is logged and securely stored on encrypted servers.\n\n*How to adapt for funders/board:* Be transparent and concise; emphasize mitigation steps.\n\n---\n\n### 8. Appendices\n\n**Checklist of Appendices to be Included:**\n\n*   [ ] **Appendix A: TeleCare Connect Logic Model**\n    *   (Detailed visual representation of program inputs, activities, outputs, and short-, medium-, and long-term outcomes)\n*   [ ] **Appendix B: Data Collection Instruments**\n    *   (Copies of patient post-visit surveys, key informant interview guides, patient focus group questions, PAM-10 survey language, and navigator call scripts related to data collection)\n*   [ ] **Appendix C: Detailed Data Tables**\n    *   (Comprehensive quantitative data tables disaggregated by all key demographic subgroups (age, insurance type, geography, language, veteran status) for all KPIs and outcome indicators. Includes baseline, endline, and change metrics.)\n*   [ ] **Appendix D: Sample Consent Forms & Data Privacy Statement**\n    *   (Examples of patient consent forms, verbal consent scripts, and MHAN\u2019s data privacy and security policy.)\n*   [ ] **Appendix E: Complete Indicator List**\n    *   (A full list of all indicators tracked, including precise definitions, calculation methodologies, and data sources.)\n*   [ ] **Appendix F: Additional Participant Quotes**\n    *   (A curated selection of additional qualitative quotes with appropriate consent documentation, providing further depth to the findings.)\n*   [ ] **Appendix G: Data Quality Checks Documentation**\n    *   (Summary of missing data rates, reliability check results, and data cleaning procedures employed.)\n\n---\n\n**How to refine this template:**\n\n*   Ask: 'Shorten the methodology to 200 words.'\n*   Ask: 'Add a visual for the retention KPI and write a caption.'\n*   Ask: 'Rewrite for a WARM tone for a community meeting handout.'\n*   Ask: 'Focus the recommendations section on only 3 key actions.'\n*   Ask: 'Provide examples specific to rural broadband challenges.'",
      "timestamp": "2025-11-02T14:07:06.634015Z",
      "duration_seconds": 41.56,
      "tokens": {
        "input": 4797,
        "output": 9348,
        "total": 14145
      },
      "cost_usd": 0.006328,
      "success": true,
      "evaluation": {
        "overall_score": 8.6,
        "criteria_scores": {
          "tone": 9,
          "completeness": 9,
          "usefulness": 9,
          "accuracy": 8,
          "authenticity": 8
        },
        "reasoning": "This is an exceptionally thorough and professional evaluation report template that demonstrates deep understanding of nonprofit evaluation practices. It successfully integrates all requested elements\u2014equity prompts, funder adaptations, plain language callouts, and concrete examples\u2014in a formal tone appropriate for government funders and board audiences. The template is highly usable with clear fill-in prompts and realistic rural health context.",
        "strengths": [
          "Exemplary integration of equity lens throughout\u2014disaggregation prompts, gap analysis, and actionable responses are embedded in every outcome section, not treated as afterthought",
          "Concrete, realistic examples with appropriate specificity (e.g., '62% \u2192 71% completion rate,' client quotes with consent IDs, geographic breakdowns) that model exactly what users should produce",
          "Excellent 'How to adapt for funders/board' guidance in each section provides practical translation between internal learning and external accountability",
          "Strong formal tone maintained consistently\u2014professional, precise, evidence-based language appropriate for government contracts and Medicaid MCOs without being stilted",
          "Comprehensive methodology section with detailed data quality checks, ethics documentation, and participatory elements (Patient Advisory Council) that meet rigorous funder standards",
          "Recommendations table is exceptionally practical with owners, timelines, resource needs, feasibility ratings, and success measures\u2014directly actionable",
          "Mixed/negative results framing ('What we learned/Why this matters/What we're changing') models constructive accountability perfectly",
          "Table shells and visual placeholders include helpful specifics (chart types, caption prompts, n-sizes) that guide non-evaluators"
        ],
        "weaknesses": [
          "Minor redundancy: Program Overview section duplicates some outcome details that appear later in Findings\u2014could streamline by using briefer outcome summaries in Overview and reserving full KPI tables for Section 4",
          "The template occasionally blurs the line between 'template with prompts' and 'completed example'\u2014some sections read as if already filled in rather than providing [BRACKETED PROMPTS], which might confuse users about what to replace vs. what to keep",
          "Appendix checklist could benefit from brief guidance on *how* to create a logic model or calculate response rates for users with limited evaluation capacity",
          "A few technical terms (e.g., 'teach-back method,' 'contribution not attribution') could use embedded plain-language definitions even though context makes them clear"
        ],
        "evaluator_model": "claude-sonnet-4.5"
      }
    },
    {
      "scenario_id": "scenario_2",
      "model": "gpt5",
      "model_display_name": "ChatGPT (GPT-5)",
      "content": "COMPREHENSIVE EVALUATION REPORT TEMPLATE\nMountain Health Access Network (MHAN) \u2014 TeleCare Connect\nReport covers FY2024 (July 1, 2023\u2013June 30, 2024)\nGeographic scope: Eastern Kentucky (Perry, Knott, Letcher, and Breathitt counties)\nPage target: 15\u201320 pages\n\nFront Matter (fill-in fields)\n- Report title: [Mountain Health Access Network (MHAN) \u2014 TeleCare Connect FY2024 Evaluation Report]\n- Prepared by: Dana Whitaker, Director of Programs\n- In collaboration with: Bluegrass Evaluation Collaborative, LLC\n- Date: 2024-08-15\n- Program: TeleCare Connect (telehealth readiness, device lending, navigator support)\n- Report covers: FY2024 (July 1, 2023\u2013June 30, 2024)\n- Geographic scope: Eastern Kentucky (Perry, Knott, Letcher, and Breathitt counties)\n- TONE: FORMAL (grant/board-facing, neutral)\n- Audiences and uses:\n  - Primary audience: [MHAN operations and navigator teams] \u2014 [Improve delivery, refine workflows, target outreach]\n  - Secondary audience(s): [Appalachian Regional Healthcare (ARH) clinics and public libraries] \u2014 [Coordinate patient access and space/resources]\n  - Funders/Board: KY Cabinet for Health and Family Services; Anthem Medicaid; MHAN Board of Directors \u2014 [Accountability to grant objectives, strategic planning]\n- Contact for questions: [Name, title, email, phone]\n\nIn plain language: \u201cThis front page tells readers what program we evaluated, when and where it ran, and who the report is for.\u201d\n\nHow to adapt for funders/board: Add grant number(s), award period, and an \u201cAt-a-Glance\u201d KPI box showing 3\u20135 grant metrics with targets vs. actuals.\n\nAudiences and Uses (confirm/adjust as needed)\n- Primary audience and uses: [PRIMARY AUDIENCE: Program staff and leadership] \u2014 [Use to improve navigator workflows, prioritize equity gaps, plan 2025 resources]\n- Secondary audience(s) and uses: [ARH clinics, libraries, community partners] \u2014 [Coordinate scheduling, room access, and broadband solutions]\n- Funders/Board: KY Cabinet for Health and Family Services; Anthem Medicaid; MHAN Board of Directors \u2014 [Demonstrate outcomes, cost-effectiveness, and lessons learned]\n\nIf key details are missing, ask these five questions, then proceed:\n1) Primary audience and uses? [e.g., program staff to improve delivery; leadership to inform planning]\n2) Funders/board version needed? [Yes/No; which funder/board?]\n3) Key demographics for equity breakdowns? [e.g., age, race/ethnicity, income, language, zip code]\n4) Main data sources available? [e.g., surveys, interviews, admin data, observations]\n5) Team capacity? [TEAM SIZE/RESOURCES: e.g., 3 staff, part-time evaluator, $50K program budget]\n\nSECTION 1) EXECUTIVE SUMMARY (350\u2013600 words)\nPurpose\n- Program purpose and who it serves: Reduce missed appointments and improve chronic disease management by enabling rural residents to access telehealth reliably.\n- Service area: Eastern Kentucky (Perry, Knott, Letcher, Breathitt).\n- Timeframe: FY2024 (July 1, 2023\u2013June 30, 2024).\n\nReach and participation (example values; replace or confirm)\n- Total enrolled participants: 1,420 enrolled patients (65% Medicaid; 24% age 65+; 2% Spanish-speaking; 6% veterans).\n- Engagement: Average 3 navigator contacts per participant; 1.8 telehealth visits scheduled; 1.3 completed per participant.\n\nTop findings (headline outcomes)\n- Completion rate for scheduled telehealth visits rose from 62% to 71% (+9 points; n=3,012 visits).\n- No-show rate fell from 28% to 16% among enrolled patients (n=1,420).\n- Patient activation: 57% moved up \u22651 Patient Activation Measure (PAM-10) level (n=612 matched surveys).\n- Participant voice: \u201cHaving someone show me how to click in made all the difference.\u201d \u2014 Client C-089 (consented).\n\nHigh-level recommendations (time-bound; ownership assigned in Section 6)\n- Add evening navigator hours (Mon\u2013Thu until 8 pm) by Q1 2025.\n- Integrate bilingual text reminders and American Sign Language (ASL) interpreter scheduling by Q2 2025.\n- Deploy three additional signal boosters to library private rooms by May 2025.\n\nOverall assessment/learning stance\n- Navigator coaching, device lending, and secure, private access points improved visit completion and patient activation. Gaps persist among seniors (65+) and patients living >30 miles from clinics due to broadband instability and lower comfort with technology. Addressing language access and first-time user support is essential to close equity gaps.\n\nIn plain language: \u201cThis section tells busy readers what changed, for whom, and what we\u2019ll do next.\u201d\n\nHow to adapt for funders/board: Lead with the three strongest outcome statements tied to grant KPIs. Keep to one page. If available, add cost-per-completed telehealth visit and cost per activation gain.\n\nConcrete example paragraph (model the level of specificity and tone)\n\u201cIn FY2024, TeleCare Connect served 1,420 patients across four Eastern Kentucky counties. Telehealth visit completion increased from 62% to 71% (+9 points; n=3,012 visits), while the no-show rate fell from 28% to 16%. Among 612 patients with matched PAM-10 surveys, 57% moved up at least one activation level (mean level 2.1 to 2.5). Patients attributed success to hands-on device coaching and access to private rooms at partner libraries. However, completion lagged for seniors (68%) and those >30 miles from clinics (66%), largely due to broadband issues. To close these gaps, MHAN will extend evening navigator hours by Q1 2025, implement bilingual reminders and integrated interpreter scheduling by Q2 2025, and install three signal boosters in library rooms by May 2025.\u201d\n\nPrompts for completion\n- [Summarize purpose and need in 2\u20133 sentences]\n- [List total participants and key demographics]\n- [State 2\u20133 headline findings with numbers and n-sizes]\n- [Include 1\u20132 short quotes with consent status]\n- [List 3 prioritized recommendations with timelines]\n- [Brief statement on equity gaps and next steps]\n\nSECTION 2) PROGRAM OVERVIEW (300\u2013450 words)\nGoals and theory of change\n- Goal: Increase reliable access to telehealth to reduce missed appointments and improve chronic care outcomes.\n- Theory of change: Hands-on tech support, reliable connectivity, and patient coaching reduce missed visits and increase readiness for telehealth engagement.\n\nTarget population and eligibility\n- Adults and seniors in remote communities within Perry, Knott, Letcher, and Breathitt counties.\n- Barriers include connectivity, device access, digital literacy, and transportation backup when telehealth fails.\n\nCore activities and dosage\n- Navigator pre-visit coaching, test calls, and multichannel reminders before every telehealth appointment.\n- Device lending (tablets + data plans) up to 90 days.\n- On-demand technical assistance and printed step-by-step guides.\n- Library private room reservations and signal booster access.\n- Staff trained in Health Insurance Portability and Accountability Act (HIPAA) and chronic care protocols.\n\nStaffing/resources\n- 18 full-time equivalents (FTE): 10 navigators, 2 Community Health Worker (CHW) leads, 1 evaluation manager, 3 admin, 2 IT.\n- Partnerships: ARH clinics, public libraries, University of Kentucky (UK) Telehealth Lab.\n- Annual budget: $600,000; device library: 120 tablets.\n\nContext\n- State policy maintained telehealth parity payments.\n- Flood recovery and periodic power outages affected connectivity in select months.\n\nSample phrasing and KPI framing (adapt as needed)\n\u201cIn 2024, TeleCare Connect served 1,420 participants through [\u2018Telehealth readiness screening,\u2019 \u2018Navigator pre-visit coaching and reminders,\u2019 \u2018Device lending (tablets + data),\u2019 \u2018Library private room reservations,\u2019 \u2018Broadband mapping and troubleshooting\u2019] to achieve:\n- Outcome 1: Completed telehealth visits (proportion of scheduled telehealth visits completed among enrolled patients).\n  - KPI: Telehealth completion rate (%) \u2014 Target 75; Actual 71 (95% of target). Data source: EHR (Electronic Health Record) attendance export. Note: Pre 62% \u2192 Post 71% (+9 points; n=3,012 visits).\n- Outcome 2: Reduced no-show rates (scheduled clinic and telehealth visits among enrolled patients).\n  - KPI: No-show rate (%) \u2014 Target 18; Actual 16 (112% of target). Data source: EHR scheduling/attendance.\n- Outcome 3: Patient activation (Patient Activation Measure, PAM-10).\n  - KPI: % moving up \u22651 PAM level \u2014 Target 60; Actual 57 (95% of target). Data source: PAM-10 survey (n=612).\u201d\n\nIn plain language: \u201cThis section explains who we serve, what we do, and the results we aim for.\u201d\n\nHow to adapt for funders/board: Map each activity to a funded objective and show target vs. actual for each KPI, citing its data source.\n\nPrompts for completion\n- [Briefly describe program need and goals]\n- [Confirm target population and eligibility criteria]\n- [List activities and typical participant dosage]\n- [Summarize staffing, partnerships, and budget]\n- [Contextual factors that influenced operations in FY2024]\n- [Point to Appendices A\u2013C for logic model, instruments, and data tables]\n\nSECTION 3) EVALUATION QUESTIONS & METHODOLOGY (300\u2013500 words)\nEvaluation questions (select 3\u20135)\n- [To what extent did participants improve in telehealth visit completion?]\n- [How did no-show rates change among enrolled participants?]\n- [To what extent did patient activation (PAM-10) improve, and for whom?]\n- [Which components (coaching, device lending, library rooms) were most/least helpful and for whom?]\n- [What barriers limited results for seniors, Spanish speakers, and those >30 miles from clinics?]\n\nDesign/approach\n- Approach: Pre\u2013post design with cohort tracking; contribution, not attribution.\n- Comparison: [If any, describe. If none, explain why.]\n- Triangulation: Quantitative EHR/PAM-10, navigator logs, and qualitative interviews/focus groups.\n\nData sources\n- EHR exports (attendance and no-show data).\n- Salesforce navigator logs (contacts, coaching, technical issues).\n- PAM-10 (Patient Activation Measure, 10-item) baseline and follow-up surveys.\n- Post-visit text/phone survey (satisfaction, barriers).\n- Key informant interview guide (navigators, library staff, clinic managers).\n\nSampling and timing\n- [Describe who was included, how many, and when data were collected; note response rates for PAM-10 and post-visit survey.]\n- [Example: PAM-10 matched n=612 (43% of eligible), post-visit survey n=[XX], response rate [XX]%.]\n\nData quality checks\n- Missing data review and imputation thresholds.\n- Reliability checks (internal consistency for PAM-10; cross-check navigator logs with EHR timestamps).\n- Spot audits of 10% of navigator records.\n- Data cleaning steps documented in Appendix E.\n\nEthics/consent and privacy\n- Consent: Verbal consent via phone script; consent logged in Salesforce.\n- Privacy: HIPAA-compliant storage; Business Associate Agreements (BAA) with partners.\n- Institutional Review Board (IRB): [Not required/non-human subjects per [X] determination.]\n\nEquity and participation\n- Patient Advisory Council (8 members) reviewed tools and preliminary charts in July 2024.\n- Large-print guides; ASL interpreter scheduling as needed; bilingual survey where feasible.\n\nIn plain language: \u201cWe measured success by tracking completed telehealth visits, no-shows, and activation scores, and by asking patients and staff what helped and what got in the way.\u201d\n\nTable shell (Methods overview)\n| Method | Sample/Response Rate | Timeline | Purpose/Questions Informed |\n|-------|----------------------|---------|----------------------------|\n| EHR attendance export | [n=1,420; 100% roster] | [Quarterly pulls] | Telehealth completion; no-show trends |\n| Salesforce navigator logs | [n=1,420; 95% complete] | [Ongoing; monthly QA] | Engagement dosage; barriers/supports |\n| PAM-10 surveys | [n=612 matched; 43% RR] | [Baseline, 60\u201390 days] | Activation gains; subgroup differences |\n| Post-visit survey | [n=[XX]; [XX]% RR] | [Within 72 hours] | Satisfaction; immediate barriers |\n| Key informant interviews | [n=[XX]] | [Q3\u2013Q4 FY24] | Component value; improvement ideas |\n\nHow to adapt for funders/board: Keep to one short paragraph emphasizing validity, consent, and alignment with grant indicators. Move full methodological detail to appendices.\n\nSECTION 4) FINDINGS BY OUTCOME AREA (400\u2013700 words per outcome)\nInstructions: Repeat the structure below for each outcome:\n- Outcome A: Telehealth visit completion\n- Outcome B: Reduced no-show rates\n- Outcome C: Patient activation (PAM-10)\n\nOutcome A: Telehealth Visit Completion\nOutcome definition and indicator(s)\n- Definition: Proportion of scheduled telehealth visits completed among enrolled patients.\n- Indicators: Telehealth completion rate (%); number of completed telehealth visits.\n\nQuantitative results\nKPI table shell\n| Indicator | Target | Actual | % Achieved | Data Source | Notes |\n|----------|--------|--------|-----------|-------------|-------|\n| Telehealth completion rate (%) | 75 | 71 | 95 | EHR attendance export | Pre 62% \u2192 Post 71% (+9 points; n=3,012 visits) |\n| # completed telehealth visits | 2,200 | 2,120 | 96 | EHR attendance export | Across 1,420 patients |\n\nVisual placeholders\n- Figure A1: Pre vs. post telehealth completion rate (paired bars).\n  Caption: \u201cTelehealth completion increased from 62% to 71% (+9 points; n=3,012 visits). Source: EHR attendance export.\u201d\n- Figure A2: Completion rate by distance to clinic (>30 miles vs. \u226430 miles) (bar chart).\n  Caption: \u201cCompletion lower for patients >30 miles (66%) vs. \u226430 miles (73%). Source: EHR; disaggregation by geocoded distance.\u201d\n- Figure A3: Completion rate by age group (<65 vs. 65+) (bar chart).\n  Caption: \u201cSeniors (65+) completed 68% vs. 72% for <65. Source: EHR; age from admin records.\u201d\n\nQualitative insights\n- Themes (evidence tags):\n  - Hands-on device coaching reduced login failures (Navigator log audit; Interview: Navigator Lead).\n  - Library private rooms increased privacy and confidence (Focus Group: Library Staff).\n- Quote placeholders:\n  - \u201c[Having someone show me how to click in made all the difference.] \u2014 Client C-089 (consented)\u201d\n  - \u201c[I knew the room was private and the Wi-Fi was strong, so I wasn\u2019t nervous.] \u2014 Client [ID], (consented)\u201d\n\nEquity lens\n- Disaggregate by key demographics (prompts):\n  - Age (65+ vs. <65) \u2014 [Insert rates and gap]\n  - Distance to clinic (>30 miles vs. \u226430 miles) \u2014 [Insert rates and gap]\n  - Insurance (Medicaid, Medicare, Commercial) \u2014 [Insert rates and gap]\n  - Language (Spanish vs. English) \u2014 [Insert rates and gap if available]\n- Interpretation prompts:\n  - Whose outcomes improved least? [e.g., seniors and those >30 miles]\n  - Possible drivers? [Broadband reliability; digital confidence]\n  - Actionable responses? [In-home setup visits for 65+; expand signal boosters in libraries]\n\nMixed/negative results framing\n- What we learned: [Completion increased to 71% but remains below 75% target.]\n- Why this matters: [Incomplete visits reduce timely care for chronic conditions.]\n- What we\u2019re changing: [Evening navigator hours; mandatory pre-visit test calls for first-time users by Q1 2025.]\n\nEvidence tags\n- EHR attendance export; Navigator log audit; Interview: Clinic Manager #2; Focus Group: Library Staff.\n\nHow to adapt for funders/board: Lead with KPI table and one chart. Keep quotes to one line and footnote data sources. Note percent of target achieved.\n\nConcrete example paragraph (specificity model for an outcome)\n\u201cTelehealth completion improved from 62% to 71% (+9 points; n=3,012 visits), reaching 95% of the 75% target. Gains were strongest for patients within 30 miles of a clinic (73%), while those farther away completed 66%. Seniors completed 68% vs. 72% for younger adults. Interviews indicate device coaching and library rooms reduced login failures and anxiety, but storm-related outages in February 2024 suppressed completion in remote hollers. To close gaps, MHAN will implement in-home first-session setup for seniors and add three signal boosters in partner libraries.\u201d\n\nOutcome B: Reduced No-Show Rates\nOutcome definition and indicator(s)\n- Definition: No-show rate for scheduled clinic and telehealth visits among enrolled patients.\n- Indicator: No-show rate (%).\n\nQuantitative results\nKPI table shell\n| Indicator | Target | Actual | % Achieved | Data Source | Notes |\n|----------|--------|--------|-----------|-------------|-------|\n| No-show rate (%) | 18 | 16 | 112 | EHR scheduling/attendance | Pre 28% \u2192 Post 16% (\u221212 points; n=1,420) |\n\nVisual placeholders\n- Figure B1: No-show rate pre vs. post (line chart).\n  Caption: \u201cNo-show rate decreased from 28% to 16% (\u221212 points; n=1,420). Source: EHR scheduling/attendance.\u201d\n- Figure B2: No-show by language (bar chart).\n  Caption: \u201cSpanish speakers 22% vs. English speakers 16%. Source: EHR; language from intake.\u201d\n- Figure B3: No-show by distance to clinic (bar chart).\n  Caption: \u201c>30 miles: 18% vs. \u226430 miles: 15%. Source: EHR.\u201d\n\nQualitative insights\n- Themes:\n  - Reminder texts reduced day-of no-shows (Navigator logs).\n  - Backup conversion to phone reduced missed care during broadband outages (Clinic Manager interview).\n- Quote placeholder:\n  - \u201c[If the video fails, they switch me to a call right away\u2014no more missing the doctor.] \u2014 Client C-231 (consented)\u201d\n\nEquity lens\n- Disaggregate by language, distance, age, insurance.\n- Focus on underrepresented groups (e.g., Spanish speakers): [Interpret drivers; propose bilingual navigator hire; integrate interpreter scheduling.]\n\nMixed/negative results framing\n- What we learned: [Language access gaps persist; Spanish speakers report higher no-shows.]\n- Why this matters: [Risks widening disparities for limited-English-proficient patients.]\n- What we\u2019re changing: [Hire bilingual navigator; implement Spanish/English automated reminders by Q2 2025.]\n\nEvidence tags\n- EHR attendance; Navigator logs; Focus Group: Library Staff.\n\nHow to adapt for funders/board: Emphasize that target was exceeded (112% of target) while naming specific equity gap actions.\n\nOutcome C: Patient Activation (PAM-10)\nOutcome definition and indicator(s)\n- Definition: Change in Patient Activation Measure (PAM-10) among participants with matched surveys.\n- Indicators: % moving up \u22651 PAM level; change in mean PAM level.\n\nQuantitative results\nKPI table shell\n| Indicator | Target | Actual | % Achieved | Data Source | Notes |\n|----------|--------|--------|-----------|-------------|-------|\n| % moving up \u22651 PAM level | 60 | 57 | 95 | PAM-10 survey | Matched n=612 |\n| Mean PAM level (baseline \u2192 endline) | 2.5 | 2.5 | 100 | PAM-10 survey | Baseline 2.1 \u2192 Endline 2.5 |\n\nVisual placeholders\n- Figure C1: Distribution of PAM levels (stacked bars, baseline vs. endline).\n  Caption: \u201cShift toward higher activation levels among matched participants (n=612). Source: PAM-10.\u201d\n- Figure C2: Mean activation gain by age and insurance (clustered bars).\n  Caption: \u201cSeniors gained 0.3 levels vs. 0.5 for <65; Medicaid patients gained 0.5 vs. 0.3 for Medicare. Source: PAM-10.\u201d\n\nQualitative insights\n- Themes:\n  - Simple checklists increased confidence logging in (Navigator call audit).\n  - Printed instructions helpful for lower digital literacy (Interviews).\n- Quote placeholder:\n  - \u201c[The step-by-step sheet stayed by my computer. I don\u2019t panic anymore.] \u2014 Client C-477 (consented)\u201d\n\nEquity lens\n- Disaggregate by age, insurance, language, and county.\n- Interpretation prompts:\n  - Who advanced least? [Seniors; rural far-distance households]\n  - Drivers? [Digital comfort; caregiver support]\n  - Responses? [In-home setup; caregiver coaching; large-print and pictorial guides]\n\nMixed/negative results framing\n- What we learned: [Activation gains fell short by 3 percentage points.]\n- Why this matters: [Lower self-efficacy predicts future missed care and poorer chronic disease control.]\n- What we\u2019re changing: [Revise navigator script with teach-back method; add caregiver coaching; launch March 2025.]\n\nEvidence tags\n- PAM-10; Navigator call audit; Interview: Navigator Lead.\n\nHow to adapt for funders/board: One stacked bar visual and one KPI table. Add one brief quote with consent noted.\n\nSECTION 5) DISCUSSION/INTERPRETATION (300\u2013500 words)\nConnect findings to program theory\n- Pre-visit coaching and simple checklists boosted confidence and reduced login failures; device lending removed access barriers; private rooms increased privacy and reliability.\n\nTriangulate across sources\n- EHR improvements match navigator logs (fewer login failures, fewer last-minute cancellations).\n- Interviews and speed tests explain subgroup gaps (broadband instability correlates with lower completion).\n\nExternal factors\n- Telehealth parity payments sustained supply of telehealth slots.\n- Flood recovery and storm-related outages in February 2024 reduced completion in certain hollers; library signal boosters partially mitigated.\n\nSurprises and nuance\n- Library rooms outperformed home settings for first-time users, supported by speed test logs and timestamped completion data.\n- Text reminders were most effective when combined with a brief test call for first-time users.\n\nLearning stance\n- What we learned: [Navigator coaching is essential but insufficient for seniors and far-distance households.]\n- Why this matters: [Without targeted supports, the program risks reinforcing geographic and age-related disparities.]\n- What we\u2019re changing: [Extend hours; in-home setups; bilingual communications; more boosters; teach-back coaching.]\n\nIn plain language: \u201cHere we explain why the numbers look this way and what outside factors influenced results.\u201d\n\nHow to adapt for funders/board: Emphasize accountability, cost-awareness, and concrete course corrections linked to KPI gaps.\n\nPrompts for completion\n- [Summarize 2\u20133 key drivers that explain improvements]\n- [Name 2\u20133 factors that explain remaining gaps]\n- [List the top 3 program adjustments and expected impact]\n\nSECTION 6) RECOMMENDATIONS & NEXT STEPS (250\u2013400 words)\nGuidance\n- Tie each recommendation to a specific insight and outcome gap.\n- Be specific, time-bound, and feasible given 18 FTE, 120 tablets, and a $600,000 budget.\n\nRecommendation table shell\n| Recommendation | Insight/Gap Addressed | Owner/Lead | Timeframe (Immediate/3\u20136 months/12 months) | Resource Needs (staff hours, budget) | Feasibility (H/M/L) | Success Measure |\n|----------------|-----------------------|------------|--------------------------------------------|--------------------------------------|---------------------|-----------------|\n| Add evening navigator hours (Mon\u2013Thu until 8 pm) | After-work availability; first-time support | Navigator Lead | 3\u20136 months (Q1 2025) | 0.5 FTE shift; $[XX] | High | \u226575% completion for first-time users |\n| Integrate bilingual reminders + ASL interpreter scheduling | Language gap; accessibility | Evaluation Manager + IT | 3\u20136 months (Q2 2025) | Vendor fees $[XX]; 40 hrs IT | High | No-show gap Spanish vs. English \u22643 pts |\n| Deploy 3 signal boosters in library rooms | Rural broadband instability | IT Lead + Library Partners | 6\u201312 months (by May 2025) | Hardware $[XX]; install 60 hrs | Medium | +4 pts completion in target sites |\n| In-home first-session setup for 65+ | Senior activation/completion gap | CHW Leads | Immediate pilot (Q4 2024) | 0.2 FTE; mileage $[XX] | High | 65+ completion rises from 68% to 72% |\n| Revise navigator scripts with teach-back | Activation shortfall | Evaluation Manager | Immediate | 16 hrs training | High | \u226560% advance \u22651 PAM level |\n\nIn plain language: \u201cThis is our to-do list with owners, timelines, and how we\u2019ll know it worked.\u201d\n\nHow to adapt for funders/board: Flag budget-neutral items and those requiring reallocation or new grant funding. Note any procurement or compliance steps.\n\nPrompts for completion\n- [Add or edit 3\u20135 priority recommendations]\n- [Specify owners, timelines, and success measures]\n- [Identify budget or staffing implications]\n\nSECTION 7) LIMITATIONS (150\u2013250 words)\n- Sample size/response rates: [PAM-10 matched n=612 (43% of eligible); potential nonresponse bias toward more engaged patients.]\n- Representativeness: [Spanish speakers underrepresented (2% of sample); rural far-distance households possibly overrepresented among device borrowers.]\n- Data quality issues: PAM-10 nonresponse among the oldest patients may bias activation upward; conducted sensitivity checks comparing age and insurance strata.\n- Design constraints: No randomized comparison group; short follow-up window (60\u201390 days) may miss longer-term effects on chronic disease outcomes.\n- External influences: Storm-related broadband outages; clinic scheduling changes; parity policy.\n- Ethics/consent: Verbal consent logged; encrypted server storage; BAAs with partners; IRB not required.\n\nIn plain language: \u201cHere\u2019s what we couldn\u2019t measure or are less sure about, and why.\u201d\n\nHow to adapt for funders/board: Be concise and transparent; include 1\u20132 mitigation steps (e.g., planned oversampling for seniors; expanded bilingual outreach).\n\nSECTION 8) APPENDICES (checklist and placeholders)\n- [ ] Appendix A: Logic model or theory of change\n  - [Insert diagram or bullet logic model: Inputs \u2192 Activities \u2192 Outputs \u2192 Outcomes \u2192 Impact]\n- [ ] Appendix B: Data collection instruments\n  - [PAM-10 survey; Post-visit survey; Interview and focus group guides]\n- [ ] Appendix C: Detailed data tables (by demographic subgroup)\n  - [Tables by age, language, distance, insurance, county, and zip code]\n- [ ] Appendix D: Sample consent forms and data privacy statement\n  - [Phone script; storage and access protocols]\n- [ ] Appendix E: Complete indicator list with definitions and calculation notes\n  - [Indicator formulas; inclusion/exclusion criteria; data pulls schedule]\n- [ ] Appendix F: Additional participant quotes (with consent documentation)\n  - [Quote bank with IDs and consent status]\n- [ ] Appendix G: Data quality checks documentation\n  - [Missing data rates; reliability checks; audit outcomes]\n\nCROSS-CUTTING EQUITY AND PARTICIPATION PROMPTS (embed throughout)\n- Disaggregation: For each outcome, break out by age, race/ethnicity, income (if available), language, insurance, county/zip code, and distance to clinic.\n- Interpretation: \u201cWhose outcomes improved least? What likely explains this? What will we do next quarter to address it?\u201d\n- Participation: \u201cWhose voices informed this evaluation?\u201d [Patient Advisory Council (8 members) reviewed preliminary charts in July 2024.]\n- Access accommodations: Large-print materials; ASL interpreter scheduling; bilingual reminders; library private rooms; device lending with data.\n- Missing voices: \u201cWho is missing from our data and how will we include them next time?\u201d [Plan oversampling or targeted outreach.]\n\nFORMATTING AND STYLE REQUIREMENTS\n- Define acronyms on first use: EHR (Electronic Health Record); PAM-10 (Patient Activation Measure, 10-item); HIPAA; IRB; BAA; CHW; FTE.\n- Use specific numbers and percentages; avoid vague terms.\n- Tie each claim to a data source (e.g., \u201cSource: EHR attendance export, FY2024\u201d).\n- Keep language clear and plain; include \u201cIn plain language\u201d callouts in each section.\n- Visuals: Include captions with baseline, endline, n-sizes, and data sources.\n\nTEMPLATE FILL-IN PROMPTS SUMMARY (use within each section)\n- [Program purpose in 1\u20132 sentences]\n- [Participant reach and composition]\n- [Key outcomes with numbers and data sources]\n- [Top 2\u20133 recommendations with timelines]\n- [Equity gaps identified and responses]\n- [Methods summary in \u2264150 words for board versions]\n- [Quotes with consent and ID]\n\nOPTIONAL ONE-PAGE DASHBOARD (for board/funders packet)\n- Telehealth completion: 62% \u2192 71% (+9 points; n=3,012) \u2014 95% of target\n- No-show rate: 28% \u2192 16% (\u221212 points; n=1,420) \u2014 112% of target\n- Activation: 57% moved up \u22651 PAM level (n=612) \u2014 95% of target\n- Equity notes: Seniors and >30 miles lagging; Spanish speakers higher no-show\n- Next steps: Evening hours (Q1 2025); bilingual reminders/ASL (Q2 2025); boosters by May 2025\n\nQUICK COMPLETION CHECKLIST (before publishing)\n- [ ] All outcomes show target vs. actual with % achieved\n- [ ] All visuals have captions and data sources\n- [ ] Equity disaggregation and action steps included\n- [ ] Consent and privacy statements included\n- [ ] Recommendations have owners, timelines, and success measures\n- [ ] \u201cIn plain language\u201d boxes present in each section\n- [ ] \u201cHow to adapt for funders/board\u201d notes included\n\nHOW TO REFINE (ask the AI to iterate)\n- Ask: \u201cShorten the methodology to 200 words.\u201d\n- Ask: \u201cAdd a visual for the completion KPI and write a caption.\u201d\n- Ask: \u201cRewrite for a FORMAL tone for a board packet.\u201d\n- Ask: \u201cDraft a one-page executive summary with cost-per-outcome.\u201d\n- Ask: \u201cCreate a subgroup analysis table by age and distance with key takeaways.\u201d",
      "timestamp": "2025-11-02T14:11:47.886398Z",
      "duration_seconds": 322.82,
      "tokens": {
        "input": 4463,
        "output": 8042,
        "total": 12505
      },
      "cost_usd": 0.134019,
      "success": true,
      "evaluation": {
        "overall_score": 9.2,
        "criteria_scores": {
          "tone": 10,
          "completeness": 9,
          "usefulness": 10,
          "accuracy": 9,
          "authenticity": 8
        },
        "reasoning": "This is an exceptionally well-crafted evaluation template that demonstrates deep understanding of nonprofit evaluation practice. The formal tone is perfectly calibrated for grant/board audiences, the structure is comprehensive and practical, and the embedded examples provide concrete guidance. Minor weaknesses include some repetition and slightly formulaic phrasing in places, but these don't significantly detract from its utility.",
        "strengths": [
          "Excellent tone calibration\u2014consistently formal, neutral, and grant-appropriate throughout, with professional language that matches funder expectations",
          "Outstanding specificity in examples\u2014the telehealth completion example (62% to 71%, n=3,012) and recommendation table with owners/timelines/success measures are exactly the level of detail nonprofits need",
          "Exceptional equity integration\u2014disaggregation prompts, 'whose voices' questions, and 'what we're changing' framing are embedded naturally rather than tacked on",
          "Highly practical structure\u2014KPI tables with target/actual/% achieved, visual placeholders with caption prompts, and evidence tags make this immediately usable",
          "Strong funder/board adaptation notes\u2014each section includes specific guidance on condensing for different audiences, including cost-per-outcome suggestions",
          "Comprehensive appendix checklist\u2014covers all essential evaluation documentation from logic models to consent forms to data quality checks",
          "Excellent 'in plain language' callouts\u2014these would genuinely help staff translate evaluator jargon for community audiences",
          "Realistic resource constraints\u2014the template acknowledges team capacity (18 FTE, $600K budget) and ties recommendations to feasibility",
          "Strong mixed/negative results framing\u2014'what we learned/why this matters/what we're changing' structure models constructive accountability"
        ],
        "weaknesses": [
          "Some repetition between sections\u2014the outcome definitions and KPIs appear in both the Program Overview and Findings sections, which could be streamlined",
          "Slightly formulaic phrasing in places\u2014phrases like 'In plain language:' and 'How to adapt for funders/board:' are mechanically repeated rather than varied",
          "The 'How to Refine' section at the end, while helpful, breaks the fourth wall in a way that might confuse users who expect a pure template"
        ],
        "evaluator_model": "claude-sonnet-4.5"
      }
    },
    {
      "scenario_id": "scenario_2",
      "model": "claude",
      "model_display_name": "Claude (Sonnet 4.5)",
      "error": "Expecting value: line 1513 column 1 (char 8316)",
      "timestamp": "2025-11-02T14:11:48.462685Z",
      "success": false
    },
    {
      "scenario_id": "scenario_3",
      "model": "gemini",
      "model_display_name": "Gemini 2.5 Flash",
      "content": "# Pacific Horizons Refugee Services (PHRS) Career Pathways for New Americans Evaluation Report: January 1\u2013December 31, 2024\n\n**Prepared by:** Lina Nguyen, Senior Evaluation Manager\n**In collaboration with:** PHRS Impact & Learning Unit (internal)\n**Date:** 2025-02-05\n**Report covers:** January 1\u2013December 31, 2024\n**Geographic scope:** King County, Washington (Seattle, Kent, Tukwila, Burien, Renton)\n**Audiences and uses:**\n*   **Primary Audience:** PHRS program leadership and employment specialists, to improve program delivery, inform strategic planning, and support staff development.\n*   **Secondary Audience(s):** Employer partners and community colleges, to foster collaboration, demonstrate impact, and refine referral pathways.\n*   **Funders/Board:** ORR, Washington Department of Commerce, Ballmer Group, and the PHRS Board of Directors, to demonstrate accountability, report on grant outcomes, and inform future funding decisions.\n\n---\n\n## 1. Executive Summary\n\nThis report summarizes the performance and impact of Pacific Horizons Refugee Services (PHRS)\u2019s Career Pathways for New Americans program during the period of January 1\u2013December 31, 2024, in King County, Washington. The program aims to support newly arrived refugees and asylees in securing quality employment aligned with their skills and experience, primarily through contextualized ESL instruction, credential evaluation support, targeted career coaching, and employer partnerships.\n\nIn 2024, the program served 1,085 clients (54% women) from 46 countries, with top languages including Arabic, Dari, Somali, and Ukrainian. Eligibility was limited to individuals with refugee, asylee, SIV, or humanitarian parole status, within five years of their arrival. Clients received intensive support, averaging 14 weeks of services, 48 hours of ESL instruction, and a median of six career coaching sessions. This comprehensive approach aimed to bridge critical gaps in language, cultural understanding, and professional navigation for New Americans.\n\n**Top Findings:**\n\n1.  **High Placement and Retention:** The program successfully placed 63% of job-seeking clients within 90 days of engagement, exceeding the target of 60%. Of those placed, 72% were retained in their employment for at least 90 days, also surpassing the 70% target. For example, our employer cohorts significantly accelerated hiring decisions, particularly in healthcare support roles, leading to prompt and stable employment for many participants.\n2.  **Increased Earning Potential:** Clients achieved a median starting wage of $21.80, exceeding the target of $21.00 and notably above the county's minimum wage. Furthermore, 214 clients secured credential equivalency, surpassing the target of 200, which directly contributed to higher-wage, skill-aligned placements. As client D-144 noted, \u201cOnce my degree was recognized, employers took my application seriously.\u201d\n3.  **Persistent Equity Gaps:** Despite overall strong performance, persistent wage and placement gaps were observed for women and clients with limited English proficiency. Women were placed at 59% compared to 67% for men, often citing childcare and scheduling as significant barriers. Similarly, clients with limited English proficiency faced slower pathways to sector-aligned roles, often settling for lower-wage stopgap employment due to credential evaluation backlogs.\n\n**High-Level Recommendations:**\n\n1.  **Pilot childcare stipends for job seekers (Q2 2025):** Address a key barrier for women, aiming to improve placement rates and access to training.\n2.  **Increase evening ESL sections by 25% (Q2 2025):** Enhance accessibility for working clients and those with family obligations, supporting better English proficiency and sector-specific vocabulary.\n3.  **Add an employer cohort focused on healthcare support roles (Q3 2025):** Capitalize on strong placement and retention in this sector, leveraging existing partnerships and client skills.\n\n**Overall Assessment:**\nPHRS\u2019s Career Pathways for New Americans demonstrates strong effectiveness in job placement and retention, largely driven by robust employer partnerships and individualized coaching. However, the program acknowledges that significant work remains to address equity gaps related to gender, language proficiency, and the often-lengthy credential evaluation process, which can delay sector-aligned hiring. Our focus for 2025 will be to strategically address these disparities to ensure more equitable outcomes for all New Americans.\n\n**In plain language:** This section tells busy readers what changed, for whom, and what we\u2019ll do next.\n\n*How to adapt for funders/board:* Lead with outcomes tied directly to specific grant objectives and KPIs; keep this section to one concise page. Include relevant grant KPIs and cost-per-outcome metrics if available and applicable to the funder.\n\n## 2. Program Overview\n\nThe Career Pathways for New Americans program, operated by Pacific Horizons Refugee Services (PHRS), provides comprehensive employment support to refugees, asylees, and other eligible New Americans in King County, Washington. Our efforts are focused on Seattle, Kent, Tukwila, Burien, and Renton, areas with significant refugee populations and diverse employment opportunities.\n\n**Goals and Theory of Change:**\nThe program's overarching goal is to empower New Americans to achieve economic self-sufficiency through sustainable, skill-aligned employment. Our theory of change posits that by providing contextualized English as a Second Language (ESL) instruction, targeted career coaching, and strategic employer partnerships, we can effectively reduce common barriers (e.g., language, credential recognition, cultural navigation) and accelerate participants' entry into quality jobs. This holistic approach is designed to build long-term career pathways rather than just immediate job placements.\n\n**Target Population and Eligibility:**\nThe program serves adult New Americans (ages 18-64) who are refugees, asylees, SIV holders, or humanitarian parolees, and are within five years of their arrival in the United States. Our clients often face multiple systemic barriers, including limited English proficiency, lack of affordable childcare, unrecognized foreign credentials, limited professional networks in the U.S., and transportation challenges.\n\n**Activities and Dosage:**\nCareer Pathways for New Americans delivers a multi-faceted service model, including:\n*   **Contextualized ESL and Bridge Courses:** 4\u20136 hours per week, focusing on workplace communication, industry-specific vocabulary, and job interview skills.\n*   **Career Coaching and Job Readiness Workshops:** Bi-weekly individualized coaching sessions covering resume writing, interview preparation, job search strategies, and U.S. workplace culture. Workshops address topics like financial literacy and employee rights.\n*   **Credential Evaluation and Licensing Navigation:** Dedicated support to evaluate foreign credentials, understand U.S. licensing requirements, and navigate the process for professional recognition.\n*   **Employer Cohort Hiring Events and Paid Work Experiences:** Direct connections with employer partners for streamlined hiring, often through cohort-based recruitment drives. Paid work experiences offer hands-on U.S. work exposure.\n*   **Mentor Matching and Retention Coaching:** Connecting clients with community mentors for cultural assimilation and professional networking, coupled with post-placement retention support for the first 90-120 days of employment.\n\nOur staff consists of 65 dedicated professionals, including certified employment specialists and experienced ESL instructors. The program is further bolstered by 120 volunteer mentors and partnerships with local colleges and 75 employers.\n\n**Staffing/Resources:**\nPHRS utilizes a robust team of 65 staff members dedicated to the Career Pathways program, supported by 120 community mentors. Key partnerships include local community colleges for advanced training opportunities and over 75 employer partners across various sectors. The program operates on an annual budget of $3.2 million.\n\n**Context:**\nThe operating environment in King County in 2024 presented both opportunities and challenges:\n*   **Economic Landscape:** King County saw continued increases in the minimum wage, which positively impacted starting wages for many participants. However, volatility in the tech sector led to shifts in demand, with a growing need in healthcare support roles.\n*   **Demographic Shifts:** Continued arrivals from Ukraine and Afghanistan contributed to a growing and diverse client base, bringing diverse educational backgrounds and professional experiences.\n*   **Community Resources:** Strong connections with community colleges and a network of employers provided valuable pathways and support.\n\nFor a detailed visual representation of the program's intended causal links, please refer to **Appendix A: Logic Model**. Additional context on data collection is in **Appendix B: Instruments** and **Appendix C: Indicator Definitions**.\n\n**Sample phrasing:** In 2024, Career Pathways for New Americans served 1085 participants through contextualized ESL and bridge courses, career coaching and job readiness workshops, credential evaluation and licensing navigation, employer cohort hiring and paid work experience, and mentor matching and retention coaching to achieve job placement within 90 days, 90-day job retention, and improved wages and credential utilization.\n\n*How to adapt for funders/board:* Align program goals and activities directly with the specific objectives outlined in the grant proposal and the approved budget. Emphasize how the program's strategic design addresses funder priorities.\n\n## 3. Evaluation Questions & Methodology\n\nThis evaluation was conducted to assess the effectiveness and impact of the Career Pathways for New Americans program, focusing on its ability to support New Americans in King County achieve employment and economic stability.\n\n**Evaluation Questions:**\n1.  To what extent did participants in the Career Pathways program achieve employment within 90 days and maintain it for at least 90 days?\n2.  What was the median starting wage for participants, and to what extent did the program facilitate the recognition of foreign credentials?\n3.  Which program components (e.g., ESL, coaching, employer cohorts, credential support) were most and least helpful for participants, and for whom were these components most effective (disaggregated by key demographics)?\n4.  What are the key barriers and facilitators for participants in securing and retaining quality, skill-aligned employment, particularly for women and individuals with limited English proficiency?\n\n**Design/Approach:**\nThis evaluation employed a **cohort tracking design**, following all participants who engaged with the program between January 1 and December 31, 2024. We utilized a **contribution analysis approach**, attributing observed outcomes to program interventions while acknowledging the influence of external factors. Given the program's nature, a randomized control trial (RCT) was not feasible or ethical; therefore, the analysis focuses on participant progress and outcomes relative to baseline and established targets.\n\n**Data Sources:**\nA mixed-methods approach was used, integrating quantitative and qualitative data from multiple sources to provide a comprehensive understanding of program impact:\n*   **PHRS ETO Admin Logs:** Comprehensive quantitative data on client demographics, service utilization (ESL hours, coaching sessions), job placements, starting wages (documented through payroll verification), and retention data.\n*   **Washington State Unemployment Insurance (UI) Wage File:** External verification of wages and employment retention for participants, providing a robust, independent data source (with a time lag).\n*   **Employer Satisfaction Survey:** Surveys administered to employer partners on placed clients' readiness, performance, and program effectiveness.\n*   **Multilingual Intake and Exit Surveys:** Administered at program entry and exit in participants' preferred languages (Arabic, Dari, Somali, Ukrainian, English) to gather self-reported data on goals, perceived progress, and satisfaction.\n*   **Focus Group Guides:** Structured discussions with client cohorts, conducted in their native languages, to elicit deeper qualitative insights into program experiences, perceived helpfulness of components, and encountered barriers.\n*   **Case Notes:** Detailed records maintained by employment specialists providing narrative accounts of client progress, challenges, and successes.\n\n**Sampling and Timing:**\nAll 1,085 eligible clients who engaged with the Career Pathways program in 2024 were included in the quantitative analysis (n=1,085).\n*   **Surveys:** Intake surveys were completed by 98% of clients (n=1,063); exit surveys by 85% of clients upon program completion or transition (n=922).\n*   **Focus Groups:** Four focus groups were conducted in November-December 2024, with 8-10 participants each, purposively sampled to represent diverse language groups (Arabic, Dari, Somali, Ukrainian) and program stages.\n*   **Employer Surveys:** Administered digitally to all employer partners with PHRS placements in Q4 2024 (n=75 employers; 68% response rate).\n\n**Data Quality Checks:**\nData quality was ensured through a multi-step process:\n*   **Missing Data Review:** Regular checks of ETO data for completeness, with follow-up protocols for missing critical fields.\n*   **Reliability Checks:** Cross-referencing placement and wage data between ETO, WA UI files, and employer surveys to ensure consistency.\n*   **Spot Audits:** Random audits of client files to verify service delivery and documentation accuracy.\n*   **Data Cleaning:** Systematic review and correction of inconsistencies or errors in quantitative datasets.\n\n**Ethics/Consent:**\nAll evaluation activities adhered to ethical research principles. Written consent was obtained from all participants in their preferred language (available in 7 languages) before data collection. A clear privacy statement, aligned with ORR guidelines, was provided, outlining data use, storage, and confidentiality. Participant quotes are used only with explicit written permission, often obtained during follow-up consent. An Institutional Review Board (IRB) review was deemed not required as the evaluation focused on program improvement and did not involve human subjects research as defined by federal regulations.\n\n**Equity/Participation:**\nEquity and participation were central to the evaluation design.\n*   **Client Advisory Council (CAC):** A 12-member CAC, representing diverse nationalities and program experiences, co-designed key questions for the intake and exit surveys, ensuring that client perspectives were reflected in the data collected.\n*   **Language Access:** All surveys, consent forms, and focus group materials were provided in the primary languages of PHRS clients. Interpreters were provided for all focus groups and discussions.\n*   **Childcare:** Childcare was offered on-site for all focus groups to ensure maximum participation from parents.\n*   **Disaggregation:** Data analysis systematically disaggregated outcomes by key demographic factors (gender, language proficiency, nationality, etc.) to highlight disparities.\n\n**In plain language:** We measured success by tracking job placements, wages, and client satisfaction, using data like attendance logs, client surveys, and employer feedback. We also listened to what clients told us about their experiences in interviews.\n\n| Method                                      | Sample/Response Rate                                  | Timeline                       | Purpose/Question(s) Informed                                                                                               |\n| :------------------------------------------ | :---------------------------------------------------- | :----------------------------- | :------------------------------------------------------------------------------------------------------------------------- |\n| PHRS ETO Admin Logs                         | n=1,085 clients (all program participants)            | Ongoing throughout 2024        | Q1, Q2, Q3 (quantitative); Service utilization, placement, retention, wages                                                |\n| WA UI Wage File                             | n=780 (matched clients)                               | Lagged (Q1 2025 for 2024 data) | Q1, Q2 (external verification of employment & wages)                                                                       |\n| Multilingual Intake/Exit Surveys            | Intake: n=1,063 (98%); Exit: n=922 (85%)              | Intake: Jan-Dec 2024; Exit: Rolling | Q1, Q3, Q4 (client perceptions, barriers, satisfaction)                                                                    |\n| Employer Satisfaction Survey                | n=51 (68% response rate from 75 partners)             | Q4 2024                        | Q1, Q3 (employer perspective on client readiness & program value)                                                          |\n| Client Focus Groups (Arabic, Dari, Somali, Ukrainian) | 4 groups, 8-10 participants each (n=36 total)         | Nov-Dec 2024                   | Q3, Q4 (in-depth qualitative insights on program components, barriers, and efficacy for diverse groups)                    |\n| Case Notes                                  | All client files accessing services (n=1,085)          | Ongoing throughout 2024        | Q1, Q3, Q4 (individual client progress, specific challenges, qualitative insights)                                         |\n\n*How to adapt for funders/board:* Keep the design description concise, emphasizing the robustness and validity of the methods. Highlight how consent and data privacy were ensured, and explicitly state how the chosen methods align with demonstrating progress against grant indicators.\n\n## 4. Findings by Outcome Area\n\nThis section presents detailed findings for the Career Pathways for New Americans program, disaggregated by key demographic data to highlight areas of success and persistent disparities.\n\n### 4.1. Outcome Area: Job Placement within 90 Days\n\n**Outcome Definition and Indicators:** The percentage of enrolled job-seeking clients successfully placed into employment within 90 days of program intake.\n\n**Quantitative Results:**\n| Indicator                           | Target   | Actual   | % Achieved | Data Source                    | Notes                                                                           |\n| :---------------------------------- | :------- | :------- | :--------- | :----------------------------- | :------------------------------------------------------------------------------ |\n| % placed within 90 days             | 60%      | 63%      | 105%       | ETO admin data; employer verification | Cohort-wide, includes unsubsidized and subsidized placements                    |\n\n**Visual Placeholder: Job Placement Rate (Bar Chart)**\n[Insert Bar Chart here showing Target vs. Actual Job Placement Rates]\n*Caption: Participants achieved a 63% job placement rate within 90 days, exceeding the 60% target (n=1,085).*\n\n**Qualitative Insights:**\n*   **Employer Cohorts Accelerated Hiring:** Employer-specific hiring events were highly effective, reducing the time from application to offer. Theme: \"Direct connections matter.\"\n*   **Mentorship Improved Application Quality:** Clients consistently reported that mentor support significantly enhanced their resume and interview preparation, leading to increased confidence. Theme: \"Personalized guidance is key.\"\n\n**Quote placeholder(s):** \"My mentor helped me translate my nursing experience to U.S. terms, which made a huge difference in interviews.\" \u2014 Client U-221 (consented).\n\n**Equity Lens:**\n*   **Disaggregation by Gender:** Women were placed at 59%, while men achieved 67% placement. Focus group participants frequently cited childcare responsibilities and inflexibility in work schedules as primary barriers for women.\n*   **Disaggregation by English Proficiency:** Clients with Limited English Proficiency (LEP) experienced a 58% placement rate, compared to 69% for those with Advanced English Proficiency. This suggests language skills remain a significant factor impacting immediate job acquisition.\n\n**What we learned from placement data:**\n*   **What we learned:** While overall placement rates exceeded targets, women and clients with limited English proficiency faced lower placement rates.\n*   **Why this matters:** These disparities can perpetuate inequities, delay economic stability for vulnerable populations, and potentially push clients into lower-wage, non-skill-aligned jobs out of immediate necessity.\n*   **What we\u2019re changing:** PHRS will pilot a childcare stipend for job seekers (Q2 2025) to address a significant barrier for women. Additionally, we will work with employer partners to advocate for more flexible shifts and family-friendly policies. For LEP clients, we plan to add evening ESL sections and targeted sector-specific vocabulary modules (Q2 2025) to better equip them for a wider range of roles.\n\n**Evidence tags:** Admin placement record, Employer survey, Focus Group: ESL Cohort B\n\n### 4.2. Outcome Area: 90-Day Job Retention\n\n**Outcome Definition and Indicators:** The percentage of placed clients who remained employed for at least 90 days post-start date.\n\n**Quantitative Results:**\n| Indicator                           | Target   | Actual   | % Achieved | Data Source                    | Notes                                                                           |\n| :---------------------------------- | :------- | :------- | :--------- | :----------------------------- | :------------------------------------------------------------------------------ |\n| % retained at 90 days               | 70%      | 72%      | 103%       | Employer verification; case notes | n=678 placed clients                                                            |\n\n**Visual Placeholder: 90-Day Job Retention Rate (Bar Chart)**\n[Insert Bar Chart here showing Target vs. Actual Job Retention Rates]\n*Caption: The program achieved a 72% 90-day job retention rate, exceeding the 70% target (n=678 placed clients).*\n\n**Qualitative Insights:**\n*   **Supervisor Check-ins & Mentor Support:** Regular communication with supervisors and ongoing mentor support were key factors in resolving early workplace challenges and improving job satisfaction. Theme: \"Support beyond placement fosters stability.\"\n*   **Transportation Subsidies:** Initial transportation assistance (e.g., ORCA cards for the first month) significantly improved punctuality and reduced early attrition by easing financial burdens. Theme: \"Practical support ensures smooth transitions.\"\n\n**Quote placeholder(s):** \"Weekly check-ins helped me solve small issues before they became big problems and helped me feel secure in my new job.\" \u2014 Client R-310 (consented).\n\n**Equity Lens:**\n*   **Disaggregation by Industry:** Retention rates varied by industry, with Healthcare Support roles seeing 76% retention, IT Support at 81%, Hospitality at 70%, and Warehouse/Logistics at 68%. The lower retention in warehouse roles suggests potential mismatches in client expectations or working conditions.\n\n**What we learned from retention data:**\n*   **What we learned:** While overall retention was strong, roles in warehouse/logistics showed comparatively lower retention rates. This indicates that while clients secure these jobs, the fit might not be as sustainable for some.\n*   **Why this matters:** Early attrition is costly for both clients (loss of income, morale) and employers (recruitment costs), and can disrupt the pathway to long-term economic stability.\n*   **What we\u2019re changing:** We will strengthen our job preview process for warehouse/logistics roles to ensure clients have realistic expectations of the demands and environment. We will also expand retention coaching to 120 days specifically for placements in warehouse positions (Q3 2025) to provide extended support during the critical early months. We will also coach employer leads on shift flexibility and cultural sensitivity within these roles.\n\n**Evidence tags:** Employer verification, Case notes, Survey Q12 (mentor helpfulness)\n\n### 4.3. Outcome Area: Wages and Credential Utilization\n\n**Outcome Definition and Indicators:** Starting wages for placed clients and the achievement of credential recognition for clients with prior professional training.\n\n**Quantitative Results:**\n| Indicator                           | Target  | Actual  | % Achieved | Data Source                     | Notes                                                                           |\n| :---------------------------------- | :------ | :------ | :--------- | :------------------------------ | :------------------------------------------------------------------------------ |\n| Median starting wage (USD)          | $21.00  | $21.80  | 104%       | Admin payroll verification; WA UI wage file (lagged) | County minimum wage context considered (n=312 for wage data)                    |\n| # clients with credential equivalency | 200     | 214     | 107%       | WES/ECE credential outcomes     | Nursing, engineering, and teaching most common                                  |\n\n*Baseline median wage: $17.40; Endline median wage: $21.10 (for full cohort) (Note: the example provided an initial endline of 21.1 which is lower than actual of 21.8, so using actual 21.8)*\n\n**Visual Placeholder: Median Starting Wage Over Time (Line Chart)**\n[Insert Line Chart here showing historical median wage + current actual]\n*Caption: Median starting wage increased from a baseline of $17.40 to $21.80 in 2024, exceeding the target of $21.00 (n=312 clients with verified wage data).*\n\n**Qualitative Insights:**\n*   **Credential Evaluation Boosted Offers:** Clients who successfully had their foreign credentials recognized reported receiving higher wage offers and more professional roles, particularly in healthcare. Theme: \"Validation of skills unlocks potential.\"\n*   **Negotiation Coaching's Impact:** Workshops on salary negotiation were directly correlated with higher starting offers, especially in IT support roles where negotiation is more common. Theme: \"Empowering clients for better compensation.\"\n\n**Quote placeholder(s):** \"Once my degree was recognized, employers took my application seriously, and I could finally pursue work in my field, not just any job.\" \u2014 Client D-144 (consented).\n\n**Equity Lens:**\n*   **Disaggregation by Gender (Median Wage):** A notable gender wage gap persists, with women achieving a median starting wage of $20.10 compared to $23.00 for men (a $2.90 difference). This may be influenced by industry placements, negotiation confidence, and childcare demands affecting available work hours.\n*   **Disaggregation by English Proficiency (Median Wage):** Clients with Limited English Proficiency had a median starting wage of $20.40, while those with Advanced English Proficiency earned $23.20, showing a significant wage disparity directly linked to language skills.\n\n**What we learned from wage and credential data:**\n*   **What we learned:** Although median starting wages exceeded targets overall, a significant gender wage gap persists, and clients with limited English proficiency consistently secure lower-paying positions. Additionally, the credential evaluation process, while vital, caused significant delays in job starts.\n*   **Why this matters:** These wage disparities exacerbate economic vulnerability for specific groups, and delays in credential recognition can force highly skilled individuals into survival jobs, underutilizing their talents and leading to frustration.\n*   **What we\u2019re changing:** To address the gender wage gap, PHRS will implement targeted salary negotiation workshops for women (Q2 2025) and advocate with employer partners for transparent pay scales and family-friendly benefits. To streamline credential evaluation, we will move to batch WES submissions monthly and pre-screen credential pathways at intake (starting Q1 2025) to accelerate the process and guide clients toward appropriate professional tracks more quickly.\n\n**Evidence tags:** WA UI wage file, WES outcomes, Employer survey\n\n*How to adapt for funders/board:* Lead with outcomes directly corresponding to grant Key Performance Indicators (KPIs). Present 1\u20132 concise visuals per outcome area, ensuring clear captions with \u2018n\u2019 sizes and data sources. Briefly footnote the methods for quantitative data as needed. Keep participant quotes brief and impactful.\n\n## 5. Discussion/Interpretation\n\nThe 2024 evaluation of the Career Pathways for New Americans program reveals a landscape of significant achievements coupled with critical areas for continuous improvement. Our findings strongly indicate that the program effectively contributes to the economic integration of New Americans in King County.\n\n**Connecting Findings to Program Theory:**\nThe data largely affirms our theory of change. The robust job placement (63%) and retention (72%) rates underscore the effectiveness of our comprehensive service model. Specifically, employer cohort hiring events significantly accelerated placements, validating the strategy of direct partnerships with responsive employers. Furthermore, the higher median starting wage ($21.80) and increased credential equivalencies achieved (214 clients) suggest that the combination of targeted ESL, rigorous career coaching, and dedicated credential support effectively moves clients into jobs that align more closely with their skills and offer better compensation. As seen in healthcare fields, credentialing, coupled with sector-specific ESL, demonstrably improved wage offers for clients with pre-existing professional backgrounds.\n\n**Triangulation of Data:**\nConsistency across various data sources strengthens our conclusions. ETO administrative data on placements and wages aligned closely with employer feedback regarding client readiness and performance. Moreover, client self-reported experiences from intake and exit surveys, and particularly in focus groups, directly corroborated the observed quantitative trends. For example, clients consistently reported childcare and language as persistent fundamental barriers, directly explaining the lower placement and wage outcomes observed for women and individuals with limited English proficiency in the administrative data.\n\n**External Factors:**\nSeveral external factors influenced program outcomes. The continued increase in King County's minimum wage positively impacted starting wages, allowing our clients to enter employment at a higher floor. Additionally, expansions in public transit lines in portions of King County likely eased transportation burdens for some clients, indirectly supporting punctuality and job retention. Conversely, volatility in the tech sector, marked by layoffs, shifted some client aspirations and pathways towards more stable demands in fields like IT support, where PHRS successfully adapted its employer partnerships. The ongoing arrival of New Americans from Ukraine and Afghanistan also broadened the pool of highly skilled individuals requiring credential navigation support.\n\n**Surprises:**\nOne notable surprise was the faster-than-expected wage gains in healthcare support roles. While we anticipated growth in this sector, the rapidity with which clients, especially those with some prior medical experience, were able to secure skilled roles with competitive wages was particularly encouraging. This was further validated by employer wage surveys and the WA UI files, suggesting that this sector is highly amenable to our program's model of credential support and contextualized training. This outcome highlights a valuable area for deeper resource allocation and partnership development.\n\n**Learning Stance:**\n*   **What we learned:** While the core program components are effective, systemic barriers related to childcare, language proficiency, and the credential evaluation timeline disproportionately affect certain client groups.\n*   **Why this matters:** These persistent inequities undermine the program's vision of equitable economic integration and can lead to underemployment, diminished motivation, and prolonged reliance on social services for vulnerable populations.\n*   **What we\u2019re changing:** Our immediate focus will be to implement targeted interventions \u2013 such as childcare stipends, expanded evening ESL, and streamlined credential processes \u2013 to directly address these disparities and ensure that *all* New Americans have an equitable chance at quality employment. We are committed to a continuous improvement cycle, leveraging these insights to refine and strengthen our program.\n\n**In plain language:** Here we make sense of why results look the way they do, connecting what clients tell us, what our data shows, and what\u2019s happening in the world around us.\n\n*How to adapt for funders/board:* Emphasize the program's accountability and responsiveness to data. Highlight how practical lessons learned are leading to concrete course corrections and future strategic directions. Frame challenges as opportunities for innovation and deeper impact.\n\n## 6. Recommendations & Next Steps\n\nBased on the findings and discussion, the following recommendations are put forth to enhance the effectiveness, equity, and reach of the Career Pathways for New Americans program. Each recommendation is linked to specific insights and addresses identified outcome gaps.\n\n| Recommendation                                        | Owner/Lead              | Timeframe               | Resource Needs (staff hours, budget) | Feasibility (H/M/L) | Success Measure                                                                                                |\n| :---------------------------------------------------- | :---------------------- | :---------------------- | :----------------------------------- | :------------------ | :------------------------------------------------------------------------------------------------------------- |\n| **1. Pilot childcare stipends for job seekers.** Addresses lower placement for women. | Program Manager         | Q2 2025                 | 40 staff hours (setup), $25K (stipends) | High                | 15% increase in women's placement rates; 20% increase in training attendance for women; client feedback.   |\n| **2. Increase evening ESL sections by 25%.** Addresses lower placement & wages for LEP clients. | ESL Coordinator         | Q2 2025                 | 20 staff hours (scheduling), $15K (instructor FTE) | High                | 10% increase in LEP client engagement in ESL; improved self-reported English proficiency for new attendees. |\n| **3. Add employer cohort in healthcare support roles.** Capitalize on strong placement/wages in sector. | Employer Engagement Specialist | Q3 2025                 | 30 staff hours (partnership development) | High                | Secure 2 new employer partners; place 30+ clients in healthcare support roles; median starting wage > $22.00. |\n| **4. Implement targeted salary negotiation workshops for women.** Addresses gender wage gap. | Career Coach Lead       | Q2 2025                 | 15 staff hours (module development), $5K (guest speaker) | Medium              | 20% increase in self-reported negotiation attempts; 10% reduction in gender wage gap for participants.     |\n| **5. Streamline credential evaluation process.** Addresses job start delays and underemployment. | Credentialing Navigator | Q1 2025 (Immediate)     | 25 staff hours (process docs/training) | High                | 20% reduction in time from credential submission to equivalency; 15% increase in skill-aligned placements. |\n| **6. Strengthen job preview & extended retention coaching for warehouse/logistics.** Addresses lower retention in this sector. | Employment Specialist Team | Q3 2025                 | 20 staff hours (training), $10K (additional coaching FTE) | Medium              | 10% increase in 90-day retention for warehouse roles; reduction in client-reported job dissatisfaction.    |\n| **7. Translate key program materials (e.g., job descriptions, workplace safety) into top client languages.** Addresses language barriers and safety. | Communications Specialist | Q2 2025                 | 30 staff hours, $10K (translation services) | High                | 25% increase in client understanding of job roles and safety protocols; reduced workplace incidents. |\n\n*How to adapt for funders/board:* For funders and board members, highlight recommendations that are budget-neutral or can be absorbed within existing resources. Clearly identify any recommendations that would require additional funding or reallocation, providing a strong case for their impact. Emphasize how these steps are data-driven and aim to improve outcomes for their target populations.\n\n## 7. Limitations\n\nThis evaluation provides a comprehensive assessment of the Career Pathways program, yet it is important to acknowledge certain limitations that may influence the interpretation and generalizability of the findings.\n\n1.  **Sample Size and Representativeness:** While the evaluation included all program participants (n=1,085), ensuring strong internal validity, direct comparisons to a control group were not feasible. This means causal attribution, rather than contribution, cannot be definitively established. Moreover, while King County is demographically diverse, the findings primarily reflect the experiences of PHRS's client base and may not be fully generalizable to other refugee populations or geographic areas.\n2.  **Data Quality Issues / Missing Data:**\n    *   **WA UI Wage Data:** Wage and employment data from the Washington State UI file, while robust, was only available for approximately 72% of placed clients. Missing data (28%) primarily stemmed from recent arrivals not yet in the system or clients lacking Social Security Numbers (SSNs) at the time of initial employment. Where possible, self-reported wages were cross-checked with employer confirmations, but a small portion of wage data remains self-reported and unverified by external sources.\n    *   **Exit Survey Response Rate:** The 85% response rate for exit surveys, while strong, means 15% of clients did not provide direct feedback upon completion or departure, potentially missing insights from those who may have had less positive experiences.\n3.  **Design Constraints:** The absence of a comparable control group means that while we can observe significant positive changes, we cannot definitively claim that these changes *would not have occurred* without the program. The evaluation focuses on describing changes and attributing them to program activities within the context of external factors.\n4.  **Short Follow-up Window:** The 90-day retention window provides a valuable snapshot of immediate job stability but does not capture long-term career progression, wage growth beyond the starting wage, or sustained economic self-sufficiency. Future evaluations should consider extended follow-up periods.\n5.  **External Influences:** The King County economic landscape (e.g., minimum wage increases, sector volatility) undoubtedly influenced outcomes. While acknowledged in the discussion, it is challenging to quantify the precise impact of these external factors independently of program interventions.\n6.  **Ethics/Consent Status:** While robust multi-language consent processes were followed and data hosted on secure servers, the reliance on self-reported data for certain qualitative insights (e.g., perceived helpfulness of components) inherently carries a degree of subjectivity.\n\n**In plain language:** Here\u2019s what we couldn\u2019t measure perfectly or are less sure about, and why. For example, some employment data was hard to get for everyone.\n\n*How to adapt for funders/board:* Be transparent and concise with limitations. For each limitation, briefly state any mitigation steps taken or plans for addressing it in future evaluations. This demonstrates a commitment to rigor and continuous improvement.\n\n## 8. Appendices\n\nThis section lists supporting documents and detailed data that provide additional context and evidence for the evaluation findings.\n\n*   [ ] **Appendix A: Program Logic Model or Theory of Change.** A visual representation detailing the program's inputs, activities, outputs, short-term outcomes, and long-term impact.\n*   [ ] **Appendix B: Data Collection Instruments.** Includes copies of the multilingual intake and exit surveys, employer satisfaction survey, and focus group guides used for data collection.\n*   [ ] **Appendix C: Detailed Data Tables by Demographic Subgroup.** Comprehensive tables presenting all quantitative findings disaggregated by key demographics such as age, gender, nationality, English proficiency level, and geographic area.\n*   [ ] **Appendix D: Sample Consent Forms and Data Privacy Statement.** Documentation of the informed consent process and the privacy protocols implemented to protect participant data.\n*   [ ] **Appendix E: Complete Indicator List with Definitions and Calculation Notes.** A comprehensive list of all indicators tracked, their precise definitions, and calculation methodologies, including data sources.\n*   [ ] **Appendix F: Additional Participant Quotes.** A selection of additional testimonials and quotes from program participants, with explicit consent for their use.\n*   [ ] **Appendix G: Data Quality Checks Documentation.** Records of data cleaning processes, missing data rates for key variables, and reliability checks performed.\n\n---\n\n**How to refine this template:**\n*   Ask: 'Shorten the methodology to 200 words.'\n*   Ask: 'Add a visual for the retention KPI and write a caption.'\n*   Ask: 'Rewrite for a FORMAL tone for a board packet.'",
      "timestamp": "2025-11-02T14:12:35.589534Z",
      "duration_seconds": 47.12,
      "tokens": {
        "input": 4704,
        "output": 8281,
        "total": 12985
      },
      "cost_usd": 0.005674,
      "success": true,
      "evaluation": {
        "overall_score": 9.2,
        "criteria_scores": {
          "tone": 10,
          "completeness": 9,
          "usefulness": 10,
          "accuracy": 9,
          "authenticity": 8
        },
        "reasoning": "This is an exceptionally strong evaluation report that demonstrates deep understanding of nonprofit evaluation practices. The tone is perfectly balanced\u2014professional yet accessible\u2014and the content is immediately usable. The template successfully integrates equity analysis, funder adaptations, and plain-language explanations throughout. Minor weaknesses include some repetition and a few areas where the examples could be even more concise for board-facing versions.",
        "strengths": [
          "Outstanding integration of equity lens throughout\u2014disaggregation prompts, gap analysis, and 'What we learned/Why this matters/What we're changing' framework are exceptionally well-executed and actionable",
          "Excellent use of concrete, realistic examples with appropriate specificity (e.g., '63% placement vs 60% target,' specific client quotes with consent codes, detailed recommendation table with owners/timelines/resources)",
          "Superb balance of quantitative rigor and qualitative depth\u2014data tables, visual placeholders with proper captions, triangulation discussion, and evidence tags create a credible, professional evaluation framework",
          "Highly practical 'How to adapt for funders/board' notes in every section provide genuine value for different audiences without requiring complete rewrites",
          "Strong attention to evaluation ethics and data quality\u2014consent processes, missing data acknowledgment, and limitations section demonstrate professional standards",
          "The recommendations table with feasibility ratings, resource needs, and success measures is immediately actionable and realistic for nonprofit capacity",
          "Plain-language callouts effectively translate technical terms without being condescending, making the report accessible to diverse stakeholders",
          "Authentic nonprofit voice throughout\u2014acknowledges challenges honestly (gender wage gap, credential delays) while maintaining constructive framing"
        ],
        "weaknesses": [
          "Some minor redundancy between sections (e.g., program description appears in both Executive Summary and Program Overview with similar detail\u2014could be streamlined for the 18-22 page target)",
          "The 'In plain language' callouts, while helpful, occasionally state the obvious (e.g., 'This section tells busy readers what changed')\u2014a few could be more substantive or omitted",
          "A few data points in the scenario appear inconsistent (baseline median wage of $17.40 vs endline of $21.10 in one place, but actual of $21.80 in another)\u2014the template handles this well by noting the discrepancy, but it slightly undermines credibility",
          "Could benefit from one additional visual example beyond placeholders (e.g., a simple mock bar chart) to fully demonstrate expected formatting standards"
        ],
        "evaluator_model": "claude-sonnet-4.5"
      }
    },
    {
      "scenario_id": "scenario_3",
      "model": "gpt5",
      "model_display_name": "ChatGPT (GPT-5)",
      "content": "Pacific Horizons Refugee Services (PHRS)\nCareer Pathways for New Americans\nEvaluation Report Template (Fill-in-Ready)\nReport period: January 1\u2013December 31, 2024\nGeographic scope: King County, Washington (Seattle, Kent, Tukwila, Burien, Renton)\nTone: BALANCED (professional and approachable)\nPage target: 18\u201322 pages\n\nFront matter (complete before drafting)\n- Title: Career Pathways for New Americans \u2014 2024 Evaluation Report\n- Prepared by: Lina Nguyen, Senior Evaluation Manager\n- In collaboration with: PHRS Impact & Learning Unit (internal)\n- Date: 2025-02-05\n- Report covers: January 1\u2013December 31, 2024\n- Geographic scope: King County, Washington (Seattle, Kent, Tukwila, Burien, Renton)\n- Audiences and uses:\n  - Primary: [PHRS program leadership and employment specialists \u2014 use to improve service delivery, staffing, and scheduling decisions]\n  - Secondary: [Employer partners and community colleges \u2014 use to refine cohorts and bridge courses]\n  - Funders/Board: Office of Refugee Resettlement (ORR), Washington Department of Commerce (WA Commerce), Ballmer Group, PHRS Board of Directors \u2014 use to assess performance vs. grant KPIs, inform future funding\n- Acronyms defined on first use:\n  - PHRS: Pacific Horizons Refugee Services\n  - ORR: Office of Refugee Resettlement\n  - WA UI: Washington State Unemployment Insurance (wage file)\n  - ESL: English as a Second Language\n  - KPI: Key Performance Indicator\n  - ETO: Efforts to Outcomes (PHRS administrative database)\n  - SIV: Special Immigrant Visa\n\nAudiences and Uses (state clearly in your own words)\n- Primary audience and intended uses: [e.g., PHRS program staff/leadership \u2014 to improve service delivery and plan 2025 strategy]\n- Secondary audience(s) and intended uses: [e.g., Employer partners and community colleges \u2014 to align cohorts and hiring expectations]\n- Funders/Board: ORR; Washington Department of Commerce; Ballmer Group; PHRS Board of Directors \u2014 [use to assess progress vs. funded objectives and resource use]\n\n1) Executive Summary (350\u2013600 words)\nPurpose: Summarize what changed, for whom, and what you\u2019ll do next.\n\nUse this fill-in framework (edit as needed):\n- Program purpose and who it serves:\n  - [Career Pathways for New Americans helps newly arrived refugees, asylees, SIV holders, and humanitarian parolees secure quality employment aligned with their skills through contextualized ESL, credential evaluation, career coaching, and employer partnerships.]\n- Reach and participation (2024 defaults \u2014 revise if needed):\n  - [Clients served: 1,085 total; 54% women; clients from 46 countries.]\n  - [Top languages: Arabic, Dari, Somali, Ukrainian.]\n  - [Eligibility: Refugee/asylee/SIV/humanitarian parole within 5 years of arrival.]\n  - [Average service duration: 14 weeks; average ESL instructional hours: 48; median career coaching sessions: 6.]\n- Headline outcomes (2024 defaults \u2014 revise if needed):\n  - [Job placement within 90 days: 63% (target: 60%). Data source: ETO admin records, employer verification.]\n  - [90-day retention: 72% of placed clients (target: 70%). Data source: employer verification, case notes.]\n  - [Median starting wage: $21.80 (target: $21.00). Data source: employer verification; WA UI file (lagged).]\n  - [Credential equivalency achieved for 214 clients (target: 200). Data source: WES/credential evaluators.]\n  - [Sample client quote (consented): \u201cMy mentor helped me translate my nursing experience to U.S. terms.\u201d \u2014 Client U-221]\n- Equity highlights (defaults \u2014 tailor with your data):\n  - [Placement gap by gender: women 59% vs. men 67%.]\n  - [Median wage gap: women $20.10 vs. men $23.00.]\n  - [Planned response: childcare stipend pilot, evening ESL expansion, salary negotiation workshops tailored for women.]\n- High-level recommendations (defaults \u2014 confirm or revise):\n  - ['Pilot childcare stipend for job seekers (Q2 2025)']\n  - ['Increase evening ESL sections by 25% (Q2 2025)']\n  - ['Add employer cohort in healthcare support roles (Q3 2025)']\n- Overall assessment/learning stance:\n  - [Strong placement and retention supported by robust employer partnerships. Persistent wage and placement gaps for women and clients with limited English proficiency; credential evaluation backlogs delay sector-aligned hiring. We will address these with targeted scheduling, financial supports, and credential process improvements.]\n\nIn plain language: This section tells busy readers what changed, for whom, and what we\u2019ll do next.\n\nHow to adapt for funders/board: Keep to one page; lead with grant KPIs, cost-per-placement/retained job if available; tie results to specific grant objectives.\n\nExample (model the level of detail and tone):\n\u201cIn 2024, the Youth Pathways mentoring program served 127 students in Westview (62% Latinx, 28% Black; 71% eligible for free/reduced lunch). Attendance improved for 89% of participants; average chronic absence dropped from 16% to 9% over two semesters. Students completing 10+ mentoring sessions were 2.1x more likely to submit all homework on time. Youth and caregiver interviews highlighted stronger school belonging and improved communication at home. We recommend formalizing caregiver touchpoints and expanding peer mentoring to all cohorts.\u201d\n\n2) Program Overview (300\u2013450 words)\nPurpose: Provide context, goals, activities, and resources.\n\nUse this fill-in framework:\n- Goals and theory of change:\n  - [Career Pathways aims to connect newly arrived adults to quality, skill-aligned employment. If we provide contextualized ESL, targeted coaching, credential evaluation support, and employer cohort hiring opportunities, then participants will overcome language, credential, and network barriers and enter living-wage jobs more quickly.]\n- Target population and eligibility:\n  - [Adults (18\u201364) across King County \u2014 Seattle, Kent, Tukwila, Burien, Renton. Eligibility: refugee, asylee, SIV, or humanitarian parole, within five years of arrival. Common barriers: limited English, childcare access, credential recognition, limited professional networks, transportation costs.]\n- Activities and dosage (defaults \u2014 edit to match 2024 operations):\n  - [Contextualized ESL and bridge courses: 4\u20136 hours/week]\n  - [Career coaching and job readiness workshops: biweekly]\n  - [Credential evaluation and licensing navigation]\n  - [Employer cohort hiring events and paid work experiences]\n  - [Mentor matching and retention coaching]\n- Staffing and resources (defaults):\n  - [65 staff, including certified employment specialists and ESL instructors; 120 volunteer mentors; partnerships with local colleges and 75 employers; 2024 program budget: $3.2M.]\n- 2024 context:\n  - [Seattle minimum wage increases; tech sector volatility; rising demand in healthcare support roles; large arrivals from Ukraine and Afghanistan.]\n- Logic model and documentation:\n  - [See Appendix A: Logic Model; Appendix B: Data Collection Instruments; Appendix C: Indicator Definitions.]\n\nSample phrasing you can adapt:\n\u201cIn 2024, Career Pathways for New Americans served 1,085 participants through: \u2018Contextualized ESL and bridge courses\u2019; \u2018Career coaching and job readiness workshops\u2019; \u2018Credential evaluation and licensing navigation\u2019; \u2018Employer cohort hiring and paid work experience\u2019; and \u2018Mentor matching and retention coaching\u2019 to achieve job placement within 90 days (target 60%, actual 63), 90-day retention (target 70%, actual 72), median starting wage ($21.00 target, $21.80 actual), and 214 credential equivalencies (target 200).\u201d\n\nHow to adapt for funders/board: Map activities to funded objectives and approved budget lines. Name specific employer and education partners tied to grants.\n\n3) Evaluation Questions & Methodology (300\u2013500 words)\nPurpose: Explain what you asked, how you measured, and how you protected participants.\n\nEvaluation questions (select 3\u20135 and refine):\n- [To what extent did participants achieve job placement within 90 days, 90-day retention, and competitive starting wages?]\n- [Which program components (ESL, credential support, employer cohorts, coaching) were most/least helpful and for whom?]\n- [Where do inequities appear (e.g., by gender, language level, country of origin, age), and what are plausible drivers?]\n- [What factors predict higher wage offers and faster sector-aligned placement?]\n- [How satisfied are employers and participants with program supports?]\n\nDesign/approach:\n- [Cohort tracking with pre-post indicators; contribution (not attribution) lens; no randomized comparison group; limited benchmarking to county labor data where feasible.]\n\nData sources:\n- [ETO admin logs; WA UI wage file (lagged); employer satisfaction survey; multilingual intake/exit participant surveys; focus groups with Arabic, Dari, Somali, and Ukrainian interpretation; case notes; credential evaluator reports.]\n\nSampling and timing:\n- [Admin data: full sample (N=[insert]); Surveys: [insert N, response rates]; Focus groups: [# groups, # participants], conducted [months]. Employer survey: [N employers], response rate [X%].]\n\nData quality checks:\n- [Missing data review; cross-check self-reported wages with employer verification/UI where available; spot audits of 10% of case files; duplicate record checks; coding reliability check (kappa \u22650.70) for qualitative themes.]\n\nEthics/consent:\n- [Written consent in 7 languages; privacy statement aligned with ORR; quotes included only with written permission; identifiable information stored on secure servers; IRB not required.]\n\nEquity and participation:\n- [Client Advisory Council (12 members) co-designed 6 survey items; interpreters and onsite childcare provided during focus groups; two co-interpretation workshops held with staff and clients (December 2024).]\n\nIn plain language: We measured success by tracking placements, retention, wages, and credential outcomes in our database, alongside surveys, interviews, and employer feedback, with participants\u2019 consent and interpreters as needed.\n\nTable shell: Methods overview\n- Method | Sample/Response Rate | Timeline | Purpose/Questions Informed | Data Quality Steps\n- [Admin ETO data] | [N=?, 100%] | [Jan\u2013Dec 2024] | [All KPIs; subgroup equity] | [Missing data checks; audits]\n- [Participant surveys] | [N=?, ?%] | [Intake, exit, 90 days] | [Satisfaction; barriers; helpful components] | [Translation checks; reliability]\n- [Employer survey] | [N=?, ?%] | [Q3\u2013Q4] | [Readiness; retention drivers] | [Follow-up for nonresponse]\n- [Focus groups] | [# groups/# participants] | [Q2\u2013Q4] | [Context for gaps] | [Bilingual facilitation; consent]\n\nHow to adapt for funders/board: Keep design concise; emphasize alignment to grant indicators, consent procedures, and response rates.\n\n4) Findings by Outcome Area (400\u2013700 words per outcome)\nInstructions for each outcome:\n- Define outcome and indicators\n- Present quantitative results with KPI table and a simple visual placeholder\n- Add qualitative insights (themes + 1\u20132 quotes with consent)\n- Apply an equity lens (disaggregate by key demographics and interpret gaps)\n- Frame mixed/negative results using: What we learned / Why this matters / What we\u2019re changing\n- Tag evidence sources (e.g., \u201cETO admin record,\u201d \u201cEmployer survey Q4\u201d)\n\nKey demographics for equity breakdowns (defaults \u2014 adapt to your context):\n- [Age group], [Gender], [Race/ethnicity], [Primary language], [English proficiency level], [Income bracket], [City/ZIP], [Arrival cohort/nationality]\n\n4.1 Outcome A: Job placement within 90 days\n- Definition and indicator(s):\n  - [Indicator: % of enrolled job-seeking clients placed within 90 days of intake. Target: 60%.]\n- Quantitative results (defaults \u2014 replace with final numbers as needed):\n  - [Actual: 63% placed within 90 days (n=1,085). Source: ETO admin data; employer verification.]\n- KPI table shell:\n  - Indicator | Target | Actual | % Achieved | Data Source | Notes\n  - % placed within 90 days | 60% | 63% | 105% | ETO; employer verification | [Include unsubsidized and subsidized placements]\n- Visual placeholder:\n  - [Figure A1 placeholder: Bar chart \u2014 Placement rate target vs. actual]\n  - Caption prompt: \u201cParticipants achieved [63%] placement within 90 days vs. [60%] target (n=1,085). Source: [ETO; employer verification].\u201d\n- Disaggregation prompts (enter your data):\n  - [By gender: Women [59%], Men [67%]]\n  - [By English proficiency: Limited [58%], Advanced [69%]]\n  - [By nationality (examples): Ukrainian [65%], Afghan [60%], Somali [61%]]\n  - Interpretation: [Briefly interpret gaps and likely drivers.]\n- Qualitative insights (themes):\n  - [Employer cohort events accelerated hiring decisions, especially in healthcare support roles.]\n  - [Mentorship improved resume translation and interview confidence.]\n  - Quote placeholder(s): \u201c[\u2018My mentor helped me translate my nursing experience to U.S. terms.\u2019 \u2014 U-221, consented]\u201d\n- Mixed/negative results:\n  - What we learned: [Limited English proficiency slowed sector-aligned placement for healthcare and IT.]\n  - Why this matters: [Delays can push clients into lower-wage jobs below skill level.]\n  - What we\u2019re changing: [Add evening ESL sections and a sector vocabulary module by Q2 2025; pilot childcare stipends.]\n- Evidence tags: [ETO admin record; Employer survey Q2; Focus Group B \u2014 ESL Cohort]\n- How to adapt for funders/board: Open with the KPI table and one chart; add a one-sentence equity note; footnote data sources.\n\nExample (expected specificity):\n- Indicator: % placed within 90 days\n- Target: 60%; Actual: 63% (n=1,085); % Achieved: 105%\n- Disaggregation: Women 59%, Men 67%; Limited English 58%, Advanced 69%\n- Theme: \u201cCohort hiring events at two hospital systems produced 118 hires in Q3\u2013Q4; candidates averaged 2.3 weeks faster placement than non-cohort seekers.\u201d\n\n4.2 Outcome B: 90-day job retention\n- Definition and indicator(s):\n  - [Indicator: % of placed clients retained at 90 days post-start. Target: 70%.]\n- Quantitative results (defaults \u2014 replace with final numbers as needed):\n  - [Actual: 72% (n=678 placed clients). Source: employer verification; case notes.]\n- KPI table shell:\n  - Indicator | Target | Actual | % Achieved | Data Source | Notes\n  - % retained at 90 days | 70% | 72% | 103% | Employer verification; case notes | [Include unsubsidized and subsidized]\n- Visual placeholder:\n  - [Figure B1 placeholder: Simple bar chart \u2014 Retention rates by industry]\n  - Caption prompt: \u201c90-day retention varied by industry: [Healthcare support 76%], [Warehouse/logistics 68%], [IT support 81%], [Hospitality 70%] (n=678). Source: [Employer verification].\u201d\n- Disaggregation prompts:\n  - [By industry: insert rates]\n  - [By shift type: day vs. swing vs. night]\n  - [By city/ZIP: e.g., Tukwila vs. Seattle]\n  - Interpretation: [Warehouse/logistics retention lagged, suggesting mismatch in schedules and physical demands.]\n- Qualitative insights:\n  - [Supervisor check-ins and mentor support reduced early churn; transportation subsidies aided punctuality in first month.]\n  - Quote placeholder: \u201c[\u2018Weekly check-ins helped me solve small issues before they got big.\u2019 \u2014 R-310, consented]\u201d\n- Mixed/negative results:\n  - What we learned: [Retention lowest in warehouse/logistics; caregivers cited childcare conflicts with swing shifts.]\n  - Why this matters: [Early attrition disrupts household income and employer trust.]\n  - What we\u2019re changing: [Extend retention coaching to 120 days for warehouse placements (Q3 2025); co-create job previews with employer partners; advocate for shift flexibility.]\n- Evidence tags: [Employer verification; Case notes; Mentor survey Q12]\n\n4.3 Outcome C: Starting wages and wage equity\n- Definition and indicator(s):\n  - [Indicators: Median starting wage (USD); % at/above living wage benchmark; wage gaps by subgroup. Target median: $21.00.]\n- Quantitative results (defaults \u2014 replace as needed):\n  - [Actual median starting wage: $21.80 (n=[insert]); Source: employer verification; WA UI (lagged).]\n- KPI table shell:\n  - Indicator | Target | Actual | % Achieved | Data Source | Notes\n  - Median starting wage (USD) | $21.00 | $21.80 | 104% | Employer verification; WA UI | [County minimum wage context]\n  - % at/above living wage | [insert] | [insert] | [insert] | [Specify source] | [Define benchmark]\n- Visual placeholder:\n  - [Figure C1 placeholder: Box-and-whisker \u2014 starting wages by gender]\n  - Caption prompt: \u201cMedian starting wage by gender (n=[N]): Women [$20.10], Men [$23.00]. Source: [WA UI; employer payroll].\u201d\n- Disaggregation prompts:\n  - [By gender; English proficiency; city; industry; nationality/arrival cohort]\n  - Interpretation: [Gender wage gap persists ($2.90). Negotiation coaching and childcare appear linked to offers.]\n- Qualitative insights:\n  - [Credential recognition correlated with higher offers in healthcare; negotiation coaching boosted IT support offers.]\n  - Quote placeholder: \u201c[\u2018Once my degree was recognized, employers took my application seriously.\u2019 \u2014 D-144, consented]\u201d\n- Mixed/negative results:\n  - What we learned: [Credential evaluation timelines delay higher-wage, sector-aligned placements.]\n  - Why this matters: [Delays push clients toward short-term, lower-wage jobs.]\n  - What we\u2019re changing: [Batch WES submissions monthly; prescreen credential pathways during intake; offer bridge roles with advancement ladders.]\n- Evidence tags: [WA UI wage file; WES outcomes; Employer survey Q6]\n\n4.4 Outcome D: Credential recognition and utilization\n- Definition and indicator(s):\n  - [Indicators: # credential equivalencies or license milestones; % using credential in job placement; time-to-equivalency.]\n  - Targets (defaults): [200 credential equivalencies; achieved 214.]\n- Quantitative results:\n  - [Actual: 214 credentials recognized (n applicants=[insert]); median time-to-equivalency: [insert weeks]. Source: WES/board records; ETO.]\n- KPI table shell:\n  - Indicator | Target | Actual | % Achieved | Data Source | Notes\n  - # credential equivalencies | 200 | 214 | 107% | WES; licensing boards | [Top fields: nursing, engineering, teaching]\n  - % placed using credential | [insert] | [insert] | [insert] | ETO; employer verification | [Define \u201cusing credential\u201d]\n- Visual placeholder:\n  - [Figure D1 placeholder: Funnel \u2014 applicants \u2192 submitted \u2192 evaluated \u2192 recognized \u2192 sector-aligned job]\n  - Caption prompt: \u201cCredential pipeline outcomes, 2024 (n=[N]). Source: [WES; licensing boards; ETO].\u201d\n- Disaggregation prompts:\n  - [By field (health, education, engineering); by gender; by language; by country.]\n  - Interpretation: [Backlogs highest in [field]; women report more interruptions due to caregiving.]\n- Qualitative insights:\n  - [Clients credit one-on-one navigation for overcoming documentation hurdles; employers value clear credential summaries.]\n  - Quote placeholder: \u201c[\u2018The step-by-step guide helped me avoid mistakes and saved time.\u2019 \u2014 A-078, consented]\u201d\n- Mixed/negative results:\n  - What we learned: [Applicants with incomplete documentation face multi-month delays.]\n  - Why this matters: [Extended timelines reduce earnings and talent utilization in shortage fields.]\n  - What we\u2019re changing: [Add document checklists at intake; schedule monthly credential clinics with interpreters; fund application fees for priority sectors.]\n- Evidence tags: [Credential tracking log; Client interviews; Case notes]\n\nHow to adapt for funders/board (applies to all four outcomes): Lead with KPI tables and one visual per outcome; keep quotes short; add footnotes for methods and any data caveats.\n\n5) Discussion/Interpretation (300\u2013500 words)\nPurpose: Make sense of results and connect back to your theory.\n\nPrompts:\n- Connect findings to theory of change:\n  - [Employer cohort hiring plus mentor support accelerated placements; credential recognition combined with sector ESL improved wage offers in healthcare support.]\n- Triangulate evidence:\n  - [ETO/admin trends align with employer survey feedback on readiness; participant interviews identify childcare and language as persistent barriers that explain gender and proficiency gaps.]\n- External factors:\n  - [Higher minimum wage and improved transit access aided outcomes; tech sector layoffs shifted some clients into IT support pathways with strong retention.]\n- Surprises:\n  - [Faster-than-expected wage gains in healthcare support; verified through employer wage surveys and WA UI files.]\n- Learning stance (use the framing):\n  - What we learned: [e.g., Providing more evening ESL improved attendance among caregivers.]\n  - Why this matters: [Increases equitable access and reduces placement delays.]\n  - What we\u2019re changing: [Scale evening sections; embed childcare supports and negotiation workshops.]\n\nIn plain language: Here we explain why outcomes look the way they do and what that means for clients and operations.\n\nHow to adapt for funders/board: Emphasize accountability, lessons tied to KPIs, and clear course corrections with timelines.\n\n6) Recommendations & Next Steps (250\u2013400 words)\nPurpose: Translate insights into specific, resourced actions.\n\nGuidance:\n- Tie each recommendation to an insight, outcome, and equity gap.\n- Ensure feasibility with available resources: 65 staff across workforce and ESL, 3 analysts in the Evaluation Unit, 120 mentors, $3.2M budget.\n- Sequence actions (immediate, 3\u20136 months, 12 months).\n\nTable shell:\n- Recommendation | Owner/Lead | Timeframe (immediate/3\u20136 months/12 months) | Resource Needs (staff hours, budget) | Feasibility (H/M/L) | Success Measure\n- Expand evening ESL by 25% in Seattle/Kent | [ESL Director] | 3\u20136 months | [80 staff hours; $15K adjuncts] | [H] | [Attendance +15%; placement gap narrows by 3 pts]\n- Pilot childcare stipend for job seekers | [Program Manager] | 3\u20136 months | [$30K pilot fund] | [M] | [Placement for women +4 pts; retention +3 pts]\n- Add healthcare support employer cohort | [Employer Relations Lead] | 6\u201312 months | [40 hrs; partner MOUs] | [H] | [100 cohort hires; 90-day retention \u226575%]\n- Batch WES submissions monthly + intake screening | [Credential Navigator] | Immediate | [20 hrs setup] | [H] | [Time-to-equivalency -3 weeks]\n- Salary negotiation workshops for women | [Career Coach Lead] | Immediate | [10 hrs/month; volunteer mentors] | [H] | [Reduce wage gap by $0.75]\n\nSample recommendations (you can adapt):\n- \u201cExpand peer mentoring to all cohorts | Program Manager | 6 months | 20 staff hours, $2K | High | \u226575% cohort participation\u201d\n- \u201cStandardize caregiver outreach script and schedule | Family Liaison | Immediate | 8 hours setup | High | 80% reach within first month\u201d\n\nHow to adapt for funders/board: Flag budget-neutral options; identify items requiring reallocation or future grant funding; link to grant deliverables.\n\n7) Limitations (150\u2013250 words)\nPurpose: Be transparent about uncertainty and constraints.\n\nPrompts (defaults \u2014 revise with your specifics):\n- Sample/response: [Employer survey response rate was [X%]; participant exit survey [Y%], potentially biasing satisfaction upward.]\n- Missing data: [WA UI wage data missing for ~29% of placed clients due to recency or SSN gaps; cross-checked with employer payroll when available.]\n- Design constraints: [No comparison group; short follow-up window (90 days) may miss late attrition or delayed wage growth.]\n- External influences: [Sector shifts and policy changes (minimum wage) confound causal interpretation.]\n- Ethics/consent: [Documented multi-language consents; de-identified analysis; secure servers.]\n- Mitigations: [Triangulated multiple sources; sensitivity checks; subgroup analyses.]\n\nIn plain language: Here\u2019s what we couldn\u2019t measure or are less sure about, and how we tried to reduce those gaps.\n\nHow to adapt for funders/board: Keep concise; clearly state steps taken to mitigate limitations and any impact on interpreting KPIs.\n\n8) Appendices (checklist with placeholders)\nAttach or link as available:\n- [ ] Appendix A: Logic model or theory of change [Insert diagram or one-page logic model]\n- [ ] Appendix B: Data collection instruments [Surveys; interview/focus group guides; employer survey]\n- [ ] Appendix C: Detailed data tables by demographic subgroup [CSV or spreadsheet]\n- [ ] Appendix D: Sample consent forms and data privacy statement [Multi-language]\n- [ ] Appendix E: Complete indicator list with definitions and calculation notes\n- [ ] Appendix F: Additional participant quotes (with consent documentation)\n- [ ] Appendix G: Data quality checks (missing data rates; audit logs; reliability statistics)\n\nVisuals and Tables: Placeholders and Captions\n- Place each visual with:\n  - Title [Insert descriptive title]\n  - Caption [What the reader should see in one sentence]; include n-size and data source\n  - Notes [Any caveats or definitions]\n- Sample visual placeholders you can copy:\n  - [Figure X: Placement within 90 days by gender \u2014 Bar chart]\n    - Caption: \u201cWomen [59%] vs. men [67%] placement rate (n=[N]). Source: [ETO; employer verification].\u201d\n  - [Figure Y: Starting wages by industry \u2014 Box plot]\n    - Caption: \u201cMedian wages ranged from [$19.80] in hospitality to [$24.10] in IT support (n=[N]). Source: [WA UI].\u201d\n  - [Figure Z: Credential pipeline \u2014 Funnel]\n    - Caption: \u201cOf [N] credential applicants, [N1] submitted complete packages, [N2] recognized, [N3] placed in sector roles. Source: [WES; ETO].\u201d\n\nEquity and Participation Prompts (embed throughout)\n- Disaggregate by: [Age; Gender; Race/Ethnicity; Primary Language; English proficiency; Income; City/ZIP; Arrival cohort/nationality].\n- Interpretation prompts:\n  - \u201cWhose outcomes improved least? What are the likely drivers (e.g., scheduling, childcare, transport, language level, discrimination)?\u201d\n  - \u201cWhat operational changes will we test to close these gaps?\u201d\n- Participation:\n  - \u201cWhose voices informed this evaluation? Who is missing, and how will we include them next time?\u201d\n  - \u201cNote access supports in data collection (interpreters, childcare, transportation vouchers).\u201d\n- Participatory steps (defaults):\n  - [Two co-interpretation workshops with staff and Client Advisory Council (December 2024).]\n\nFormatting and Style Requirements (apply consistently)\n- Define all acronyms on first use.\n- Use specific numbers and percentages; avoid \u201cmany/most.\u201d\n- Tie each claim to a data source.\n- Use plain English; add \u201cIn plain language\u201d callouts for technical terms.\n- Visuals: include captions, n-sizes, and data sources.\n- Include constructive subheads for mixed/negative results: \u201cWhat we learned / Why this matters / What we\u2019re changing.\u201d\n\nData Tables: Reusable Shells\n1) KPI summary table (all outcomes)\n- Outcome/Indicator | Target | Actual | % Achieved | N | Data Source | Notes\n- Placement within 90 days | 60% | 63% | 105% | 1,085 | ETO; employer verification | Includes subsidized/unsubsidized\n- 90-day retention | 70% | 72% | 103% | 678 | Employer verification; case notes | \u2014\n- Median starting wage (USD) | $21.00 | $21.80 | 104% | [N] | Employer verification; WA UI | County minimum wage context\n- Credential equivalencies (#) | 200 | 214 | 107% | [N] | WES; licensing boards | Top fields: nursing, engineering, teaching\n\n2) Disaggregation table shell\n- Subgroup | Indicator | Target | Actual | Gap vs. overall | N | Interpretation | Action\n- Women | Placement | 60% | 59% | -4 pts | [N] | [Childcare/scheduling cited] | [Childcare stipend; evening ESL]\n- Men | Placement | 60% | 67% | +4 pts | [N] | [\u2014] | [\u2014]\n- Limited English | Placement | 60% | 58% | -5 pts | [N] | [Language barriers] | [Sector vocabulary modules]\n\n3) Methods overview table (replicate from Section 3)\n- Method | Sample/Response Rate | Timeline | Purpose/Questions Informed | Data Quality Steps\n- [Fill as above]\n\n\u201cIn plain language\u201d callouts (examples you can reuse)\n- Placement within 90 days: \u201cHow quickly people got a job after joining.\u201d\n- 90-day retention: \u201cWhether they stayed in that job for at least three months.\u201d\n- Credential equivalency: \u201cGetting overseas education recognized in the U.S.\u201d\n- Living wage: \u201cEnough pay to meet basic expenses in King County.\u201d\n\n\u201cHow to adapt for funders/board\u201d notes (apply per section)\n- Executive Summary: One page; KPIs first; add cost-per-outcome if available.\n- Program Overview: Map to grant objectives and budget.\n- Methods: Emphasize data validity, consent, response rates.\n- Findings: KPI table + one visual; short, source-cited quotes; footnotes for caveats.\n- Discussion: Lessons tied to outcomes; realistic next steps.\n- Recommendations: Time-bound, resourced; flag budget-neutral vs. funding-required.\n- Limitations: Transparent, concise; note mitigation.\n\nQuick-start defaults used in this template (revise if you have better data)\n- Reach and participation: 1,085 clients; 54% women; 46 countries; Arabic/Dari/Somali/Ukrainian top languages; average 14 weeks; 48 ESL hours; median 6 coaching sessions.\n- KPIs: 63% placement within 90 days; 72% 90-day retention; $21.80 median starting wage; 214 credential equivalencies.\n- Equity patterns: Lower placement and wages for women and limited English; response: evening ESL; childcare stipends; negotiation workshops.\n- Data sources: ETO admin, WA UI, employer survey, participant surveys and focus groups.\n- Team capacity: Program staff 65; Evaluation Unit 3 analysts; mentors 120; budget $3.2M.\n\nOptional funder/board adaptation checklist\n- [ ] Insert grant-specific KPI targets and actuals\n- [ ] Add cost-per-placement and cost-per-retained job\n- [ ] Include compliance notes (e.g., ORR reporting fields)\n- [ ] Add short budget variance note if relevant\n- [ ] Limit quotes to 1\u20132 per outcome; keep concise\n\nEndnotes/Footnotes (optional)\n- [1] WA UI (Washington State Unemployment Insurance) data are lagged by ~1\u20132 quarters.\n- [2] All quotes included with written consent; IDs de-identified.\n\nHow to refine this template (ask the AI for help)\n- \u201cShorten the methodology to 200 words.\u201d\n- \u201cAdd a visual for the retention KPI and write a caption.\u201d\n- \u201cRewrite for a FORMAL tone for a board packet.\u201d\n- \u201cDraft two equity-focused recommendations with owners and timelines.\u201d\n- \u201cCreate a one-page KPI dashboard summary for funders.\u201d",
      "timestamp": "2025-11-02T14:13:48.569676Z",
      "duration_seconds": 120.11,
      "tokens": {
        "input": 4405,
        "output": 8447,
        "total": 12852
      },
      "cost_usd": 0.13992,
      "success": true,
      "evaluation": {
        "overall_score": 8.8,
        "criteria_scores": {
          "tone": 9,
          "completeness": 9,
          "usefulness": 9,
          "accuracy": 9,
          "authenticity": 8
        },
        "reasoning": "This is an exceptionally thorough, well-structured template that demonstrates deep understanding of nonprofit evaluation practice. It successfully balances technical rigor with accessibility, provides concrete examples at the right level of specificity, and embeds equity considerations throughout. The template is immediately usable and would save practitioners significant time.",
        "strengths": [
          "Outstanding structural completeness\u2014every promised element is present: section headings with word counts, bracketed fill-in prompts, concrete examples in Executive Summary and Findings, table shells, visual placeholders with caption prompts, 'In plain language' callouts, funder/board adaptation notes, and equity prompts",
          "Exemplary use of realistic, sector-appropriate examples (e.g., the Youth Pathways example, the credential pipeline funnel, specific wage gaps by gender) that model the expected level of detail without being prescriptive",
          "Sophisticated equity integration\u2014disaggregation prompts are embedded in every outcome section with the 'What we learned/Why this matters/What we're changing' framework for addressing gaps, not just reporting them",
          "Excellent balance of professional rigor and accessibility\u2014technical terms are defined, plain-language callouts are genuinely helpful, and the BALANCED tone is consistently maintained",
          "Highly practical recommendations section with a detailed table shell including Owner, Timeframe, Resource Needs, Feasibility, and Success Measures\u2014this operationalizes insights effectively",
          "Thoughtful adaptation guidance for multiple audiences (funders/board notes in every section) without creating separate templates",
          "Strong attention to ethical considerations\u2014consent, privacy, language access, and participatory elements are woven throughout, not siloed",
          "Comprehensive appendices checklist and reusable table shells that would genuinely accelerate report production",
          "The 'How to refine' section at the end provides clear next-step prompts for users to customize further"
        ],
        "weaknesses": [
          "Minor repetition\u2014some guidance (e.g., 'define acronyms,' 'cite sources') appears in multiple sections when a single reference to formatting standards might suffice",
          "The template is very long (likely exceeds 22 pages even unfilled), which may be overwhelming for smaller organizations despite the quality; a one-page 'quick navigation guide' at the start could help",
          "A few bracketed prompts could be more specific\u2014for example, in the Discussion section, 'Connect findings to theory of change' could include a sentence starter like '[Component X] likely drove [Outcome Y] because [mechanism]...'",
          "The authenticity score reflects minor instances of AI-typical phrasing (e.g., 'Here we make sense of why results look the way they do') that, while clear, sound slightly formulaic compared to how an experienced evaluator might write"
        ],
        "evaluator_model": "claude-sonnet-4.5"
      }
    },
    {
      "scenario_id": "scenario_3",
      "model": "claude",
      "model_display_name": "Claude (Sonnet 4.5)",
      "content": "# CAREER PATHWAYS FOR NEW AMERICANS\n## 2024 Annual Evaluation Report\n\n**Pacific Horizons Refugee Services (PHRS)**  \nKing County, Washington (Seattle, Kent, Tukwila, Burien, Renton)\n\n---\n\n**Reporting Period:** January 1\u2013December 31, 2024\n\n**Prepared by:** Lina Nguyen, Senior Evaluation Manager  \n**In collaboration with:** PHRS Impact & Learning Unit (internal)  \n**Report Date:** February 5, 2025\n\n**Geographic Scope:** King County, Washington (Seattle, Kent, Tukwila, Burien, Renton)\n\n**Audiences and Uses:**\n- **Primary:** PHRS program leadership and employment specialists (to improve service delivery, identify gaps, and allocate resources)\n- **Secondary:** Employer partners and community colleges (to strengthen collaboration and referral pathways)\n- **Funders/Board:** Office of Refugee Resettlement (ORR); Washington Department of Commerce; Ballmer Group; PHRS Board of Directors (to demonstrate outcomes, compliance, and stewardship)\n\n---\n\n## TABLE OF CONTENTS\n\n1. Executive Summary ............................................................... 3\n2. Program Overview ................................................................. 5\n3. Evaluation Questions & Methodology ...................................... 7\n4. Findings by Outcome Area ..................................................... 10\n5. Discussion/Interpretation ....................................................... 17\n6. Recommendations & Next Steps ............................................. 19\n7. Limitations ........................................................................... 21\n8. Appendices .......................................................................... 22\n\n---\n\n## 1. EXECUTIVE SUMMARY\n**Target length: 350\u2013600 words**\n\n> **In plain language:** This section tells busy readers what changed, for whom, and what we'll do next.\n\n> **How to adapt for funders/board:** Lead with outcomes tied to grant objectives; keep to one page; include grant KPIs and cost-per-outcome if available. For ORR, lead with placement and retention metrics; for Ballmer Group, highlight equity gaps and corrective actions.\n\n### Program Purpose and Who We Served\n\n[In 2024, Career Pathways for New Americans supported newly arrived refugees, asylees, Special Immigrant Visa holders, and humanitarian parolees to secure quality employment aligned with their skills and experience. The program combines contextualized English as a Second Language (ESL) instruction, credential evaluation support, career coaching, and employer partnership cohort hiring to reduce barriers and accelerate entry to stable, living-wage jobs.]\n\n[We served **1,085 clients** (54% women, 46% men) from **46 countries of origin**. The top languages spoken were Arabic, Dari, Somali, and Ukrainian. Eligibility criteria included refugee, asylee, SIV, or humanitarian parole status within 5 years of arrival in the United States. Participants were adults aged 18\u201364 residing across King County, with the majority in Seattle, Kent, Tukwila, Burien, and Renton.]\n\n### Participation and Dosage\n\n[Clients engaged with the program for an average of **14 weeks**, receiving approximately **48 hours of ESL instruction** and a median of **6 one-on-one career coaching sessions**. Additional touchpoints included credential evaluation navigation, job readiness workshops, paid work experiences, and mentor matching for retention support.]\n\n### Top Findings\n\n**Job Placement (Target: 60%; Actual: 63%)**  \n[Sixty-three percent of enrolled job-seeking clients secured employment within 90 days of intake, exceeding our annual target. Employer cohort hiring events and mentor-supported application preparation accelerated hiring decisions. However, **women placed at 59% compared to 67% for men**, with childcare access and shift scheduling cited as primary barriers.]\n\n**90-Day Job Retention (Target: 70%; Actual: 72%)**  \n[Seventy-two percent of placed clients remained employed at the 90-day mark (n=678). Retention was highest in IT support roles (81%) and lowest in warehouse/logistics (68%). Weekly supervisor check-ins and transportation subsidies reduced early turnover. One client shared: *\"Weekly check-ins helped me solve small issues before they got big.\"* \u2014 Client R-310 (consented).]\n\n**Wages and Credential Utilization**  \n[The median starting wage was **$21.80/hour**, slightly above our $21.00 target and well above the 2024 baseline of $17.40. **214 clients** achieved credential equivalency through World Education Services (WES), surpassing our goal of 200. Credential recognition correlated with higher wage offers, particularly in healthcare support roles. Yet a **$2.90 median wage gap persists between men ($23.00) and women ($20.10)**, driven in part by occupational sorting and negotiation confidence. As one client explained: *\"Once my degree was recognized, employers took my application seriously.\"* \u2014 Client D-144 (consented).]\n\n### Concrete Example (model the level of detail and tone):\n\n*\"In 2024, the Youth Pathways mentoring program served 127 students in Westview (62% Latinx, 28% Black; 71% eligible for free/reduced lunch). Attendance improved for 89% of participants; average chronic absence dropped from 16% to 9% over two semesters. Students completing 10+ mentoring sessions were 2.1\u00d7 more likely to submit all homework on time. Youth and caregiver interviews highlighted stronger school belonging and improved communication at home. We recommend formalizing caregiver touchpoints and expanding peer mentoring to all cohorts.\"*\n\n### High-Level Recommendations\n\n1. **Pilot childcare stipend for job seekers** (Q2 2025) to close gender placement gap\n2. **Increase evening ESL sections by 25%** (Q2 2025) to serve clients with daytime work or family obligations\n3. **Add employer cohort in healthcare support roles** (Q3 2025) to expand pathways for credentialed nurses and allied health professionals\n\n### Overall Assessment and Learning Stance\n\n[Career Pathways demonstrated strong placement and retention outcomes, supported by robust employer partnerships and individualized coaching. Employer satisfaction surveys rated program graduates as \"job-ready\" at 87%. Credential evaluation and sector-aligned ESL showed measurable wage impacts. At the same time, **persistent wage and placement gaps for women and clients with limited English proficiency** signal the need for targeted supports\u2014particularly around childcare access, flexible scheduling advocacy with employers, and accelerated ESL pathways. Credential evaluation backlogs at WES delayed some sector-aligned placements, prompting us to batch submissions and pre-screen pathways at intake beginning in Q1 2025.]\n\n[We approach this report with a stance of **continuous learning**: celebrating what worked, naming what didn't, and committing to concrete adjustments that center equity and client voice.]\n\n---\n\n## 2. PROGRAM OVERVIEW\n**Target length: 300\u2013450 words**\n\n> **In plain language:** This section describes what the program does, who it's for, and why we think it works.\n\n> **How to adapt for funders/board:** Align goals and activities with funded objectives and approved budget categories. For ORR, emphasize self-sufficiency and rapid employment. For Commerce and Ballmer, highlight wage quality and equity.\n\n### Goals and Theory of Change\n\n[Career Pathways for New Americans operates on the theory that **contextualized ESL, targeted career coaching, and employer cohort partnerships** reduce the barriers that keep skilled refugees and asylees from accessing quality employment. By addressing language proficiency, credential recognition, and employer bias simultaneously, we accelerate clients' transition from arrival to stable, family-sustaining work. Our logic model (Appendix A) maps inputs \u2192 activities \u2192 outputs \u2192 short- and long-term outcomes, with a focus on both speed to employment and quality of match.]\n\n### Target Population and Eligibility\n\n[The program serves **adults aged 18\u201364** who hold refugee, asylee, SIV, or humanitarian parole status and arrived in the United States within the past 5 years. Clients reside across King County, with concentrations in Seattle, Kent, Tukwila, Burien, and Renton. Common barriers include:]\n\n- [Limited English proficiency]\n- [Lack of U.S. work experience or professional networks]\n- [Unrecognized foreign credentials and professional licenses]\n- [Childcare and eldercare responsibilities]\n- [Transportation costs and access]\n- [Trauma and acculturation stress]\n\n[In 2024, we served clients from 46 countries, including Afghanistan, Ukraine, Somalia, Democratic Republic of Congo, Syria, and Eritrea.]\n\n### Activities and Dosage\n\n[Participants access a menu of integrated services tailored to individual goals and readiness:]\n\n- **Contextualized ESL and bridge courses:** 4\u20136 hours/week, with sector-specific vocabulary modules (healthcare, IT, logistics)\n- **Career coaching and job readiness workshops:** Biweekly one-on-one sessions covering r\u00e9sum\u00e9 building, interview prep, workplace culture, and salary negotiation\n- **Credential evaluation and licensing navigation:** Case management support to submit WES applications, interpret results, and pursue state licensure (e.g., nursing, teaching)\n- **Employer cohort hiring events:** Quarterly hiring fairs with vetted employers committed to skills-based hiring and onboarding supports\n- **Paid work experiences:** Subsidized internships (up to 12 weeks) in healthcare, IT, and logistics to build U.S. work history\n- **Mentor matching and retention coaching:** Volunteer mentors provide cultural navigation, problem-solving, and encouragement through the first 90 days of employment\n\n[Staff include **certified employment specialists** (12 FTE), **ESL instructors** (8 FTE), **career navigators** (5 FTE), and **case managers** (4 FTE). All employment staff hold Workforce Development Certification; ESL instructors are TESOL-certified with adult education endorsements.]\n\n### Staffing, Partnerships, and Resources\n\n- **Staff:** 65 total (29 program staff, 18 ESL faculty, 12 case managers, 6 administrative/data)\n- **Volunteer mentors:** 120 active mentors, recruited from employer partners and community\n- **Institutional partners:** Seattle Colleges, Highline College, Renton Technical College; 75+ employer partners across healthcare, IT, logistics, hospitality, and manufacturing\n- **Annual budget:** $3.2 million (ORR, WA Commerce, Ballmer Group, City of Seattle, earned revenue)\n\n### Context and Operating Environment\n\n[In 2024, Seattle's minimum wage rose to $19.97/hour (large employers), creating upward pressure on entry-level wages. The regional tech sector experienced layoffs and hiring slowdowns, shifting some clients toward healthcare support and logistics pathways. Meanwhile, demand for certified nursing assistants (CNAs), medical assistants (MAs), and phlebotomists grew sharply. New arrivals from Ukraine (following 2022 humanitarian parole) and Afghanistan (following SIV processing delays) increased program demand by 18% over 2023. King County Metro expanded ORCA LIFT subsidized transit passes, improving job access for clients in South King County.]\n\n### Logic Model and Supporting Documents\n\n[See **Appendix A** for full logic model; **Appendix B** for data collection instruments; **Appendix C** for complete indicator definitions and calculation notes.]\n\n---\n\n## 3. EVALUATION QUESTIONS & METHODOLOGY\n**Target length: 300\u2013500 words**\n\n> **In plain language:** We measured success by tracking how many clients got jobs, stayed in them, and earned livable wages\u2014and by asking clients, employers, and staff what helped and what got in the way.\n\n> **How to adapt for funders/board:** Keep design description concise; emphasize validity, consent, and alignment with grant performance indicators. For ORR, cite ETO admin data; for Ballmer Group, emphasize equity disaggregation and participatory methods.\n\n### Evaluation Questions\n\nThis evaluation addressed five core questions:\n\n1. [To what extent did participants achieve job placement within 90 days of enrollment?]\n2. [What percentage of placed clients remained employed at 90 days, and which industries showed the strongest retention?]\n3. [What were starting wages, and how did wage outcomes vary by gender, English proficiency, and credential status?]\n4. [Which program components (ESL, coaching, mentorship, credential support) were most helpful, and for whom?]\n5. [What barriers persisted, and what programmatic adjustments are needed to advance equity?]\n\n### Design and Approach\n\n[We used a **pre-post cohort tracking design** with contribution analysis (not attribution). All enrolled clients were tracked from intake through 90 days post-placement. We did not use a comparison group; instead, we compared outcomes to program targets, 2023 baselines, and county labor market benchmarks. Where possible, we triangulated administrative data with employer verification and participant self-report.]\n\n### Data Sources\n\n| **Data Source** | **Sample / Response Rate** | **Timeline** | **Purpose / Questions Informed** |\n|-----------------|----------------------------|--------------|----------------------------------|\n| **ETO administrative database** | 1,085 clients (100% of enrollees) | Ongoing (Jan\u2013Dec 2024) | Placement, retention, wages, dosage, demographics (Q1, Q2, Q3) |\n| **Washington UI wage file** | 771 matched records (71% of placed clients; 29% missing SSN/recent arrival) | Quarterly, lagged 60 days | Wage verification, industry sector (Q3) |\n| **Employer satisfaction survey** | 58 employer partners (77% response rate) | November 2024 | Job readiness, retention support needs (Q2, Q4) |\n| **Participant intake survey** | 1,085 clients (100%) | At enrollment | Baseline English level, barriers, goals, demographics |\n| **Participant exit survey** | 891 clients (82% of enrolled) | At program completion or 90-day mark | Satisfaction, helpfulness of components, outcomes (Q4, Q5) |\n| **Focus groups** | 6 groups; 47 clients total (Arabic, Dari, Somali, Ukrainian language groups) | October\u2013November 2024 | Barriers, helpful components, retention challenges (Q4, Q5) |\n| **Staff debrief interviews** | 12 employment specialists and ESL instructors | December 2024 | Implementation insights, equity gaps (Q5) |\n\n### Sampling and Timing\n\n[All enrolled clients were invited to complete intake and exit surveys in their preferred language (Arabic, Dari, Somali, Ukrainian, Swahili, Amharic, English). Response rates: intake 100% (required for enrollment); exit 82%. Focus group participants were recruited via stratified purposive sampling to ensure representation across gender, nationality, and English proficiency levels. Childcare and interpretation were provided; participants received $40 gift cards. Employer survey respondents represented the full range of industries and hiring volumes.]\n\n### Data Quality and Validation\n\n[ETO data undergo monthly spot audits by the Evaluation Unit to check for missing fields, duplicate records, and data entry errors. Wage data are cross-checked against UI wage files where available; discrepancies <5% are considered acceptable. Where UI data are missing (29% of placed clients), we use employer-verified wage records or client self-report flagged as \"unverified.\" Survey instruments were piloted with 12 clients in July 2024 and revised for clarity. All translations were back-translated by certified translators.]\n\n### Ethics, Consent, and Privacy\n\n[Written informed consent was obtained in seven languages at intake. Consent forms explained data use, confidentiality protections, and the option to withdraw. Privacy protocols align with ORR confidentiality requirements; all data are stored on HIPAA-compliant secure servers. Participant quotes are used only with explicit written permission and are de-identified using ID codes (e.g., Client R-310). Institutional Review Board (IRB) approval was not required for this program evaluation under 45 CFR 46.104(d)(2).]\n\n### Equity and Participation\n\n[PHRS convened a **Client Advisory Council** (12 members representing major nationality and language groups) in August 2024. The Council co-designed survey items, reviewed focus group guides, and participated in two data interpretation workshops (December 2024) to validate findings and prioritize recommendations. Interpreters, childcare, and meal stipends were provided for all participatory sessions. Staff emphasized creating a welcoming environment and using plain language in all materials.]\n\n---\n\n## 4. FINDINGS BY OUTCOME AREA\n**Target length: 400\u2013700 words per outcome**\n\n> **In plain language:** This section shows the results\u2014what happened, for how many people, and whether we met our goals. We also look at who did better or worse, and why that matters.\n\n> **How to adapt for funders/board:** Lead with grant KPIs in table format; include 1\u20132 concise visuals per outcome; footnote methods; keep quotes brief and illustrative. For ORR, emphasize placement and self-sufficiency; for Ballmer, emphasize equity gaps and corrective actions.\n\n---\n\n### OUTCOME 1: Job Placement Within 90 Days\n\n**Definition:** Share of enrolled job-seeking clients who secured employment (unsubsidized or subsidized) within 90 days of intake, verified by employer or pay stub.\n\n#### Quantitative Results\n\n| **Indicator** | **Target** | **Actual** | **% Achieved** | **Data Source** | **Notes** |\n|---------------|------------|------------|----------------|-----------------|-----------|\n| % placed within 90 days | 60% | 63% | 105% | ETO admin data; employer verification | n=1,085 cohort-wide; includes unsubsidized and subsidized placements |\n\n**Pre/Post Context:** In 2023, placement rate was 58% (n=921). The 5-percentage-point gain reflects strengthened employer partnerships and expanded evening ESL offerings.\n\n**Visual Placeholder:**\n> **[BAR CHART: Job Placement Rate by Gender and English Proficiency]**  \n> *Caption:* \"Sixty-three percent of enrolled clients secured jobs within 90 days (n=1,085). Placement rates were higher for men (67%) than women (59%), and higher for clients with advanced English (69%) vs. limited English (58%). Data source: ETO admin records, Jan\u2013Dec 2024.\"\n\n#### Disaggregation and Equity Analysis\n\n| **Subgroup** | **Placement Rate (%)** | **n** |\n|--------------|------------------------|-------|\n| **Gender** | | |\n| Women | 59% | 586 |\n| Men | 67% | 499 |\n| **English Proficiency** | | |\n| Limited (CASAS <220) | 58% | 641 |\n| Advanced (CASAS \u2265220) | 69% | 444 |\n| **Nationality (examples)** | | |\n| Ukrainian | 65% | 187 |\n| Afghan | 60% | 214 |\n| Somali | 61% | 163 |\n\n**Equity Gap Analysis:**  \n[Women placed at **59% vs. 67% for men**\u2014an 8-percentage-point gap. Exit surveys and focus groups identified **childcare access** and **inflexible shift schedules** as primary barriers. One mother of three explained: *\"I had to turn down two good jobs because they wanted me there at 6 a.m. and my daycare doesn't open until 7.\"* \u2014 Client A-089 (consented). Limited English proficiency also slowed placement; clients with CASAS scores below 220 placed at 58%, compared to 69% for advanced learners.]\n\n**Action:** We will pilot a **childcare stipend** for job-seeking clients (up to $500/month for 3 months) beginning Q2 2025, funded by reallocating Ballmer grant capacity-building reserves. We will also advocate with employer partners for **flexible start times and part-time pathways**, particularly in healthcare support roles.\n\n#### Qualitative Insights\n\n**Key Themes:**\n1. **Employer cohort hiring events accelerated placement.** Clients appreciated face-to-face interaction with hiring managers, and employers valued PHRS pre-screening and skills verification.\n2. **Mentorship improved application quality and interview confidence.** Clients with mentors were 1.4\u00d7 more likely to receive job offers within 60 days (admin data analysis).\n3. **Childcare and transportation remain persistent barriers**, especially for women and clients in South King County.\n\n**Representative Quotes:**\n- *\"My mentor helped me translate my nursing experience to U.S. terms. I got three interviews in one week.\"* \u2014 Client U-221 (consented)\n- *\"The employer fair was different\u2014they saw me as a person, not just a r\u00e9sum\u00e9.\"* \u2014 Client S-145 (consented)\n\n#### Mixed/Negative Results: What We Learned, Why This Matters, What We're Changing\n\n**What we learned:**  \n[Clients with limited English proficiency placed more slowly and were more likely to accept lower-wage \"survival jobs\" outside their field to meet immediate income needs.]\n\n**Why this matters:**  \n[Delays can push skilled professionals into roles below their training and experience, undermining long-term economic mobility and job satisfaction. This pattern is inequitable and inefficient.]\n\n**What we're changing:**  \n[We will add **evening ESL sections** (25% increase in seats, funded by WA Commerce workforce training allocation) and introduce **sector-specific vocabulary modules** in healthcare, IT, and logistics starting Q2 2025. We will also shorten the ESL-to-employment bridge by integrating job search coaching into advanced ESL classes.]\n\n**Evidence tags:** Admin placement records (ETO); Employer satisfaction survey Q7; Focus Group: ESL Cohort B (Somali speakers, Oct 2024)\n\n---\n\n### OUTCOME 2: 90-Day Job Retention\n\n**Definition:** Share of placed clients who remained employed with the same or a new employer 90 days after job start, verified by employer contact or pay stub.\n\n#### Quantitative Results\n\n| **Indicator** | **Target** | **Actual** | **% Achieved** | **Data Source** | **Notes** |\n|---------------|------------|------------|----------------|-----------------|-----------|\n| % retained at 90 days | 70% | 72% | 103% | Employer verification; case notes | n=678 placed clients (those who started jobs) |\n\n**Pre/Post Context:** 2023 retention was 68% (n=533). The 4-percentage-point gain reflects expanded mentor supports and transportation subsidies.\n\n**Visual Placeholder:**\n> **[STACKED BAR CHART: 90-Day Retention by Industry Sector]**  \n> *Caption:* \"Retention at 90 days was highest in IT support (81%) and healthcare support (76%), and lowest in warehouse/logistics (68%) and hospitality (70%). Data source: Employer verification and case notes, n=678 placed clients, 2024.\"\n\n#### Disaggregation and Equity Analysis\n\n| **Industry Sector** | **90-Day Retention (%)** | **n** |\n|---------------------|--------------------------|-------|\n| Healthcare support | 76% | 241 |\n| Warehouse/logistics | 68% | 189 |\n| IT support | 81% | 102 |\n| Hospitality | 70% | 83 |\n| Other | 73% | 63 |\n\n**Equity Gap Analysis:**  \n[Retention was **lowest in warehouse and logistics roles (68%)**, where clients reported **unpredictable schedules, physically demanding conditions, and limited supervisor communication**. One client shared: *\"I quit after six weeks because the hours kept changing and I couldn't plan childcare.\"* \u2014 Client R-201 (consented). In contrast, healthcare and IT roles offered more consistent schedules and proactive onboarding supports.]\n\n**Action:** We will **strengthen job preview and expectations-setting** for warehouse placements, including site visits and peer panels. We will also coach employer partners on **shift flexibility and communication practices**. For high-churn sectors, we will extend retention coaching from 90 to 120 days (Q3 2025).\n\n#### Qualitative Insights\n\n**Key Themes:**\n1. **Weekly check-ins from mentors or employment specialists reduced early turnover.** Clients credited quick problem-solving (e.g., transportation issues, supervisor conflicts) with keeping them on track.\n2. **Transportation subsidies (ORCA LIFT passes) improved punctuality** and reduced stress, particularly for clients in South King County commuting to Seattle-based jobs.\n3. **Supervisor training on cultural competence and communication** (offered to 22 employer partners in 2024) correlated with higher retention in healthcare and IT sectors.\n\n**Representative Quotes:**\n- *\"Weekly check-ins helped me solve small issues before they got big. My coach called my supervisor when I was confused about overtime rules.\"* \u2014 Client R-310 (consented)\n- *\"The free bus pass saved me $100/month and I was never late.\"* \u2014 Client D-078 (consented)\n\n#### Mixed/Negative Results: What We Learned, Why This Matters, What We're Changing\n\n**What we learned:**  \n[Retention in warehouse/logistics roles is significantly lower than in other sectors, and clients report misalignment between job expectations and reality.]\n\n**Why this matters:**  \n[Early attrition disrupts income stability, strains employer relationships, and can discourage clients from future job search efforts. It also suggests program-employer fit issues that we can address.]\n\n**What we're changing:**  \n[Starting Q3 2025, we will offer **workplace tours and peer panels** for all warehouse/logistics placements, and **extend retention coaching to 120 days** for this sector. We will also work with employer partners to pilot **flexible shift bidding** and improve supervisor communication training.]\n\n**Evidence tags:** Employer verification logs; Exit survey Q12 (mentor helpfulness); Focus Group: Logistics Workers (Arabic speakers, Nov 2024)\n\n---\n\n### OUTCOME 3: Wages and Credential Utilization\n\n**Definition:** Starting hourly wages for placed clients, and credential equivalency outcomes for clients with prior professional training or post-secondary degrees.\n\n#### Quantitative Results\n\n| **Indicator** | **Target** | **Actual** | **% Achieved** | **Data Source** | **Notes** |\n|---------------|------------|------------|----------------|-----------------|-----------|\n| Median starting wage (USD/hour) | $21.00 | $21.80 | 104% | Admin payroll verification; WA UI wage file (lagged) | n=678 placed clients; county minimum wage context considered |\n| # clients achieving credential equivalency | 200 | 214 | 107% | WES credential outcomes | Nursing, engineering, teaching most common fields |\n\n**Pre/Post Context:** Median starting wage in 2023 was $19.20/hour (n=533 placed clients). The $2.60 increase reflects rising minimum wages, stronger employer partnerships, and credential utilization gains.\n\n**Visual Placeholder:**\n> **[BOX PLOT: Starting Wages by Gender and English Proficiency]**  \n> *Caption:* \"Median starting wage was $21.80/hour. Men earned a median of $23.00/hour compared to $20.10 for women\u2014a $2.90 gap. Clients with advanced English earned $23.20/hour vs. $20.40 for those with limited English. Data source: WA UI wage file and employer verification, n=678, 2024.\"\n\n#### Disaggregation and Equity Analysis\n\n| **Subgroup** | **Median Wage (USD/hour)** | **n** |\n|--------------|----------------------------|-------|\n| **Gender** | | |\n| Women | $20.10 | 386 |\n| Men | $23.00 | 292 |\n| **English Proficiency** | | |\n| Limited (CASAS <220) | $20.40 | 401 |\n| Advanced (CASAS \u2265220) | $23.20 | 277 |\n| **Credential Status** | | |\n| WES equivalency achieved | $24.50 | 214 |\n| No foreign credential | $19.80 | 464 |\n\n**Equity Gap Analysis:**  \n[A **$2.90 median wage gap** persists between men and women, even after controlling for industry and hours worked. Exit surveys and focus groups suggest **occupational sorting** (women more concentrated in lower-wage healthcare support roles like CNA vs. higher-wage phlebotomy or IT help desk) and **salary negotiation confidence gaps**. One client noted: *\"I accepted the first offer because I was afraid they'd take it back. My mentor said I should have asked for more.\"* \u2014 Client U-199 (consented).]\n\n[Clients who achieved **WES credential equivalency earned $24.50/hour**\u2014a $4.70 premium over those without recognized credentials. However, WES processing timelines (averaging 12\u201316 weeks in 2024) caused job-start delays, and some clients accepted lower-wage stopgap jobs while waiting.]\n\n**Action:** We will launch **salary negotiation workshops tailored for women** (Q2 2025), incorporate negotiation role-plays into career coaching, and share gender-disaggregated wage data with employer partners to advocate for pay equity. We will also **batch WES submissions monthly** and **pre-screen credential pathways at intake** to reduce evaluation delays (Q1 2025).\n\n#### Qualitative Insights\n\n**Key Themes:**\n1. **Credential evaluation boosted wage offers and employer respect.** Clients with recognized nursing, engineering, or teaching credentials reported more interviews and higher starting offers.\n2. **Negotiation coaching correlated with higher wages**, particularly in IT support roles where salary ranges are wider and negotiable.\n3. **Credential evaluation timelines caused delays and frustration.** Some clients felt \"stuck\" waiting for WES results and took survival jobs they later regretted.\n\n**Representative Quotes:**\n- *\"Once my degree was recognized, employers took my application seriously. I went from $18/hour offers to $26.\"* \u2014 Client D-144 (consented)\n- *\"I waited four months for my WES evaluation. By then I'd already started a warehouse job and it was hard to leave.\"* \u2014 Client A-203 (consented)\n\n#### Mixed/Negative Results: What We Learned, Why This Matters, What We're Changing\n\n**What we learned:**  \n[Credential evaluation delays at WES caused job-start delays and income gaps, pushing some clients to accept lower-wage work while waiting for results.]\n\n**Why this matters:**  \n[Delays undermine the program's goal of **rapid, skills-aligned placement**. Clients lose months of higher earnings, and some become locked into lower-wage roles due to schedule or psychological barriers to re-entering job search.]\n\n**What we're changing:**  \n[Starting Q1 2025, we will **batch WES submissions monthly** (vs. ad hoc), **pre-screen credential pathways at intake** to identify fast-track options (e.g., nursing licenses that don't require full WES), and **provide bridge stipends** (up to $1,000) for clients waiting on evaluations, funded by ORR self-sufficiency services allocation.]\n\n**Evidence tags:** WA UI wage file; WES outcomes tracking database; Exit survey Q9 (credential support); Staff debrief interviews (Dec 2024)\n\n---\n\n### Concrete Example (model the expected specificity):\n\n**Outcome: Improved on-time homework submission**\n\n- **Indicator:** % of students submitting \u226590% of assignments\n- **Target:** 70%; **Actual:** 64% (n=114); **% Achieved:** 91%\n- **Pre/post:** 41% \u2192 64% (+23 percentage points)\n- **Disaggregation:**  \n  - Grades 9\u201310: 68%  \n  - Grades 11\u201312: 58%  \n  - English learners: 61%  \n  - Non-EL: 66%\n- **Theme:** Students credited text reminders and peer study halls.  \n- **Quote:** *\"The Tuesday study group kept me from falling behind.\"* \u2014 10th grader (consented)\n- **What we're changing:** Expand peer study halls to 2\u00d7/week for upper grades; pilot multilingual reminders for families.\n\n---\n\n## 5. DISCUSSION/INTERPRETATION\n**Target length: 300\u2013500 words**\n\n> **In plain language:** Here we make sense of why results look the way they do\u2014what's working, what's not, and what outside forces shaped outcomes.\n\n> **How to adapt for funders/board:** Emphasize accountability, practical lessons, and planned course corrections. Tie interpretation to program theory and grant goals.\n\n### Connecting Findings to Program Theory\n\n[Our theory of change posits that **contextualized ESL, credential recognition, and employer partnerships** reduce barriers and accelerate quality job placement. The 2024 data **validate this theory**: clients who completed 40+ hours of ESL placed at 71% (vs. 52% for <20 hours); credential equivalency raised median wages by $4.70/hour; and employer cohort hiring correlated with faster placements and higher retention in healthcare and IT sectors. The evidence confirms that **integrated, skills-aligned supports outperform fragmented or English-only approaches**.]\n\n### Triangulation Across Data Sources\n\n[Administrative placement and wage data **align closely with employer and client reports**. Employers rated program graduates as \"job-ready\" at 87% (employer survey), and 81% of exit survey respondents reported feeling \"well-prepared\" for their first day. Where data diverge, it is instructive: clients flagged **childcare and inflexible schedules** as barriers more frequently than staff anticipated, signaling a need to center family supports in program design. UI wage data, while incomplete (29% missing), match employer-verified records within 3%, lending confidence to our wage findings.]\n\n### External Factors and Context\n\n[Seattle's **minimum wage increase** to $19.97/hour raised the floor for all workers, contributing to the overall wage gain. **King County Metro's ORCA LIFT expansion** in South King County improved job access, particularly for clients in Kent, Tukwila, and Renton commuting to Seattle-based healthcare and IT roles. Conversely, **tech sector layoffs** in late 2023 and early 2024 reduced entry-level IT openings, shifting some clients toward healthcare support and logistics pathways. The surge in **Ukrainian and Afghan arrivals** strained ESL capacity and lengthened wait times, underscoring the need for flexible, scalable service models.]\n\n### Surprises and Unexpected Patterns\n\n[We were **surprised by the speed and scale of wage gains in healthcare support roles**\u2014median $22.50/hour for CNAs and MAs, well above county averages. Focus groups revealed that **employer partners in healthcare actively negotiated higher wages** to compete for PHRS-referred candidates, viewing them as reliable and culturally competent. We were also surprised by the **low retention in warehouse/logistics**, given strong initial placement numbers; qualitative data clarified that poor supervisor communication and erratic schedules\u2014not the work itself\u2014drove turnover.]\n\n### Learning Stance: What We Learned / Why This Matters / What We're Changing\n\n**What we learned:**  \n[Gender and English proficiency gaps are **not inevitable**\u2014they result from structural barriers (childcare, scheduling) and program design choices (timing of ESL, wage negotiation coaching) that we can address.]\n\n**Why this matters:**  \n[Equity is not just a moral imperative; it's an operational and economic one. Women and limited-English clients represent 54% and 59% of our cohort, respectively. If we don't close these gaps, we leave hundreds of clients\u2014and their families\u2014behind.]\n\n**What we're changing:**  \n[We are piloting **childcare stipends, evening ESL, sector vocabulary modules, salary negotiation workshops for women, and extended retention coaching** for high-churn sectors. We will track disaggregated outcomes quarterly (vs. annually) and adjust in real time.]\n\n---\n\n## 6. RECOMMENDATIONS & NEXT STEPS\n**Target length: 250\u2013400 words**\n\n> **In plain language:** Based on what we learned, here's what we're going to do differently\u2014and who's responsible for making it happen.\n\n> **How to adapt for funders/board:** Flag budget-neutral options and items requiring reallocation or future grant funding. For ORR, emphasize self-sufficiency supports; for Ballmer, emphasize equity interventions.\n\n### Prioritized Recommendations\n\nEach recommendation below ties to a finding, names an owner, specifies a timeline, estimates resource needs, assesses feasibility, and defines a success measure.\n\n| **Recommendation** | **Owner/Lead** | **Timeframe** | **Resource Needs** | **Feasibility** | **Success Measure** |\n|--------------------|----------------|---------------|--------------------|-----------------|---------------------|\n| **1. Pilot childcare stipend for job seekers** (up to $500/month \u00d7 3 months) to close gender placement gap | Employment Services Director | Q2 2025 (April\u2013June launch) | $75K (Ballmer capacity-building reserve reallocation); 10 staff hours for policy/admin setup | **High** (funding identified; aligned with funder priorities) | Women's placement rate \u226565% by Q4 2025 (from 59% baseline) |\n| **2. Increase evening ESL sections by 25%** (add 2 sections, 40 seats) to serve clients with daytime obligations | ESL Program Manager | Q2 2025 (May start) | $48K instructor costs (WA Commerce workforce allocation); 15 staff hours curriculum adaptation | **High** (funding available; space confirmed at Highline College) | Evening ESL enrollment \u226580 clients by Q3 2025; placement rate for evening cohort \u226565% |\n| **3. Add employer cohort in healthcare support roles** (CNAs, MAs, phlebotomists) to expand credentialed pathways | Employer Partnerships Coordinator | Q3 2025 (Sept hiring fair) | 40 staff hours event planning; $5K venue/catering (ORR employment services); employer in-kind | **High** (strong employer interest confirmed) | \u226530 hires from Sept cohort; median wage \u2265$23/hour |\n| **4. Launch salary negotiation workshops for women** (monthly, 2-hour sessions) | Career Coach Lead | Q2 2025 (April start) | 12 staff hours/month facilitation; $2K childcare/interpretation (reallocate admin savings) | **High** (existing curriculum adapted from national model) | \u226560% of women workshop participants negotiate offer; gender wage gap narrows to \u2264$2/hour by Q4 2025 |\n| **5. Batch WES credential submissions monthly and pre-screen pathways at intake** to reduce evaluation delays | Case Management Supervisor | Q1 2025 (Feb implementation) | 8 staff hours setup; ongoing 4 hours/month coordination | **High** (process change, no added cost) | Average WES turnaround \u226410 weeks (from 14-week baseline); \u226590% of eligible clients submit within 30 days of intake |\n| **6. Extend retention coaching to 120 days for warehouse/logistics placements** | Retention Coach (new 0.5 FTE) | Q3 2025 (July start) | $35K salary + benefits (ORR retention services allocation); 20 hours onboarding/training | **Medium** (requires hiring; ORR budget amendment approved) | Warehouse/logistics retention \u226575% at 120 days (from 68% at 90 days) |\n| **7. Expand Client Advisory Council to 18 members and formalize co-design process** for program adaptations | Evaluation Manager + Program Director | Q2 2025 (April recruitment) | 30 staff hours facilitation/year; $6K stipends, childcare, interpretation | **High** (Ballmer evaluation allocation) | Council meets quarterly; \u22653 program changes co-designed annually; \u226575% member retention |\n\n### Implementation Sequencing\n\n**Immediate (Q1 2025):**  \n- Batch WES submissions and pre-screen credential pathways (Recommendation 5)\n\n**Short-term (Q2 2025):**  \n- Pilot childcare stipend (Rec 1)  \n- Launch evening ESL sections (Rec 2)  \n- Start salary negotiation workshops (Rec 4)  \n- Expand Client Advisory Council (Rec 7)\n\n**Medium-term (Q3 2025):**  \n- Healthcare employer cohort hiring fair (Rec 3)  \n- Hire and deploy retention coach for warehouse sector (Rec 6)\n\n### Alignment with Organizational Capacity\n\n[PHRS currently operates with **65 program staff, a $3.2M budget, and a 3-person Evaluation Unit**. Recommendations 1\u20135 and 7 are **high feasibility** and leverage existing funding streams or modest reallocations. Recommendation 6 (retention coach hire) requires ORR budget amendment, already approved. All recommendations were vetted by program leadership and the Client Advisory Council in December 2024 data interpretation workshops.]\n\n---\n\n## 7. LIMITATIONS\n**Target length: 150\u2013250 words**\n\n> **In plain language:** Here's what we couldn't measure or are less sure about\u2014and what we're doing to address those gaps.\n\n> **How to adapt for funders/board:** Be transparent and concise; emphasize mitigation steps and commitment to data quality improvement.\n\n### Sample and Response Rates\n\n[Exit survey response rate was **82%** (891/1,085), leaving 18% of clients unrepresented. Non-respondents were disproportionately male, younger, and early drop-outs; their outcomes may differ from completers. Focus groups included only 47 clients (4% of cohort), limiting generalizability of qualitative themes.]\n\n### Data Quality and Missing Data\n\n[**Washington UI wage data were missing for 29% of placed clients**, primarily recent arrivals without established SSNs or clients in cash/under-the-table work. For these cases, we relied on employer-verified or self-reported wages, flagged as \"unverified.\" Employer verification response rate was 89%; 11% of placements lack independent wage confirmation. ETO data entry errors (e.g., missing placement dates) affected <2% of records and were corrected via spot audits.]\n\n### Design Constraints\n\n[We did not use a **comparison or control group**; outcomes are compared to program targets and prior-year baselines, not to a matched sample of non-participants. We cannot claim attribution\u2014only contribution. **Follow-up is limited to 90 days**; longer-term retention, wage growth, and career advancement are unknown. Some clients may have been placed or retained due to external factors (e.g., family networks, prior U.S. work experience) not captured in our data.]\n\n### External Influences\n\n[Seattle's rising minimum wage, Metro transit expansions, and tech sector volatility all shaped outcomes, making year-over-year comparisons imperfect. The influx of Ukrainian and Afghan arrivals shifted cohort demographics and service demand mid-year.]\n\n### Ethics and Consent\n\n[**Informed consent was documented** for all data collection and quote use. Privacy protocols align with ORR confidentiality standards. All data are stored on secure, HIPAA-compliant servers.]\n\n### Mitigation and Next Steps\n\n[For 2025, we will increase exit survey follow-up (target 90% response rate), expand UI wage matching by partnering with WA Employment Security Department, add 6-month and 12-month retention tracking, and pilot a small comparison group of eligible non-participants (with consent) to strengthen causal inference.]\n\n---\n\n## 8. APPENDICES\n**Checklist with placeholders**\n\n- [ ] **Appendix A:** Logic model or theory of change diagram\n- [ ] **Appendix B:** Data collection instruments\n  - [ ] Participant intake survey (7 languages)\n  - [ ] Participant exit survey (7 languages)\n  - [ ] Employer satisfaction survey\n  - [ ] Focus group guides (by language)\n  - [ ] Staff debrief interview protocol\n- [ ] **Appendix C:** Complete indicator definitions and calculation notes\n  - [ ] Placement within 90 days (numerator, denominator, inclusions/exclusions)\n  - [ ] 90-day retention (verification methods, loss-to-follow-up handling)\n  - [ ] Median starting wage (data sources, adjustment for hours/FTE, outlier treatment)\n  - [ ] Credential equivalency (WES outcome categories, eligible population)\n- [ ] **Appendix D:** Detailed data tables by demographic subgroup\n  - [ ] Placement, retention, and wage outcomes by gender, age, nationality, English level, credential status, zip code\n- [ ] **Appendix E:** Sample consent forms and data privacy statement\n  - [ ] Multi-language informed consent (Arabic, Dari, Somali, Ukrainian, Swahili, Amharic, English)\n  - [ ] ORR-aligned confidentiality notice\n- [ ] **Appendix F:** Additional participant quotes (with consent documentation)\n  - [ ] Organized by outcome area and theme\n  - [ ] ID codes and consent status noted\n- [ ] **Appendix G:** Data quality checks documentation\n  - [ ] Missing data rates by variable\n  - [ ] Spot audit protocols and findings\n  - [ ] Survey reliability and translation validation notes\n- [ ] **Appendix H:** Client Advisory Council roster and participation summary\n  - [ ] Member demographics and representation\n  - [ ] Meeting dates and co-design activities\n\n---\n\n## FORMATTING AND STYLE GUIDE\n\n**Acronyms (define on first use):**\n- PHRS = Pacific Horizons Refugee Services\n- ORR = Office of Refugee Resettlement\n- ESL = English as a Second Language\n- WES = World Education Services\n- ETO = Efforts to Outcomes (case management database)\n- UI = Unemployment Insurance\n- CNA = Certified Nursing Assistant\n- MA = Medical Assistant\n- SIV = Special Immigrant Visa\n- CASAS = Comprehensive Adult Student Assessment Systems (ESL assessment)\n- FTE = Full-Time Equivalent\n\n**Numbers and Specificity:**\n- Use exact percentages and counts (not \"many\" or \"most\")\n- Include n-sizes for all quantitative claims\n- Specify timeframes (e.g., \"Q2 2025,\" not \"soon\")\n\n**Data Source Citation:**\n- Tie every claim to a source: e.g., \"(ETO admin data),\" \"(Exit survey Q12),\" \"(Focus Group: Somali speakers, Nov 2024)\"\n\n**Plain Language:**\n- Avoid or define jargon (e.g., \"dosage,\" \"triangulation,\" \"disaggregation\")\n- Use active voice and short sentences\n- Include \"In plain language\" callouts in technical sections\n\n**Visuals:**\n- Every chart/table must include: title, n-size, data source, date range\n- Suggest chart types: bar (for comparisons), line (for trends), box plot (for distributions)\n- Write descriptive captions that interpret, not just label\n\n**Page Target:**\n- **18\u201322 pages** (including appendices checklist; full appendices may add 10\u201330 pages)\n\n---\n\n## EQUITY AND PARTICIPATION INTEGRATION CHECKLIST\n\nFor **each outcome section**, confirm:\n- [ ] Results disaggregated by **gender, English proficiency, nationality/language, credential status**, and (where relevant) age, zip code\n- [ ] Gaps interpreted with **equity lens**: Whose outcomes lagged? Why? What structural barriers?\n- [ ] Concrete **actions proposed** to close gaps, with owners and timelines\n- [ ] **Client voice** included via quotes (with consent) and themes from focus groups\n\nFor **overall report**:\n- [ ] Client Advisory Council role and contributions named in Methodology and Acknowledgments\n- [ ] Language access and accommodations documented (interpretation, translation, childcare)\n- [ ] \"Whose voices informed this evaluation?\" prompt answered\n- [ ] \"Who is missing and how will we include them next time?\" addressed in Limitations or Recommendations\n\n---\n\n## QUALITY STANDARDS CHECKLIST\n\n**Do:**\n- [x] Use realistic refugee resettlement/employment examples (e.g., credential recognition, wage gaps, childcare barriers, ESL, employer partnerships)\n- [x] Present **both successes and challenges** honestly, with learning stance\n- [x] Make recommendations **specific, resourced, and time-bound** (owner, budget, feasibility)\n- [x] Include at least **one concrete example** in Executive Summary and one in Findings\n- [x] Disaggregate outcomes and **interpret equity gaps** with actionable responses\n\n**Avoid:**\n- [ ] Hype, defensiveness, or unexplained jargon\n- [ ] Vague claims (e.g., \"most clients improved\") without data\n- [ ] Recommendations without owners, timelines, or feasibility assessment\n- [ ] Visuals without captions, n-sizes, or data sources\n\n---\n\n## HOW TO REFINE THIS TEMPLATE\n\nThis template is designed to be **fill-in-ready** but also **customizable**. Here are quick prompts to adapt it:\n\n**Adjust length:**\n- *\"Shorten the Methodology section to 200 words for a board packet.\"*\n- *\"Expand the Findings section to 1,000 words per outcome for a full program evaluation report.\"*\n\n**Change tone:**\n- *\"Rewrite the Executive Summary in a FORMAL tone for an ORR site visit.\"*\n- *\"Rewrite the Discussion section in a WARM tone for a community report.\"*\n\n**Add or modify content:**\n- *\"Add a visual placeholder for the retention KPI with a bar chart and write a caption.\"*\n- *\"Include a 'Lessons Learned' sidebar in the Findings section.\"*\n- *\"Add a cost-per-outcome table in the Executive Summary for the Ballmer Group funder version.\"*\n\n**Tailor for specific audiences:**\n- *\"Create a 2-page board summary with only KPIs, top 3 findings, and recommendations.\"*\n- *\"Adapt the Executive Summary for a community presentation with plain language and client stories.\"*\n\n---\n\n**END OF TEMPLATE**\n\n**Report prepared by:** Lina Nguyen, Senior Evaluation Manager  \n**In collaboration with:** PHRS Impact & Learning Unit; Client Advisory Council  \n**Contact:** lnguyen@pacifichorizonsrefugee.org | (206) 555-0199  \n**For questions or data requests, contact:** evaluation@pacifichorizonsrefugee.org\n\n---\n\n*This evaluation was conducted in partnership with clients, staff, employer partners, and community stakeholders. We are grateful to the 1,085 clients who shared their time, stories, and trust; to the 120 volunteer mentors who walked alongside them; and to the 75 employer partners who opened doors. Special thanks to the Client Advisory Council for co-designing this evaluation and holding us accountable to equity and excellence.*",
      "timestamp": "2025-11-02T14:21:42.378929Z",
      "duration_seconds": 593.91,
      "tokens": {
        "input": 5120,
        "output": 12037,
        "total": 17157
      },
      "cost_usd": 0.195915,
      "success": true,
      "evaluation": {
        "overall_score": 9.2,
        "criteria_scores": {
          "tone": 10,
          "completeness": 9,
          "usefulness": 10,
          "accuracy": 9,
          "authenticity": 9
        },
        "reasoning": "This is an exceptionally well-crafted evaluation report template that demonstrates deep understanding of refugee resettlement programs, nonprofit evaluation standards, and funder requirements. The balanced tone is pitch-perfect, the structure is comprehensive and practical, and the scenario-specific details (WES credentials, UI wage matching, multilingual services) are highly authentic. Minor deductions only for density that might overwhelm some users and a few places where the fill-in prompts could be clearer.",
        "strengths": [
          "Outstanding sector authenticity - uses realistic refugee resettlement details (WES credential evaluation, CASAS scores, ORR compliance, UI wage matching, multilingual consent) that demonstrate genuine expertise rather than generic nonprofit language",
          "Exemplary equity integration - disaggregation prompts are embedded throughout with concrete action frameworks ('What we learned / Why this matters / What we're changing'), gender wage gap analysis, and Client Advisory Council participation",
          "Highly practical recommendations table with owners, timelines, resource needs, feasibility ratings, and success measures - this is exactly what nonprofit leaders need for implementation planning",
          "Perfect tone calibration - professional yet accessible, data-driven yet human-centered, with appropriate use of client quotes and plain language callouts",
          "Exceptional funder adaptability - specific guidance for ORR, Commerce, and Ballmer Group woven throughout, showing understanding of different funder priorities",
          "Comprehensive methodology section that balances rigor with transparency about limitations (29% missing UI data, no comparison group) in ways that build rather than undermine credibility",
          "Strong visual placeholder guidance with specific chart type recommendations and caption-writing prompts that will actually help users create meaningful data visualizations"
        ],
        "weaknesses": [
          "Template length and density may be overwhelming for smaller organizations - while the 18-22 page target fits the large org scenario, some users might benefit from a 'quick start' pathway or modular approach",
          "A few bracket prompts could be more directive - for example, in the Discussion section, users might benefit from sentence starters or more structured prompts rather than open brackets",
          "The appendices checklist is thorough but could include estimated page counts or effort levels to help teams prioritize what to include vs. omit for different audiences"
        ],
        "evaluator_model": "claude-sonnet-4.5"
      }
    }
  ],
  "summary": {
    "total_scenarios": 3,
    "total_outputs": 9,
    "successful_outputs": 7,
    "failed_outputs": 2,
    "total_cost_usd": 0.7896,
    "average_score": 9.06
  }
}